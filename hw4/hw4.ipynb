{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tdj1XLuceOk-"
   },
   "source": [
    "# Week 03: Word Representation\n",
    "The assignment this week is to distinguish between good and bad phrases of the word \"**earn**\" (e.g., earn money). You will practice using word2vector,  one of the methods learned today, in the process. \n",
    "\n",
    "Data used in this assignment:  \n",
    "https://drive.google.com/drive/folders/1qTIrefo4EFbsVF3LXhKbiahbIrvCLUBJ?usp=sharing\n",
    "\n",
    "* train.tsv: Some phrases with labels to train and validate the classification model. There are only two types of label: 1 means *good*; 0 means *bad*.\n",
    "* test.tsv: Same format as train.tsv. It's used to test your model.\n",
    "* GoogleNews-vectors-negative300.bin.gz: a pre-trained word2vector model trained by Google ([source](https://code.google.com/archive/p/word2vec/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GzvI76xeOlH"
   },
   "source": [
    "## Requirements\n",
    "* pandas\n",
    "* tensorflow\n",
    "* sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk5Xag5ueOlI"
   },
   "source": [
    "## Read Data\n",
    "We use dataframe to store data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UYsjz2eCeOlI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadData(path):\n",
    "  ngram = []\n",
    "  _class = []\n",
    "  with open(path) as f:\n",
    "    for line in f.readlines():\n",
    "      line = line.strip(\"\\n\").split(\"\\t\")\n",
    "      ngram.append(line[0])\n",
    "      _class.append(int(line[1]))\n",
    "  return pd.DataFrame({\"phrase\": ngram, \"class\": _class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earn a strong reputation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marty will surely earn every</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to earn between $</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to earn some college</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that earn rave reviews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         phrase  class\n",
       "0      earn a strong reputation      1\n",
       "1  Marty will surely earn every      0\n",
       "2             to earn between $      0\n",
       "3          to earn some college      0\n",
       "4        that earn rave reviews      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = loadData(\"train.tsv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>degree earn 62 percent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>earn maybe 30 or 50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earn the kind of money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn his 14th save</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earn a smaller amount</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phrase  class\n",
       "0  degree earn 62 percent      0\n",
       "1     earn maybe 30 or 50      0\n",
       "2  earn the kind of money      1\n",
       "3      earn his 14th save      1\n",
       "4   earn a smaller amount      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = loadData(\"test.tsv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl8pGQx2eOlL"
   },
   "source": [
    "## load word2vec model\n",
    "<font color=\"red\">**[ TODO ]**</font> Please load [GoogleNews-vectors-negative300.bin.gz](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g) model and check the embedding of the word `language`.\n",
    "\n",
    "* package `gensim` is a good choice (Look up the documentation [here](https://radimrehurek.com/gensim/models/word2vec.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DQjCDqZyeOlO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.30712891e-02  1.68457031e-02  1.54296875e-01  1.27929688e-01\n",
      " -2.67578125e-01  3.51562500e-02  1.19140625e-01  2.48046875e-01\n",
      "  1.93359375e-01 -7.95898438e-02  1.46484375e-01 -1.43554688e-01\n",
      " -3.04687500e-01  3.46679688e-02 -1.85546875e-02  1.06933594e-01\n",
      " -1.52343750e-01  2.89062500e-01  2.35595703e-02 -3.80859375e-01\n",
      "  1.09863281e-01  4.41406250e-01  3.75976562e-02 -1.22680664e-02\n",
      "  1.62353516e-02 -2.24609375e-01  7.61718750e-02 -3.12500000e-02\n",
      " -2.16064453e-02  1.49414062e-01 -4.02832031e-02 -4.46777344e-02\n",
      " -1.72851562e-01  3.32031250e-02  1.50390625e-01 -5.05371094e-02\n",
      "  2.72216797e-02  3.00781250e-01 -1.33789062e-01 -7.56835938e-02\n",
      "  1.93359375e-01 -1.98242188e-01 -1.27563477e-02  4.19921875e-01\n",
      " -2.19726562e-01  1.44531250e-01 -3.93066406e-02  1.94335938e-01\n",
      " -3.12500000e-01  1.84570312e-01  1.48773193e-04 -1.67968750e-01\n",
      " -7.37304688e-02 -3.12500000e-02  1.57226562e-01  3.30078125e-01\n",
      " -1.42578125e-01 -3.16406250e-01 -7.32421875e-02 -5.76171875e-02\n",
      "  1.02050781e-01 -1.08886719e-01  1.24023438e-01 -2.50244141e-02\n",
      " -2.49023438e-01  1.25976562e-01 -1.79687500e-01  3.32031250e-01\n",
      "  7.14111328e-03  2.51953125e-01  4.34570312e-02 -4.34570312e-02\n",
      " -3.90625000e-01  1.76757812e-01 -1.13525391e-02 -1.97753906e-02\n",
      "  2.79296875e-01  2.36328125e-01  1.19140625e-01  5.59082031e-02\n",
      "  1.73828125e-01 -1.10839844e-01 -4.95605469e-02  2.13867188e-01\n",
      "  6.17675781e-02  1.38671875e-01 -4.45556641e-03  2.55859375e-01\n",
      "  1.80664062e-01  5.88378906e-02 -6.59179688e-02 -2.08007812e-01\n",
      " -1.19140625e-01 -1.57226562e-01  5.02929688e-02 -6.29882812e-02\n",
      "  5.00488281e-02 -7.27539062e-02  1.74560547e-02 -3.56445312e-02\n",
      " -1.93359375e-01  3.93066406e-02 -3.36914062e-02 -1.07421875e-01\n",
      "  5.78613281e-02 -8.20312500e-02  1.74560547e-02 -1.65039062e-01\n",
      "  1.46484375e-01 -3.08837891e-02 -3.86718750e-01  2.49023438e-01\n",
      "  8.74023438e-02 -2.15820312e-01 -4.10156250e-02  1.60156250e-01\n",
      "  1.85546875e-01 -2.27050781e-02 -3.73535156e-02  7.86132812e-02\n",
      " -1.46484375e-01  6.78710938e-02  1.26953125e-01  3.30078125e-01\n",
      "  1.11328125e-01  9.27734375e-02 -3.45703125e-01 -1.41601562e-01\n",
      " -5.29785156e-02 -1.50390625e-01 -7.81250000e-02 -1.27929688e-01\n",
      " -4.02343750e-01 -1.41601562e-01  8.44726562e-02  1.08398438e-01\n",
      " -4.44335938e-02  3.73535156e-02  5.61523438e-02 -1.91406250e-01\n",
      "  1.54296875e-01 -5.12695312e-02 -6.49414062e-02 -8.30078125e-02\n",
      "  7.17773438e-02 -1.33789062e-01  1.05468750e-01  3.33984375e-01\n",
      " -1.08398438e-01  1.91650391e-02  2.14843750e-01  2.15820312e-01\n",
      " -1.05468750e-01 -1.44531250e-01  4.32128906e-02 -2.71484375e-01\n",
      " -3.78906250e-01  1.09863281e-01 -8.15429688e-02 -6.12792969e-02\n",
      " -1.33789062e-01  9.71679688e-02 -1.04370117e-02 -1.21093750e-01\n",
      " -2.44140625e-01  1.02050781e-01  1.10839844e-01 -1.00585938e-01\n",
      "  1.71875000e-01 -3.61328125e-02 -4.39453125e-02  2.83203125e-01\n",
      " -8.93554688e-02 -1.70898438e-01  2.46093750e-01  1.16699219e-01\n",
      "  8.39843750e-02 -1.32812500e-01 -1.61132812e-01 -1.39648438e-01\n",
      " -8.59375000e-02 -1.37695312e-01 -9.32617188e-02 -1.33789062e-01\n",
      "  1.65039062e-01  4.93164062e-02 -1.21093750e-01 -2.11914062e-01\n",
      "  1.61132812e-01 -1.07421875e-01 -3.97949219e-02 -3.51562500e-01\n",
      " -5.02929688e-02  1.46484375e-01 -4.68750000e-02  4.17480469e-02\n",
      " -1.27929688e-01 -9.76562500e-02 -2.46093750e-01  6.78710938e-02\n",
      " -2.30468750e-01  1.80664062e-02  3.54003906e-02  7.32421875e-02\n",
      " -2.23632812e-01 -1.25976562e-01  2.12890625e-01 -3.93066406e-02\n",
      " -2.41699219e-02 -9.61914062e-02  7.51953125e-02 -1.46484375e-01\n",
      " -1.49414062e-01 -8.83789062e-02 -4.88281250e-02  2.32421875e-01\n",
      "  3.30078125e-01  1.59179688e-01 -2.35351562e-01 -1.25976562e-01\n",
      "  2.68554688e-02 -5.29785156e-02 -6.59179688e-02 -2.17773438e-01\n",
      " -6.37817383e-03 -2.53906250e-01  2.28515625e-01  4.93164062e-02\n",
      "  3.54003906e-02  1.66992188e-01 -7.27539062e-02 -2.53906250e-01\n",
      " -1.34765625e-01  3.69140625e-01  1.83593750e-01 -1.64062500e-01\n",
      "  2.26562500e-01 -8.88671875e-02  3.69140625e-01  5.54199219e-02\n",
      " -3.63769531e-02 -1.48437500e-01  9.13085938e-02  2.47955322e-04\n",
      "  2.67578125e-01 -1.63085938e-01  1.19628906e-01  2.77343750e-01\n",
      " -1.49414062e-01  1.33789062e-01 -8.25195312e-02 -1.74804688e-01\n",
      " -1.77734375e-01  2.06054688e-01  5.07812500e-02 -2.08007812e-01\n",
      " -1.74804688e-01  9.66796875e-02  6.98242188e-02 -5.79833984e-04\n",
      "  9.22851562e-02  7.95898438e-02  1.41601562e-01  8.72802734e-03\n",
      " -8.05664062e-02  4.80957031e-02  2.49023438e-01 -1.64062500e-01\n",
      " -4.66308594e-02 -2.81250000e-01 -1.66015625e-01 -2.22656250e-01\n",
      " -2.32421875e-01  1.32812500e-01  4.15039062e-02  1.15234375e-01\n",
      " -7.66601562e-02 -1.10839844e-01 -1.97265625e-01  3.06396484e-02\n",
      " -1.03515625e-01  2.49023438e-02 -2.52685547e-02  3.39355469e-02\n",
      "  4.29687500e-02 -1.44531250e-01  2.12402344e-02  2.28271484e-02\n",
      " -1.88476562e-01  3.22265625e-01 -1.13281250e-01 -7.61718750e-02\n",
      "  2.94921875e-01 -1.33789062e-01 -1.80664062e-02 -6.25610352e-03\n",
      " -1.62353516e-02  5.98144531e-02  1.21582031e-01  4.17480469e-02]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "print(w2v_model[\"language\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fap51QcAeOlO"
   },
   "source": [
    "<font color=\"green\">Expected output: </font>\n",
    "\n",
    ">  <font face='monospace' size=3>\\[&nbsp;2.30712891e-02&nbsp;&nbsp;1.68457031e-02&nbsp;&nbsp;1.54296875e-01&nbsp; 1.27929688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.67578125e-01&nbsp;&nbsp;3.51562500e-02&nbsp;&nbsp;1.19140625e-01&nbsp; 2.48046875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.93359375e-01&nbsp;-7.95898438e-02&nbsp;&nbsp;1.46484375e-01&nbsp;-1.43554688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.04687500e-01&nbsp;&nbsp;3.46679688e-02&nbsp;-1.85546875e-02&nbsp; 1.06933594e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.52343750e-01&nbsp;&nbsp;2.89062500e-01&nbsp;&nbsp;2.35595703e-02&nbsp;-3.80859375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.09863281e-01&nbsp;&nbsp;4.41406250e-01&nbsp;&nbsp;3.75976562e-02&nbsp;-1.22680664e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.62353516e-02&nbsp;-2.24609375e-01&nbsp;&nbsp;7.61718750e-02&nbsp;-3.12500000e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.16064453e-02&nbsp;&nbsp;1.49414062e-01&nbsp;-4.02832031e-02&nbsp;-4.46777344e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.72851562e-01&nbsp;&nbsp;3.32031250e-02&nbsp;&nbsp;1.50390625e-01&nbsp;-5.05371094e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.72216797e-02&nbsp;&nbsp;3.00781250e-01&nbsp;-1.33789062e-01&nbsp;-7.56835938e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.93359375e-01&nbsp;-1.98242188e-01&nbsp;-1.27563477e-02&nbsp; 4.19921875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.19726562e-01&nbsp;&nbsp;1.44531250e-01&nbsp;-3.93066406e-02&nbsp; 1.94335938e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.12500000e-01&nbsp;&nbsp;1.84570312e-01&nbsp;&nbsp;1.48773193e-04&nbsp;-1.67968750e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-7.37304688e-02&nbsp;-3.12500000e-02&nbsp;&nbsp;1.57226562e-01&nbsp; 3.30078125e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.42578125e-01&nbsp;-3.16406250e-01&nbsp;-7.32421875e-02&nbsp;-5.76171875e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.02050781e-01&nbsp;-1.08886719e-01&nbsp;&nbsp;1.24023438e-01&nbsp;-2.50244141e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.49023438e-01&nbsp;&nbsp;1.25976562e-01&nbsp;-1.79687500e-01&nbsp; 3.32031250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;7.14111328e-03&nbsp;&nbsp;2.51953125e-01&nbsp;&nbsp;4.34570312e-02&nbsp;-4.34570312e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.90625000e-01&nbsp;&nbsp;1.76757812e-01&nbsp;-1.13525391e-02&nbsp;-1.97753906e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.79296875e-01&nbsp;&nbsp;2.36328125e-01&nbsp;&nbsp;1.19140625e-01&nbsp; 5.59082031e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.73828125e-01&nbsp;-1.10839844e-01&nbsp;-4.95605469e-02&nbsp; 2.13867188e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;6.17675781e-02&nbsp;&nbsp;1.38671875e-01&nbsp;-4.45556641e-03&nbsp; 2.55859375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.80664062e-01&nbsp;&nbsp;5.88378906e-02&nbsp;-6.59179688e-02&nbsp;-2.08007812e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.19140625e-01&nbsp;-1.57226562e-01&nbsp;&nbsp;5.02929688e-02&nbsp;-6.29882812e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;5.00488281e-02&nbsp;-7.27539062e-02&nbsp;&nbsp;1.74560547e-02&nbsp;-3.56445312e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.93359375e-01&nbsp;&nbsp;3.93066406e-02&nbsp;-3.36914062e-02&nbsp;-1.07421875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;5.78613281e-02&nbsp;-8.20312500e-02&nbsp;&nbsp;1.74560547e-02&nbsp;-1.65039062e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.46484375e-01&nbsp;-3.08837891e-02&nbsp;-3.86718750e-01&nbsp; 2.49023438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;8.74023438e-02&nbsp;-2.15820312e-01&nbsp;-4.10156250e-02&nbsp; 1.60156250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.85546875e-01&nbsp;-2.27050781e-02&nbsp;-3.73535156e-02&nbsp; 7.86132812e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.46484375e-01&nbsp;&nbsp;6.78710938e-02&nbsp;&nbsp;1.26953125e-01&nbsp; 3.30078125e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.11328125e-01&nbsp;&nbsp;9.27734375e-02&nbsp;-3.45703125e-01&nbsp;-1.41601562e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-5.29785156e-02&nbsp;-1.50390625e-01&nbsp;-7.81250000e-02&nbsp;-1.27929688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-4.02343750e-01&nbsp;-1.41601562e-01&nbsp;&nbsp;8.44726562e-02&nbsp; 1.08398438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-4.44335938e-02&nbsp;&nbsp;3.73535156e-02&nbsp;&nbsp;5.61523438e-02&nbsp;-1.91406250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.54296875e-01&nbsp;-5.12695312e-02&nbsp;-6.49414062e-02&nbsp;-8.30078125e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;7.17773438e-02&nbsp;-1.33789062e-01&nbsp;&nbsp;1.05468750e-01&nbsp; 3.33984375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.08398438e-01&nbsp;&nbsp;1.91650391e-02&nbsp;&nbsp;2.14843750e-01&nbsp; 2.15820312e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.05468750e-01&nbsp;-1.44531250e-01&nbsp;&nbsp;4.32128906e-02&nbsp;-2.71484375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.78906250e-01&nbsp;&nbsp;1.09863281e-01&nbsp;-8.15429688e-02&nbsp;-6.12792969e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.33789062e-01&nbsp;&nbsp;9.71679688e-02&nbsp;-1.04370117e-02&nbsp;-1.21093750e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.44140625e-01&nbsp;&nbsp;1.02050781e-01&nbsp;&nbsp;1.10839844e-01&nbsp;-1.00585938e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.71875000e-01&nbsp;-3.61328125e-02&nbsp;-4.39453125e-02&nbsp; 2.83203125e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-8.93554688e-02&nbsp;-1.70898438e-01&nbsp;&nbsp;2.46093750e-01&nbsp; 1.16699219e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;8.39843750e-02&nbsp;-1.32812500e-01&nbsp;-1.61132812e-01&nbsp;-1.39648438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-8.59375000e-02&nbsp;-1.37695312e-01&nbsp;-9.32617188e-02&nbsp;-1.33789062e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.65039062e-01&nbsp;&nbsp;4.93164062e-02&nbsp;-1.21093750e-01&nbsp;-2.11914062e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;1.61132812e-01&nbsp;-1.07421875e-01&nbsp;-3.97949219e-02&nbsp;-3.51562500e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-5.02929688e-02&nbsp;&nbsp;1.46484375e-01&nbsp;-4.68750000e-02&nbsp; 4.17480469e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.27929688e-01&nbsp;-9.76562500e-02&nbsp;-2.46093750e-01&nbsp; 6.78710938e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.30468750e-01&nbsp;&nbsp;1.80664062e-02&nbsp;&nbsp;3.54003906e-02&nbsp; 7.32421875e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.23632812e-01&nbsp;-1.25976562e-01&nbsp;&nbsp;2.12890625e-01&nbsp;-3.93066406e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.41699219e-02&nbsp;-9.61914062e-02&nbsp;&nbsp;7.51953125e-02&nbsp;-1.46484375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.49414062e-01&nbsp;-8.83789062e-02&nbsp;-4.88281250e-02&nbsp; 2.32421875e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;3.30078125e-01&nbsp;&nbsp;1.59179688e-01&nbsp;-2.35351562e-01&nbsp;-1.25976562e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.68554688e-02&nbsp;-5.29785156e-02&nbsp;-6.59179688e-02&nbsp;-2.17773438e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-6.37817383e-03&nbsp;-2.53906250e-01&nbsp;&nbsp;2.28515625e-01&nbsp; 4.93164062e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;3.54003906e-02&nbsp;&nbsp;1.66992188e-01&nbsp;-7.27539062e-02&nbsp;-2.53906250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.34765625e-01&nbsp;&nbsp;3.69140625e-01&nbsp;&nbsp;1.83593750e-01&nbsp;-1.64062500e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.26562500e-01&nbsp;-8.88671875e-02&nbsp;&nbsp;3.69140625e-01&nbsp; 5.54199219e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-3.63769531e-02&nbsp;-1.48437500e-01&nbsp;&nbsp;9.13085938e-02&nbsp; 2.47955322e-04<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.67578125e-01&nbsp;-1.63085938e-01&nbsp;&nbsp;1.19628906e-01&nbsp; 2.77343750e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.49414062e-01&nbsp;&nbsp;1.33789062e-01&nbsp;-8.25195312e-02&nbsp;-1.74804688e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.77734375e-01&nbsp;&nbsp;2.06054688e-01&nbsp;&nbsp;5.07812500e-02&nbsp;-2.08007812e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.74804688e-01&nbsp;&nbsp;9.66796875e-02&nbsp;&nbsp;6.98242188e-02&nbsp;-5.79833984e-04<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;9.22851562e-02&nbsp;&nbsp;7.95898438e-02&nbsp;&nbsp;1.41601562e-01&nbsp; 8.72802734e-03<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-8.05664062e-02&nbsp;&nbsp;4.80957031e-02&nbsp;&nbsp;2.49023438e-01&nbsp;-1.64062500e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-4.66308594e-02&nbsp;-2.81250000e-01&nbsp;-1.66015625e-01&nbsp;-2.22656250e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-2.32421875e-01&nbsp;&nbsp;1.32812500e-01&nbsp;&nbsp;4.15039062e-02&nbsp; 1.15234375e-01<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-7.66601562e-02&nbsp;-1.10839844e-01&nbsp;-1.97265625e-01&nbsp; 3.06396484e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.03515625e-01&nbsp;&nbsp;2.49023438e-02&nbsp;-2.52685547e-02&nbsp; 3.39355469e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;4.29687500e-02&nbsp;-1.44531250e-01&nbsp;&nbsp;2.12402344e-02&nbsp; 2.28271484e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.88476562e-01&nbsp;&nbsp;3.22265625e-01&nbsp;-1.13281250e-01&nbsp;-7.61718750e-02<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;&nbsp;2.94921875e-01&nbsp;-1.33789062e-01&nbsp;-1.80664062e-02&nbsp;-6.25610352e-03<br> </font>\n",
    ">  <font face='monospace' size=3>&nbsp;-1.62353516e-02&nbsp;&nbsp;5.98144531e-02&nbsp;&nbsp;1.21582031e-01&nbsp; 4.17480469e-02\\] </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL4Gqhyw56oX"
   },
   "source": [
    "<font color=\"red\">**[ TODO ]**</font> You can also find the top-N most similar words. Try it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zq-Jwhxe5jDy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elementary', 0.7868632078170776),\n",
       " ('schools', 0.7411909103393555),\n",
       " ('shool', 0.6692329049110413),\n",
       " ('elementary_schools', 0.6597153544425964),\n",
       " ('kindergarten', 0.6529811024665833)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(positive=[\"school\"], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUUOFU4J4Anl"
   },
   "source": [
    "<font color=\"green\">Expected output: </font>\n",
    ">  <font face='monospace' size=3>\n",
    "[('elementary', 0.7868632078170776),<br>\n",
    "&nbsp;('schools', 0.7411909103393555),<br>\n",
    "&nbsp;('shool', 0.6692329049110413),<br>\n",
    "&nbsp;('elementary_schools', 0.6597153544425964),<br>\n",
    "&nbsp;('kindergarten', 0.6529811024665833)]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIk5hWfGeOlR"
   },
   "source": [
    "## Preprocessing\n",
    "Preprocess the two tsv files here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUKN7pEKeOlS"
   },
   "source": [
    "#### adjust the ratio of the two classes of training data\n",
    "In the training data, the ratio of good phrases to bad phrases is about one to thirty. That will make training classification unsatisfactory, so we need to adjust the ratio. Reducing bad phrases and adding good phrases are both common way.\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> Please adjust the ratio of good phrases to bad phrases however you think is best and output the number of the two classes for demo.\n",
    "\n",
    "You need to explain why you chose this ratio and how you did it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "test_good = test[test[\"class\"] == 1]\n",
    "print(len(test_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "test_bad = test[test[\"class\"] == 0]\n",
    "print(len(test_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test good-to-bad ratio 1:1\n"
     ]
    }
   ],
   "source": [
    "print(\"test good-to-bad ratio 1:\" + str(int(len(test_bad) / len(test_good))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Good-to-Bad Ratio\n",
    "The ratio is adjusted by cutting short bad training data. It may be a good idea to have the ratio as close to that of testing data as possible. However, removing too many bad cases risks reducing the model accuracy. The final ratio is chosen by trials and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earn a strong reputation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62946</th>\n",
       "      <td>earn first place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62919</th>\n",
       "      <td>earn that amount of money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40857</th>\n",
       "      <td>it is expected to earn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62922</th>\n",
       "      <td>earn 12 or more</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          phrase  class\n",
       "0       earn a strong reputation      1\n",
       "62946           earn first place      1\n",
       "62919  earn that amount of money      1\n",
       "40857     it is expected to earn      1\n",
       "62922            earn 12 or more      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values(by=[\"class\"], ascending=False, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49598\n"
     ]
    }
   ],
   "source": [
    "train = train[:-150000]\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "gpleKkC9eOlS",
    "outputId": "c8fe9973-707a-4b08-be22-c9532f76fe3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6105\n"
     ]
    }
   ],
   "source": [
    "train_good = train[train[\"class\"] == 1]\n",
    "print(len(train_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43493\n"
     ]
    }
   ],
   "source": [
    "train_bad = train[train[\"class\"] == 0]\n",
    "print(len(train_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train good-to-bad ratio 1:7\n"
     ]
    }
   ],
   "source": [
    "print(\"train good-to-bad ratio 1:\" + str(int(len(train_bad) / len(train_good))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-V40xvY1eOlT"
   },
   "source": [
    "#### number words\n",
    "Give each word a unique number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "N2g3NLJ9eOlT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6414\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tok = Tokenizer()\n",
    "tok.fit_on_texts(pd.concat([train, test], ignore_index=True)[\"phrase\"])\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj0V1G_AeOlT"
   },
   "source": [
    "#### convert phrases into numbers\n",
    "Your model can't understand words, so we have to do this transform first. \n",
    "\n",
    "The number should be the same as the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FdwSF-1JeOlU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 2063, 203], [1, 113, 123], [1, 12, 106, 16, 6], [23, 72, 258, 2, 1], [1, 227, 28, 10]]\n"
     ]
    }
   ],
   "source": [
    "train_encoded_phrase = tok.texts_to_sequences(train[\"phrase\"])\n",
    "print(train_encoded_phrase[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49598\n"
     ]
    }
   ],
   "source": [
    "print(len(train_encoded_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "test_encoded_phrase = tok.texts_to_sequences(test[\"phrase\"])\n",
    "print(len(test_encoded_phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hhTKdm7eOlV"
   },
   "source": [
    "#### <font color=\"red\">**[ TODO ]**</font> padding\n",
    "Make all phrases the same length. The longest phrases in the two tsv files have five tokens. Hence, we should add zeroes to all the phrases that are shorter than five. \n",
    "- we suggest using `pad_sequences`, but you can do it however you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LF8rQwmneOlV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    3 2063  203]\n",
      " [   0    0    1  113  123]\n",
      " [   1   12  106   16    6]\n",
      " [  23   72  258    2    1]\n",
      " [   0    1  227   28   10]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(train_encoded_phrase, maxlen=5)\n",
    "X_test = pad_sequences(test_encoded_phrase, maxlen=5)\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbE9uyk0eOlW"
   },
   "source": [
    "#### <font color=\"red\">**[ TODO ]**</font> one hot encode the labels\n",
    "- we suggest using `to_categorical`, but again, you can use whatever you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SJkFyC8_eOlX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(train[\"class\"])\n",
    "y_test = to_categorical(test[\"class\"])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AJnIDUSeOlX"
   },
   "source": [
    "#### split training data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "r32haPqreOlY"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKthy0kTeOlY"
   },
   "source": [
    "#### <font color=\"red\">**[ TODO ]**</font> creating the embedding matrix\n",
    "The embedding matrix is used by the classification model. It should be a list of lists. Each sub-list is an embedding vector of a word and the order of all embedding vectors should be same as the word index numbering from the *tokenizer*. The tokenizer output is stored in a dictionary. You can check it using `tok.word_index.items()`.\n",
    "\n",
    "Make the embedding matrix. Our example model will need one, but you can skip it if the classification model you're using doesn't need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.sequences_to_texts([[2]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7zBQDNmmeOlZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([ 2.41699219e-02, -1.26953125e-01, -3.59375000e-01,  3.32031250e-01,\n",
      "        1.17187500e-01,  9.76562500e-02, -2.01416016e-02, -1.72851562e-01,\n",
      "       -4.54101562e-02,  2.63671875e-02, -1.35742188e-01, -6.22558594e-02,\n",
      "        1.23291016e-02,  4.17968750e-01, -1.06201172e-02,  3.80859375e-01,\n",
      "        1.64794922e-02,  5.93261719e-02, -5.93261719e-02,  1.08398438e-01,\n",
      "       -2.11914062e-01, -8.49609375e-02, -1.25976562e-01,  4.71191406e-02,\n",
      "        6.59179688e-02, -2.31445312e-01, -7.32421875e-02, -2.45117188e-01,\n",
      "       -2.13623047e-02,  1.69921875e-01,  1.72851562e-01, -1.66015625e-01,\n",
      "       -1.15722656e-01, -1.17187500e-01,  8.25195312e-02, -1.38671875e-01,\n",
      "        1.29882812e-01,  1.32812500e-01, -7.71484375e-02,  1.53320312e-01,\n",
      "        9.52148438e-02, -2.43164062e-01,  5.37109375e-02,  4.39453125e-02,\n",
      "       -1.65039062e-01, -4.14062500e-01,  1.32812500e-01, -5.34667969e-02,\n",
      "        9.71679688e-02,  6.10351562e-02, -8.00781250e-02,  6.78710938e-02,\n",
      "        3.65234375e-01,  4.88281250e-02, -2.91015625e-01,  9.96093750e-02,\n",
      "       -3.02124023e-03, -1.28906250e-01, -1.37695312e-01, -1.83593750e-01,\n",
      "        1.76757812e-01, -7.47070312e-02, -2.65625000e-01, -1.61132812e-01,\n",
      "       -6.44531250e-02,  4.22363281e-02,  6.29882812e-02, -2.50000000e-01,\n",
      "        1.03027344e-01,  1.19628906e-01,  5.37109375e-02,  1.19140625e-01,\n",
      "        7.17773438e-02, -3.85742188e-02,  2.94921875e-01, -4.02343750e-01,\n",
      "       -8.60595703e-03,  1.92382812e-01,  1.55029297e-02,  1.30615234e-02,\n",
      "       -1.63085938e-01,  6.98242188e-02, -2.24609375e-01,  3.28125000e-01,\n",
      "       -2.56347656e-02, -4.19921875e-02,  1.33789062e-01,  6.20117188e-02,\n",
      "        4.15039062e-02,  1.22558594e-01, -6.22558594e-02,  2.02148438e-01,\n",
      "       -8.10546875e-02, -9.66796875e-02,  5.95703125e-02, -3.20312500e-01,\n",
      "        3.65234375e-01,  8.25195312e-02,  8.78906250e-03, -2.19726562e-01,\n",
      "       -1.10839844e-01, -2.12890625e-01, -1.69921875e-01, -5.90820312e-02,\n",
      "        2.44140625e-02, -1.31835938e-01, -1.90429688e-01, -2.06054688e-01,\n",
      "        3.14941406e-02, -8.98437500e-02,  2.40234375e-01, -6.03027344e-02,\n",
      "       -1.35742188e-01,  2.89306641e-02,  1.62109375e-01,  1.64062500e-01,\n",
      "        1.59179688e-01,  2.18505859e-02, -1.90429688e-02, -1.68945312e-01,\n",
      "        2.75390625e-01, -2.08984375e-01, -1.63574219e-02,  1.13769531e-01,\n",
      "       -6.54296875e-02,  3.28063965e-04, -8.98437500e-02, -3.88183594e-02,\n",
      "       -2.06054688e-01, -6.17675781e-02,  1.51367188e-01, -7.47070312e-02,\n",
      "       -7.42187500e-02, -3.41796875e-02,  8.69140625e-02, -3.00292969e-02,\n",
      "       -3.00781250e-01,  4.14062500e-01, -1.66015625e-01,  2.25585938e-01,\n",
      "       -1.93359375e-01, -2.55859375e-01, -1.68945312e-01, -7.91015625e-02,\n",
      "        5.03540039e-03,  1.09863281e-02,  1.79443359e-02, -2.09960938e-01,\n",
      "       -6.25000000e-02, -1.61132812e-01,  2.12402344e-02,  1.66992188e-01,\n",
      "       -1.04492188e-01,  4.02832031e-03, -1.05957031e-01,  2.77343750e-01,\n",
      "        8.20312500e-02, -1.44195557e-03,  1.09375000e-01, -8.30078125e-02,\n",
      "        5.39550781e-02, -3.56445312e-02, -1.60156250e-01, -1.76757812e-01,\n",
      "       -7.56835938e-02,  7.99560547e-03,  5.29785156e-02, -1.90429688e-01,\n",
      "        8.54492188e-02, -2.25830078e-02, -3.10546875e-01, -2.35351562e-01,\n",
      "       -6.73828125e-02, -9.37500000e-02, -8.74023438e-02, -6.17675781e-02,\n",
      "        2.71484375e-01,  1.35742188e-01, -1.18164062e-01,  1.88476562e-01,\n",
      "       -1.16210938e-01, -2.31445312e-01,  7.66601562e-02,  3.69140625e-01,\n",
      "       -3.16406250e-01, -1.99218750e-01,  1.02050781e-01,  1.17187500e-01,\n",
      "        1.94091797e-02, -2.38037109e-02,  9.86328125e-02, -1.33789062e-01,\n",
      "       -1.07421875e-01, -2.46093750e-01, -3.33984375e-01, -1.03027344e-01,\n",
      "        2.09960938e-01, -1.00585938e-01, -4.33593750e-01, -1.06445312e-01,\n",
      "       -3.58886719e-02,  2.14843750e-01,  1.55273438e-01,  2.61230469e-02,\n",
      "       -1.39770508e-02, -1.68945312e-01, -3.47656250e-01, -1.58203125e-01,\n",
      "       -1.70898438e-01, -6.25000000e-02,  1.31835938e-01,  1.46484375e-01,\n",
      "        4.68750000e-02,  3.08593750e-01,  3.80859375e-02,  3.14453125e-01,\n",
      "        1.10473633e-02,  1.36718750e-01, -3.32031250e-02, -2.87109375e-01,\n",
      "       -2.30712891e-02,  5.54199219e-02,  2.02148438e-01,  2.29492188e-02,\n",
      "        1.72851562e-01,  3.20312500e-01, -1.29882812e-01, -1.60156250e-01,\n",
      "        1.86523438e-01, -1.13281250e-01,  3.47656250e-01, -1.12792969e-01,\n",
      "        4.08203125e-01,  1.85546875e-01,  1.34765625e-01,  6.34765625e-02,\n",
      "        6.17675781e-02, -1.10351562e-01,  1.39648438e-01,  3.51562500e-02,\n",
      "        9.91210938e-02, -1.43554688e-01,  2.12402344e-02, -3.00781250e-01,\n",
      "       -1.66992188e-01,  1.42578125e-01,  7.95898438e-02, -1.19628906e-01,\n",
      "       -1.97265625e-01, -3.43750000e-01, -1.04980469e-01, -3.66210938e-03,\n",
      "       -6.29882812e-02, -2.58789062e-02, -1.57226562e-01,  3.45703125e-01,\n",
      "       -9.39941406e-03,  1.20117188e-01, -1.29882812e-01,  2.02636719e-02,\n",
      "        1.68945312e-01, -2.38037109e-02, -3.11279297e-02,  2.20703125e-01,\n",
      "        2.65625000e-01,  1.12792969e-01,  2.14843750e-01, -6.59179688e-02,\n",
      "        2.16064453e-02, -1.37695312e-01, -6.83593750e-02, -1.44531250e-01,\n",
      "        1.66015625e-01,  8.54492188e-02,  2.55859375e-01,  1.23046875e-01,\n",
      "       -2.81250000e-01, -2.94921875e-01,  1.18408203e-02,  3.63769531e-02,\n",
      "        2.09960938e-01, -2.29492188e-02, -1.05468750e-01,  1.66015625e-01,\n",
      "       -1.78222656e-02, -1.68457031e-02, -5.81054688e-02,  2.73437500e-01,\n",
      "       -2.53906250e-02,  8.69140625e-02,  1.38671875e-01,  2.28515625e-01,\n",
      "       -2.23632812e-01, -2.42187500e-01, -2.27539062e-01, -6.25000000e-02,\n",
      "        2.38281250e-01, -2.03125000e-01,  2.38281250e-01, -1.53320312e-01],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([ 0.20410156,  0.01318359,  0.07568359,  0.28515625, -0.10888672,\n",
      "        0.10107422, -0.02954102,  0.0480957 , -0.11132812, -0.00326538,\n",
      "       -0.09277344, -0.05761719, -0.12988281, -0.11132812, -0.24707031,\n",
      "        0.140625  ,  0.07470703,  0.02661133,  0.23632812, -0.06689453,\n",
      "        0.02856445,  0.09082031,  0.19140625, -0.08251953, -0.02978516,\n",
      "        0.11425781, -0.03442383,  0.00344849, -0.00102234, -0.05444336,\n",
      "       -0.05615234,  0.09033203, -0.03637695, -0.05761719, -0.20898438,\n",
      "       -0.02893066,  0.09765625,  0.05200195,  0.04125977,  0.19238281,\n",
      "        0.02331543, -0.24707031,  0.34765625,  0.00479126,  0.10791016,\n",
      "        0.11279297,  0.08007812, -0.06689453,  0.15136719, -0.1796875 ,\n",
      "        0.00775146,  0.18066406,  0.0246582 ,  0.08691406, -0.01257324,\n",
      "       -0.12792969, -0.00315857, -0.03088379,  0.12792969,  0.13476562,\n",
      "        0.06298828, -0.00479126, -0.13867188, -0.05810547,  0.02160645,\n",
      "       -0.06079102, -0.13378906,  0.07763672, -0.08496094, -0.08740234,\n",
      "        0.2734375 ,  0.07177734,  0.06030273, -0.22851562, -0.35742188,\n",
      "       -0.265625  ,  0.00294495,  0.24023438,  0.04150391,  0.3203125 ,\n",
      "       -0.12011719, -0.22460938,  0.08154297,  0.04296875, -0.09765625,\n",
      "       -0.13867188,  0.10107422,  0.27539062, -0.00379944,  0.11425781,\n",
      "        0.006073  ,  0.13085938, -0.16894531, -0.07373047, -0.11035156,\n",
      "       -0.06494141,  0.30078125,  0.09179688,  0.06298828, -0.04711914,\n",
      "       -0.13378906, -0.00090408, -0.01806641,  0.0703125 , -0.3828125 ,\n",
      "        0.04492188, -0.15917969,  0.06030273, -0.01519775, -0.23046875,\n",
      "       -0.25390625, -0.12451172, -0.09814453, -0.02478027,  0.07470703,\n",
      "       -0.09472656, -0.09912109, -0.11767578,  0.15136719, -0.09960938,\n",
      "       -0.00430298, -0.20214844, -0.06591797,  0.14453125,  0.06933594,\n",
      "        0.06542969, -0.10693359,  0.07519531, -0.02001953,  0.07128906,\n",
      "       -0.3359375 , -0.15039062, -0.21875   ,  0.0859375 ,  0.0859375 ,\n",
      "       -0.21484375, -0.05541992, -0.03271484,  0.06079102,  0.33789062,\n",
      "        0.09130859, -0.10107422, -0.07568359, -0.02990723,  0.1953125 ,\n",
      "       -0.140625  ,  0.03833008, -0.3046875 ,  0.171875  , -0.01428223,\n",
      "        0.19335938,  0.09667969, -0.26757812, -0.11523438, -0.04345703,\n",
      "        0.06542969,  0.02502441, -0.0111084 , -0.17675781,  0.19238281,\n",
      "       -0.00270081,  0.20019531, -0.14941406,  0.24511719,  0.01397705,\n",
      "       -0.28515625,  0.171875  , -0.07324219,  0.03930664, -0.02697754,\n",
      "       -0.29101562,  0.05151367, -0.05249023, -0.14648438, -0.13183594,\n",
      "        0.02722168,  0.12207031, -0.05371094, -0.04760742,  0.01940918,\n",
      "       -0.05859375,  0.11572266,  0.05053711,  0.00042725, -0.06005859,\n",
      "       -0.0133667 , -0.13867188, -0.01574707,  0.11962891,  0.04833984,\n",
      "       -0.06542969,  0.20898438, -0.14355469, -0.02514648,  0.109375  ,\n",
      "        0.11083984, -0.07470703, -0.02453613, -0.07568359, -0.18457031,\n",
      "        0.05444336,  0.12890625, -0.10205078,  0.10498047, -0.02734375,\n",
      "        0.17578125, -0.25976562, -0.20214844, -0.04467773,  0.03588867,\n",
      "        0.02661133,  0.17480469, -0.16894531,  0.03540039, -0.30273438,\n",
      "       -0.04858398,  0.19238281,  0.06542969, -0.22070312,  0.06225586,\n",
      "       -0.07128906, -0.05761719, -0.15039062, -0.18261719,  0.11621094,\n",
      "       -0.0625    ,  0.18652344,  0.00308228, -0.23730469, -0.07861328,\n",
      "       -0.05273438, -0.03344727, -0.02380371,  0.11474609,  0.03015137,\n",
      "        0.03369141, -0.06298828,  0.05810547,  0.13964844, -0.04150391,\n",
      "        0.01025391,  0.08789062, -0.00175476, -0.17578125, -0.04858398,\n",
      "       -0.10058594, -0.11083984,  0.27148438, -0.04272461, -0.1875    ,\n",
      "        0.09912109, -0.10302734, -0.04882812,  0.05200195, -0.01470947,\n",
      "       -0.00756836,  0.06079102, -0.20019531, -0.05371094, -0.01391602,\n",
      "       -0.03686523, -0.20507812, -0.18554688, -0.11376953,  0.02453613,\n",
      "        0.13671875,  0.03112793, -0.00534058, -0.17480469, -0.02258301,\n",
      "       -0.10791016,  0.34375   ,  0.16113281,  0.30273438, -0.09082031,\n",
      "       -0.02685547,  0.00588989, -0.19335938, -0.14257812,  0.05004883,\n",
      "        0.01733398, -0.19140625, -0.00897217,  0.08740234, -0.06787109,\n",
      "        0.13476562, -0.06103516, -0.203125  ,  0.00958252,  0.16601562,\n",
      "       -0.01635742,  0.1328125 , -0.23828125, -0.10595703,  0.08691406,\n",
      "       -0.10058594,  0.04956055, -0.21191406, -0.1328125 ,  0.10839844],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_matrix = []\n",
    "for idx in range(0, vocab_size):\n",
    "  word = tok.sequences_to_texts([[idx]])[0]\n",
    "  if word in w2v_model.index_to_key:\n",
    "    embedding_matrix.append(w2v_model[word])\n",
    "  else:\n",
    "    embedding_matrix.append(np.zeros(w2v_model.vector_size))\n",
    "print(embedding_matrix[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c9JvMZaeOlZ"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpgeqgmWeOlZ"
   },
   "source": [
    "#### build model\n",
    "<font color=\"red\">**[ TODO ]**</font> Please build your classification model by ***keras*** here. Don't worry if you don't know how, just use the one given below. Feel free to make any changes or even build your own.\n",
    "\n",
    "You **must** use the pre-trained word2vec model to represent the words of phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:19:30.711930: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 13:19:31.159340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Flatten, Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=300, input_length=5, embeddings_initializer=Constant(embedding_matrix)))\n",
    "model.add(LSTM(256, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=RMSprop(learning_rate=1e-6), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7EVyMofjeOla"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5, 300)            1924200   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               570368    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,511,146\n",
      "Trainable params: 2,511,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSG0J5P7eOla"
   },
   "source": [
    "#### train\n",
    "Train classification model here.\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> Adjust the hyperparameter to optimize the validation accuracy and validation loss.\n",
    "\n",
    "* The higher the accuracy, the better; the lower the validation, the better.\n",
    "* **number of epoch** and **batch size** are the most important\n",
    "  * Start with a smaller number of epochs first--it is directly correlated to the training time, and you don't want to spend too much time waiting!\n",
    "  * Usually the larger the batch size the better, but the batch size you are able to use depends on you computing power, so start small and increase gradually. It is recommended to use powers of 2 (2, 4, 8, 16, ...) for batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MSs4f9ELeOlb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2048\n",
      "78/78 [==============================] - 2s 10ms/step - loss: 0.6967 - accuracy: 0.3403 - val_loss: 0.6950 - val_accuracy: 0.4138\n",
      "Epoch 2/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6934 - accuracy: 0.4881 - val_loss: 0.6918 - val_accuracy: 0.5599\n",
      "Epoch 3/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6901 - accuracy: 0.6338 - val_loss: 0.6885 - val_accuracy: 0.7008\n",
      "Epoch 4/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6869 - accuracy: 0.7534 - val_loss: 0.6853 - val_accuracy: 0.7951\n",
      "Epoch 5/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6837 - accuracy: 0.8251 - val_loss: 0.6822 - val_accuracy: 0.8440\n",
      "Epoch 6/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6806 - accuracy: 0.8554 - val_loss: 0.6791 - val_accuracy: 0.8637\n",
      "Epoch 7/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6774 - accuracy: 0.8690 - val_loss: 0.6760 - val_accuracy: 0.8712\n",
      "Epoch 8/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6743 - accuracy: 0.8745 - val_loss: 0.6729 - val_accuracy: 0.8737\n",
      "Epoch 9/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6713 - accuracy: 0.8764 - val_loss: 0.6699 - val_accuracy: 0.8749\n",
      "Epoch 10/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6683 - accuracy: 0.8773 - val_loss: 0.6670 - val_accuracy: 0.8750\n",
      "Epoch 11/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6653 - accuracy: 0.8774 - val_loss: 0.6640 - val_accuracy: 0.8750\n",
      "Epoch 12/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6623 - accuracy: 0.8774 - val_loss: 0.6611 - val_accuracy: 0.8750\n",
      "Epoch 13/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6594 - accuracy: 0.8774 - val_loss: 0.6582 - val_accuracy: 0.8750\n",
      "Epoch 14/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6565 - accuracy: 0.8774 - val_loss: 0.6553 - val_accuracy: 0.8750\n",
      "Epoch 15/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6536 - accuracy: 0.8774 - val_loss: 0.6524 - val_accuracy: 0.8750\n",
      "Epoch 16/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6507 - accuracy: 0.8774 - val_loss: 0.6495 - val_accuracy: 0.8750\n",
      "Epoch 17/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6478 - accuracy: 0.8774 - val_loss: 0.6467 - val_accuracy: 0.8750\n",
      "Epoch 18/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6449 - accuracy: 0.8774 - val_loss: 0.6438 - val_accuracy: 0.8750\n",
      "Epoch 19/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6420 - accuracy: 0.8774 - val_loss: 0.6409 - val_accuracy: 0.8750\n",
      "Epoch 20/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6391 - accuracy: 0.8774 - val_loss: 0.6381 - val_accuracy: 0.8750\n",
      "Epoch 21/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6362 - accuracy: 0.8774 - val_loss: 0.6352 - val_accuracy: 0.8750\n",
      "Epoch 22/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6333 - accuracy: 0.8774 - val_loss: 0.6323 - val_accuracy: 0.8750\n",
      "Epoch 23/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6304 - accuracy: 0.8774 - val_loss: 0.6293 - val_accuracy: 0.8750\n",
      "Epoch 24/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6274 - accuracy: 0.8774 - val_loss: 0.6264 - val_accuracy: 0.8750\n",
      "Epoch 25/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6244 - accuracy: 0.8774 - val_loss: 0.6234 - val_accuracy: 0.8750\n",
      "Epoch 26/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6214 - accuracy: 0.8774 - val_loss: 0.6205 - val_accuracy: 0.8750\n",
      "Epoch 27/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6184 - accuracy: 0.8774 - val_loss: 0.6175 - val_accuracy: 0.8750\n",
      "Epoch 28/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6154 - accuracy: 0.8774 - val_loss: 0.6144 - val_accuracy: 0.8750\n",
      "Epoch 29/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.6123 - accuracy: 0.8774 - val_loss: 0.6114 - val_accuracy: 0.8750\n",
      "Epoch 30/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6092 - accuracy: 0.8774 - val_loss: 0.6083 - val_accuracy: 0.8750\n",
      "Epoch 31/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6061 - accuracy: 0.8774 - val_loss: 0.6052 - val_accuracy: 0.8750\n",
      "Epoch 32/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6029 - accuracy: 0.8774 - val_loss: 0.6020 - val_accuracy: 0.8750\n",
      "Epoch 33/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5997 - accuracy: 0.8774 - val_loss: 0.5989 - val_accuracy: 0.8750\n",
      "Epoch 34/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5965 - accuracy: 0.8774 - val_loss: 0.5957 - val_accuracy: 0.8750\n",
      "Epoch 35/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5933 - accuracy: 0.8774 - val_loss: 0.5925 - val_accuracy: 0.8750\n",
      "Epoch 36/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5900 - accuracy: 0.8774 - val_loss: 0.5892 - val_accuracy: 0.8750\n",
      "Epoch 37/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5867 - accuracy: 0.8774 - val_loss: 0.5859 - val_accuracy: 0.8750\n",
      "Epoch 38/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5834 - accuracy: 0.8774 - val_loss: 0.5826 - val_accuracy: 0.8750\n",
      "Epoch 39/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5800 - accuracy: 0.8774 - val_loss: 0.5793 - val_accuracy: 0.8750\n",
      "Epoch 40/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5767 - accuracy: 0.8774 - val_loss: 0.5759 - val_accuracy: 0.8750\n",
      "Epoch 41/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5732 - accuracy: 0.8774 - val_loss: 0.5725 - val_accuracy: 0.8750\n",
      "Epoch 42/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5698 - accuracy: 0.8774 - val_loss: 0.5690 - val_accuracy: 0.8750\n",
      "Epoch 43/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5663 - accuracy: 0.8774 - val_loss: 0.5656 - val_accuracy: 0.8750\n",
      "Epoch 44/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.5627 - accuracy: 0.8774 - val_loss: 0.5621 - val_accuracy: 0.8750\n",
      "Epoch 45/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.5592 - accuracy: 0.8774 - val_loss: 0.5585 - val_accuracy: 0.8750\n",
      "Epoch 46/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.5556 - accuracy: 0.8774 - val_loss: 0.5550 - val_accuracy: 0.8750\n",
      "Epoch 47/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5520 - accuracy: 0.8774 - val_loss: 0.5514 - val_accuracy: 0.8750\n",
      "Epoch 48/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5483 - accuracy: 0.8774 - val_loss: 0.5477 - val_accuracy: 0.8750\n",
      "Epoch 49/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5446 - accuracy: 0.8774 - val_loss: 0.5440 - val_accuracy: 0.8750\n",
      "Epoch 50/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.8774 - val_loss: 0.5403 - val_accuracy: 0.8750\n",
      "Epoch 51/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.8774 - val_loss: 0.5366 - val_accuracy: 0.8750\n",
      "Epoch 52/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5333 - accuracy: 0.8774 - val_loss: 0.5328 - val_accuracy: 0.8750\n",
      "Epoch 53/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5294 - accuracy: 0.8774 - val_loss: 0.5290 - val_accuracy: 0.8750\n",
      "Epoch 54/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5256 - accuracy: 0.8774 - val_loss: 0.5252 - val_accuracy: 0.8750\n",
      "Epoch 55/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5217 - accuracy: 0.8774 - val_loss: 0.5213 - val_accuracy: 0.8750\n",
      "Epoch 56/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.8774 - val_loss: 0.5174 - val_accuracy: 0.8750\n",
      "Epoch 57/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.5138 - accuracy: 0.8774 - val_loss: 0.5135 - val_accuracy: 0.8750\n",
      "Epoch 58/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 9ms/step - loss: 0.5098 - accuracy: 0.8774 - val_loss: 0.5095 - val_accuracy: 0.8750\n",
      "Epoch 59/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.5058 - accuracy: 0.8774 - val_loss: 0.5055 - val_accuracy: 0.8750\n",
      "Epoch 60/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.5017 - accuracy: 0.8774 - val_loss: 0.5015 - val_accuracy: 0.8750\n",
      "Epoch 61/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4976 - accuracy: 0.8774 - val_loss: 0.4975 - val_accuracy: 0.8750\n",
      "Epoch 62/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4935 - accuracy: 0.8774 - val_loss: 0.4934 - val_accuracy: 0.8750\n",
      "Epoch 63/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.8774 - val_loss: 0.4894 - val_accuracy: 0.8750\n",
      "Epoch 64/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4853 - accuracy: 0.8774 - val_loss: 0.4853 - val_accuracy: 0.8750\n",
      "Epoch 65/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4811 - accuracy: 0.8774 - val_loss: 0.4812 - val_accuracy: 0.8750\n",
      "Epoch 66/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4770 - accuracy: 0.8774 - val_loss: 0.4772 - val_accuracy: 0.8750\n",
      "Epoch 67/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4729 - accuracy: 0.8774 - val_loss: 0.4731 - val_accuracy: 0.8750\n",
      "Epoch 68/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4687 - accuracy: 0.8774 - val_loss: 0.4690 - val_accuracy: 0.8750\n",
      "Epoch 69/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4646 - accuracy: 0.8774 - val_loss: 0.4650 - val_accuracy: 0.8750\n",
      "Epoch 70/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4605 - accuracy: 0.8774 - val_loss: 0.4609 - val_accuracy: 0.8750\n",
      "Epoch 71/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4563 - accuracy: 0.8774 - val_loss: 0.4569 - val_accuracy: 0.8750\n",
      "Epoch 72/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.8774 - val_loss: 0.4529 - val_accuracy: 0.8750\n",
      "Epoch 73/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.4482 - accuracy: 0.8774 - val_loss: 0.4489 - val_accuracy: 0.8750\n",
      "Epoch 74/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.4441 - accuracy: 0.8774 - val_loss: 0.4450 - val_accuracy: 0.8750\n",
      "Epoch 75/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4401 - accuracy: 0.8774 - val_loss: 0.4411 - val_accuracy: 0.8750\n",
      "Epoch 76/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.8774 - val_loss: 0.4372 - val_accuracy: 0.8750\n",
      "Epoch 77/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8774 - val_loss: 0.4334 - val_accuracy: 0.8750\n",
      "Epoch 78/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4284 - accuracy: 0.8774 - val_loss: 0.4297 - val_accuracy: 0.8750\n",
      "Epoch 79/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4246 - accuracy: 0.8774 - val_loss: 0.4260 - val_accuracy: 0.8750\n",
      "Epoch 80/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4209 - accuracy: 0.8774 - val_loss: 0.4224 - val_accuracy: 0.8750\n",
      "Epoch 81/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4173 - accuracy: 0.8774 - val_loss: 0.4189 - val_accuracy: 0.8750\n",
      "Epoch 82/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.4137 - accuracy: 0.8774 - val_loss: 0.4156 - val_accuracy: 0.8750\n",
      "Epoch 83/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.4103 - accuracy: 0.8774 - val_loss: 0.4123 - val_accuracy: 0.8750\n",
      "Epoch 84/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.4070 - accuracy: 0.8774 - val_loss: 0.4092 - val_accuracy: 0.8750\n",
      "Epoch 85/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.4039 - accuracy: 0.8774 - val_loss: 0.4062 - val_accuracy: 0.8750\n",
      "Epoch 86/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.4009 - accuracy: 0.8774 - val_loss: 0.4034 - val_accuracy: 0.8750\n",
      "Epoch 87/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3980 - accuracy: 0.8774 - val_loss: 0.4008 - val_accuracy: 0.8750\n",
      "Epoch 88/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3954 - accuracy: 0.8774 - val_loss: 0.3983 - val_accuracy: 0.8750\n",
      "Epoch 89/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.3928 - accuracy: 0.8774 - val_loss: 0.3960 - val_accuracy: 0.8750\n",
      "Epoch 90/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.3905 - accuracy: 0.8774 - val_loss: 0.3939 - val_accuracy: 0.8750\n",
      "Epoch 91/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3885 - accuracy: 0.8774 - val_loss: 0.3920 - val_accuracy: 0.8750\n",
      "Epoch 92/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3865 - accuracy: 0.8774 - val_loss: 0.3903 - val_accuracy: 0.8750\n",
      "Epoch 93/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3848 - accuracy: 0.8774 - val_loss: 0.3888 - val_accuracy: 0.8750\n",
      "Epoch 94/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3833 - accuracy: 0.8774 - val_loss: 0.3875 - val_accuracy: 0.8750\n",
      "Epoch 95/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3820 - accuracy: 0.8774 - val_loss: 0.3863 - val_accuracy: 0.8750\n",
      "Epoch 96/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3808 - accuracy: 0.8774 - val_loss: 0.3853 - val_accuracy: 0.8750\n",
      "Epoch 97/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3798 - accuracy: 0.8774 - val_loss: 0.3844 - val_accuracy: 0.8750\n",
      "Epoch 98/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3789 - accuracy: 0.8774 - val_loss: 0.3836 - val_accuracy: 0.8750\n",
      "Epoch 99/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3780 - accuracy: 0.8774 - val_loss: 0.3828 - val_accuracy: 0.8750\n",
      "Epoch 100/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3772 - accuracy: 0.8774 - val_loss: 0.3821 - val_accuracy: 0.8750\n",
      "Epoch 101/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3765 - accuracy: 0.8774 - val_loss: 0.3815 - val_accuracy: 0.8750\n",
      "Epoch 102/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3759 - accuracy: 0.8774 - val_loss: 0.3808 - val_accuracy: 0.8750\n",
      "Epoch 103/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3753 - accuracy: 0.8774 - val_loss: 0.3802 - val_accuracy: 0.8750\n",
      "Epoch 104/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3747 - accuracy: 0.8774 - val_loss: 0.3797 - val_accuracy: 0.8750\n",
      "Epoch 105/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3741 - accuracy: 0.8774 - val_loss: 0.3791 - val_accuracy: 0.8750\n",
      "Epoch 106/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3735 - accuracy: 0.8774 - val_loss: 0.3785 - val_accuracy: 0.8750\n",
      "Epoch 107/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3729 - accuracy: 0.8774 - val_loss: 0.3780 - val_accuracy: 0.8750\n",
      "Epoch 108/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3724 - accuracy: 0.8774 - val_loss: 0.3774 - val_accuracy: 0.8750\n",
      "Epoch 109/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3718 - accuracy: 0.8774 - val_loss: 0.3769 - val_accuracy: 0.8750\n",
      "Epoch 110/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3713 - accuracy: 0.8774 - val_loss: 0.3763 - val_accuracy: 0.8750\n",
      "Epoch 111/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3707 - accuracy: 0.8774 - val_loss: 0.3758 - val_accuracy: 0.8750\n",
      "Epoch 112/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3702 - accuracy: 0.8774 - val_loss: 0.3752 - val_accuracy: 0.8750\n",
      "Epoch 113/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3697 - accuracy: 0.8774 - val_loss: 0.3747 - val_accuracy: 0.8750\n",
      "Epoch 114/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3692 - accuracy: 0.8774 - val_loss: 0.3742 - val_accuracy: 0.8750\n",
      "Epoch 115/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3686 - accuracy: 0.8774 - val_loss: 0.3736 - val_accuracy: 0.8750\n",
      "Epoch 116/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3681 - accuracy: 0.8774 - val_loss: 0.3731 - val_accuracy: 0.8750\n",
      "Epoch 117/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3676 - accuracy: 0.8774 - val_loss: 0.3726 - val_accuracy: 0.8750\n",
      "Epoch 118/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3671 - accuracy: 0.8774 - val_loss: 0.3721 - val_accuracy: 0.8750\n",
      "Epoch 119/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3666 - accuracy: 0.8774 - val_loss: 0.3716 - val_accuracy: 0.8750\n",
      "Epoch 120/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3661 - accuracy: 0.8774 - val_loss: 0.3711 - val_accuracy: 0.8750\n",
      "Epoch 121/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3656 - accuracy: 0.8774 - val_loss: 0.3706 - val_accuracy: 0.8750\n",
      "Epoch 122/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3651 - accuracy: 0.8774 - val_loss: 0.3700 - val_accuracy: 0.8750\n",
      "Epoch 123/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3646 - accuracy: 0.8774 - val_loss: 0.3695 - val_accuracy: 0.8750\n",
      "Epoch 124/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3641 - accuracy: 0.8774 - val_loss: 0.3690 - val_accuracy: 0.8750\n",
      "Epoch 125/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3636 - accuracy: 0.8774 - val_loss: 0.3685 - val_accuracy: 0.8750\n",
      "Epoch 126/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3631 - accuracy: 0.8774 - val_loss: 0.3680 - val_accuracy: 0.8750\n",
      "Epoch 127/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3626 - accuracy: 0.8774 - val_loss: 0.3675 - val_accuracy: 0.8750\n",
      "Epoch 128/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3621 - accuracy: 0.8774 - val_loss: 0.3670 - val_accuracy: 0.8750\n",
      "Epoch 129/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3616 - accuracy: 0.8774 - val_loss: 0.3665 - val_accuracy: 0.8750\n",
      "Epoch 130/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3611 - accuracy: 0.8774 - val_loss: 0.3660 - val_accuracy: 0.8750\n",
      "Epoch 131/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3606 - accuracy: 0.8774 - val_loss: 0.3655 - val_accuracy: 0.8750\n",
      "Epoch 132/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3601 - accuracy: 0.8774 - val_loss: 0.3649 - val_accuracy: 0.8750\n",
      "Epoch 133/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3596 - accuracy: 0.8774 - val_loss: 0.3644 - val_accuracy: 0.8750\n",
      "Epoch 134/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3591 - accuracy: 0.8774 - val_loss: 0.3639 - val_accuracy: 0.8750\n",
      "Epoch 135/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3586 - accuracy: 0.8774 - val_loss: 0.3634 - val_accuracy: 0.8750\n",
      "Epoch 136/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3581 - accuracy: 0.8774 - val_loss: 0.3629 - val_accuracy: 0.8750\n",
      "Epoch 137/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3576 - accuracy: 0.8774 - val_loss: 0.3624 - val_accuracy: 0.8750\n",
      "Epoch 138/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3571 - accuracy: 0.8774 - val_loss: 0.3619 - val_accuracy: 0.8750\n",
      "Epoch 139/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3566 - accuracy: 0.8774 - val_loss: 0.3614 - val_accuracy: 0.8750\n",
      "Epoch 140/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3561 - accuracy: 0.8774 - val_loss: 0.3609 - val_accuracy: 0.8750\n",
      "Epoch 141/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3556 - accuracy: 0.8774 - val_loss: 0.3604 - val_accuracy: 0.8750\n",
      "Epoch 142/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3551 - accuracy: 0.8774 - val_loss: 0.3599 - val_accuracy: 0.8750\n",
      "Epoch 143/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3546 - accuracy: 0.8774 - val_loss: 0.3593 - val_accuracy: 0.8750\n",
      "Epoch 144/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3541 - accuracy: 0.8774 - val_loss: 0.3588 - val_accuracy: 0.8750\n",
      "Epoch 145/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3536 - accuracy: 0.8774 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
      "Epoch 146/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8774 - val_loss: 0.3578 - val_accuracy: 0.8750\n",
      "Epoch 147/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3526 - accuracy: 0.8774 - val_loss: 0.3573 - val_accuracy: 0.8750\n",
      "Epoch 148/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3521 - accuracy: 0.8774 - val_loss: 0.3567 - val_accuracy: 0.8750\n",
      "Epoch 149/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3516 - accuracy: 0.8774 - val_loss: 0.3562 - val_accuracy: 0.8750\n",
      "Epoch 150/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.3511 - accuracy: 0.8774 - val_loss: 0.3557 - val_accuracy: 0.8750\n",
      "Epoch 151/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3506 - accuracy: 0.8774 - val_loss: 0.3552 - val_accuracy: 0.8750\n",
      "Epoch 152/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3501 - accuracy: 0.8774 - val_loss: 0.3547 - val_accuracy: 0.8750\n",
      "Epoch 153/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3495 - accuracy: 0.8774 - val_loss: 0.3541 - val_accuracy: 0.8750\n",
      "Epoch 154/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3490 - accuracy: 0.8774 - val_loss: 0.3536 - val_accuracy: 0.8750\n",
      "Epoch 155/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3485 - accuracy: 0.8774 - val_loss: 0.3531 - val_accuracy: 0.8750\n",
      "Epoch 156/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3480 - accuracy: 0.8774 - val_loss: 0.3526 - val_accuracy: 0.8750\n",
      "Epoch 157/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3475 - accuracy: 0.8774 - val_loss: 0.3520 - val_accuracy: 0.8750\n",
      "Epoch 158/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3470 - accuracy: 0.8774 - val_loss: 0.3515 - val_accuracy: 0.8750\n",
      "Epoch 159/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3465 - accuracy: 0.8774 - val_loss: 0.3510 - val_accuracy: 0.8750\n",
      "Epoch 160/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3459 - accuracy: 0.8774 - val_loss: 0.3505 - val_accuracy: 0.8750\n",
      "Epoch 161/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3454 - accuracy: 0.8774 - val_loss: 0.3499 - val_accuracy: 0.8750\n",
      "Epoch 162/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3449 - accuracy: 0.8774 - val_loss: 0.3494 - val_accuracy: 0.8750\n",
      "Epoch 163/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3444 - accuracy: 0.8774 - val_loss: 0.3488 - val_accuracy: 0.8750\n",
      "Epoch 164/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3438 - accuracy: 0.8774 - val_loss: 0.3483 - val_accuracy: 0.8750\n",
      "Epoch 165/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3433 - accuracy: 0.8774 - val_loss: 0.3477 - val_accuracy: 0.8750\n",
      "Epoch 166/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3427 - accuracy: 0.8774 - val_loss: 0.3472 - val_accuracy: 0.8750\n",
      "Epoch 167/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3422 - accuracy: 0.8774 - val_loss: 0.3466 - val_accuracy: 0.8750\n",
      "Epoch 168/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3417 - accuracy: 0.8774 - val_loss: 0.3460 - val_accuracy: 0.8750\n",
      "Epoch 169/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3411 - accuracy: 0.8774 - val_loss: 0.3455 - val_accuracy: 0.8750\n",
      "Epoch 170/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3406 - accuracy: 0.8774 - val_loss: 0.3449 - val_accuracy: 0.8750\n",
      "Epoch 171/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3400 - accuracy: 0.8774 - val_loss: 0.3444 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3395 - accuracy: 0.8774 - val_loss: 0.3438 - val_accuracy: 0.8750\n",
      "Epoch 173/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.8774 - val_loss: 0.3433 - val_accuracy: 0.8750\n",
      "Epoch 174/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.8774 - val_loss: 0.3427 - val_accuracy: 0.8750\n",
      "Epoch 175/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3378 - accuracy: 0.8774 - val_loss: 0.3421 - val_accuracy: 0.8750\n",
      "Epoch 176/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3373 - accuracy: 0.8774 - val_loss: 0.3416 - val_accuracy: 0.8750\n",
      "Epoch 177/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3368 - accuracy: 0.8774 - val_loss: 0.3410 - val_accuracy: 0.8750\n",
      "Epoch 178/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3362 - accuracy: 0.8774 - val_loss: 0.3404 - val_accuracy: 0.8750\n",
      "Epoch 179/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3356 - accuracy: 0.8774 - val_loss: 0.3398 - val_accuracy: 0.8750\n",
      "Epoch 180/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3350 - accuracy: 0.8774 - val_loss: 0.3393 - val_accuracy: 0.8750\n",
      "Epoch 181/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3345 - accuracy: 0.8774 - val_loss: 0.3387 - val_accuracy: 0.8750\n",
      "Epoch 182/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3339 - accuracy: 0.8774 - val_loss: 0.3381 - val_accuracy: 0.8750\n",
      "Epoch 183/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3333 - accuracy: 0.8774 - val_loss: 0.3375 - val_accuracy: 0.8750\n",
      "Epoch 184/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3327 - accuracy: 0.8774 - val_loss: 0.3369 - val_accuracy: 0.8750\n",
      "Epoch 185/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3322 - accuracy: 0.8774 - val_loss: 0.3363 - val_accuracy: 0.8750\n",
      "Epoch 186/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3316 - accuracy: 0.8774 - val_loss: 0.3357 - val_accuracy: 0.8750\n",
      "Epoch 187/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3310 - accuracy: 0.8774 - val_loss: 0.3351 - val_accuracy: 0.8750\n",
      "Epoch 188/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3305 - accuracy: 0.8774 - val_loss: 0.3345 - val_accuracy: 0.8750\n",
      "Epoch 189/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3299 - accuracy: 0.8774 - val_loss: 0.3339 - val_accuracy: 0.8750\n",
      "Epoch 190/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3293 - accuracy: 0.8774 - val_loss: 0.3333 - val_accuracy: 0.8750\n",
      "Epoch 191/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3287 - accuracy: 0.8774 - val_loss: 0.3327 - val_accuracy: 0.8750\n",
      "Epoch 192/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3281 - accuracy: 0.8774 - val_loss: 0.3321 - val_accuracy: 0.8750\n",
      "Epoch 193/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3275 - accuracy: 0.8774 - val_loss: 0.3315 - val_accuracy: 0.8750\n",
      "Epoch 194/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3269 - accuracy: 0.8774 - val_loss: 0.3309 - val_accuracy: 0.8750\n",
      "Epoch 195/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3263 - accuracy: 0.8774 - val_loss: 0.3302 - val_accuracy: 0.8750\n",
      "Epoch 196/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3257 - accuracy: 0.8774 - val_loss: 0.3296 - val_accuracy: 0.8750\n",
      "Epoch 197/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3251 - accuracy: 0.8774 - val_loss: 0.3290 - val_accuracy: 0.8750\n",
      "Epoch 198/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3244 - accuracy: 0.8774 - val_loss: 0.3284 - val_accuracy: 0.8750\n",
      "Epoch 199/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3238 - accuracy: 0.8774 - val_loss: 0.3278 - val_accuracy: 0.8750\n",
      "Epoch 200/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3232 - accuracy: 0.8774 - val_loss: 0.3271 - val_accuracy: 0.8750\n",
      "Epoch 201/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3226 - accuracy: 0.8774 - val_loss: 0.3265 - val_accuracy: 0.8750\n",
      "Epoch 202/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3220 - accuracy: 0.8774 - val_loss: 0.3258 - val_accuracy: 0.8750\n",
      "Epoch 203/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3213 - accuracy: 0.8774 - val_loss: 0.3251 - val_accuracy: 0.8750\n",
      "Epoch 204/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3207 - accuracy: 0.8774 - val_loss: 0.3245 - val_accuracy: 0.8750\n",
      "Epoch 205/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3200 - accuracy: 0.8774 - val_loss: 0.3238 - val_accuracy: 0.8750\n",
      "Epoch 206/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3194 - accuracy: 0.8774 - val_loss: 0.3231 - val_accuracy: 0.8750\n",
      "Epoch 207/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3187 - accuracy: 0.8774 - val_loss: 0.3225 - val_accuracy: 0.8750\n",
      "Epoch 208/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.8774 - val_loss: 0.3218 - val_accuracy: 0.8750\n",
      "Epoch 209/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3174 - accuracy: 0.8774 - val_loss: 0.3211 - val_accuracy: 0.8750\n",
      "Epoch 210/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3168 - accuracy: 0.8774 - val_loss: 0.3204 - val_accuracy: 0.8750\n",
      "Epoch 211/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3161 - accuracy: 0.8774 - val_loss: 0.3198 - val_accuracy: 0.8750\n",
      "Epoch 212/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3154 - accuracy: 0.8774 - val_loss: 0.3191 - val_accuracy: 0.8750\n",
      "Epoch 213/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3147 - accuracy: 0.8774 - val_loss: 0.3184 - val_accuracy: 0.8750\n",
      "Epoch 214/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3141 - accuracy: 0.8774 - val_loss: 0.3177 - val_accuracy: 0.8750\n",
      "Epoch 215/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3134 - accuracy: 0.8774 - val_loss: 0.3170 - val_accuracy: 0.8750\n",
      "Epoch 216/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3127 - accuracy: 0.8774 - val_loss: 0.3163 - val_accuracy: 0.8750\n",
      "Epoch 217/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3120 - accuracy: 0.8774 - val_loss: 0.3155 - val_accuracy: 0.8750\n",
      "Epoch 218/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8774 - val_loss: 0.3148 - val_accuracy: 0.8750\n",
      "Epoch 219/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3106 - accuracy: 0.8774 - val_loss: 0.3141 - val_accuracy: 0.8750\n",
      "Epoch 220/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3099 - accuracy: 0.8774 - val_loss: 0.3134 - val_accuracy: 0.8750\n",
      "Epoch 221/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3092 - accuracy: 0.8774 - val_loss: 0.3127 - val_accuracy: 0.8750\n",
      "Epoch 222/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3085 - accuracy: 0.8774 - val_loss: 0.3120 - val_accuracy: 0.8750\n",
      "Epoch 223/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3078 - accuracy: 0.8774 - val_loss: 0.3112 - val_accuracy: 0.8750\n",
      "Epoch 224/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3071 - accuracy: 0.8774 - val_loss: 0.3105 - val_accuracy: 0.8750\n",
      "Epoch 225/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3064 - accuracy: 0.8774 - val_loss: 0.3098 - val_accuracy: 0.8750\n",
      "Epoch 226/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3057 - accuracy: 0.8774 - val_loss: 0.3090 - val_accuracy: 0.8750\n",
      "Epoch 227/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3050 - accuracy: 0.8774 - val_loss: 0.3083 - val_accuracy: 0.8750\n",
      "Epoch 228/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.3043 - accuracy: 0.8774 - val_loss: 0.3076 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3035 - accuracy: 0.8774 - val_loss: 0.3068 - val_accuracy: 0.8750\n",
      "Epoch 230/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3028 - accuracy: 0.8774 - val_loss: 0.3061 - val_accuracy: 0.8750\n",
      "Epoch 231/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3021 - accuracy: 0.8774 - val_loss: 0.3053 - val_accuracy: 0.8750\n",
      "Epoch 232/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3013 - accuracy: 0.8774 - val_loss: 0.3045 - val_accuracy: 0.8750\n",
      "Epoch 233/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.3006 - accuracy: 0.8774 - val_loss: 0.3038 - val_accuracy: 0.8750\n",
      "Epoch 234/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2998 - accuracy: 0.8774 - val_loss: 0.3030 - val_accuracy: 0.8750\n",
      "Epoch 235/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2991 - accuracy: 0.8774 - val_loss: 0.3022 - val_accuracy: 0.8750\n",
      "Epoch 236/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2983 - accuracy: 0.8774 - val_loss: 0.3014 - val_accuracy: 0.8750\n",
      "Epoch 237/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2976 - accuracy: 0.8774 - val_loss: 0.3006 - val_accuracy: 0.8750\n",
      "Epoch 238/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2968 - accuracy: 0.8774 - val_loss: 0.2999 - val_accuracy: 0.8750\n",
      "Epoch 239/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2960 - accuracy: 0.8774 - val_loss: 0.2991 - val_accuracy: 0.8750\n",
      "Epoch 240/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2953 - accuracy: 0.8774 - val_loss: 0.2983 - val_accuracy: 0.8750\n",
      "Epoch 241/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2945 - accuracy: 0.8774 - val_loss: 0.2974 - val_accuracy: 0.8750\n",
      "Epoch 242/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2937 - accuracy: 0.8774 - val_loss: 0.2966 - val_accuracy: 0.8750\n",
      "Epoch 243/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2929 - accuracy: 0.8774 - val_loss: 0.2958 - val_accuracy: 0.8750\n",
      "Epoch 244/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2921 - accuracy: 0.8774 - val_loss: 0.2949 - val_accuracy: 0.8750\n",
      "Epoch 245/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2912 - accuracy: 0.8774 - val_loss: 0.2940 - val_accuracy: 0.8750\n",
      "Epoch 246/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2904 - accuracy: 0.8774 - val_loss: 0.2932 - val_accuracy: 0.8750\n",
      "Epoch 247/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2895 - accuracy: 0.8774 - val_loss: 0.2923 - val_accuracy: 0.8750\n",
      "Epoch 248/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2887 - accuracy: 0.8774 - val_loss: 0.2914 - val_accuracy: 0.8750\n",
      "Epoch 249/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2878 - accuracy: 0.8774 - val_loss: 0.2905 - val_accuracy: 0.8750\n",
      "Epoch 250/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2869 - accuracy: 0.8774 - val_loss: 0.2896 - val_accuracy: 0.8750\n",
      "Epoch 251/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2860 - accuracy: 0.8774 - val_loss: 0.2886 - val_accuracy: 0.8750\n",
      "Epoch 252/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2852 - accuracy: 0.8774 - val_loss: 0.2877 - val_accuracy: 0.8750\n",
      "Epoch 253/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2843 - accuracy: 0.8774 - val_loss: 0.2868 - val_accuracy: 0.8750\n",
      "Epoch 254/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2834 - accuracy: 0.8774 - val_loss: 0.2859 - val_accuracy: 0.8750\n",
      "Epoch 255/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2825 - accuracy: 0.8774 - val_loss: 0.2850 - val_accuracy: 0.8750\n",
      "Epoch 256/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2816 - accuracy: 0.8774 - val_loss: 0.2840 - val_accuracy: 0.8750\n",
      "Epoch 257/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2807 - accuracy: 0.8774 - val_loss: 0.2831 - val_accuracy: 0.8750\n",
      "Epoch 258/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2797 - accuracy: 0.8774 - val_loss: 0.2821 - val_accuracy: 0.8750\n",
      "Epoch 259/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2788 - accuracy: 0.8774 - val_loss: 0.2811 - val_accuracy: 0.8750\n",
      "Epoch 260/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2778 - accuracy: 0.8774 - val_loss: 0.2801 - val_accuracy: 0.8750\n",
      "Epoch 261/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2769 - accuracy: 0.8774 - val_loss: 0.2791 - val_accuracy: 0.8750\n",
      "Epoch 262/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2759 - accuracy: 0.8774 - val_loss: 0.2781 - val_accuracy: 0.8750\n",
      "Epoch 263/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2749 - accuracy: 0.8774 - val_loss: 0.2771 - val_accuracy: 0.8750\n",
      "Epoch 264/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2740 - accuracy: 0.8774 - val_loss: 0.2761 - val_accuracy: 0.8750\n",
      "Epoch 265/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2730 - accuracy: 0.8774 - val_loss: 0.2750 - val_accuracy: 0.8750\n",
      "Epoch 266/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2720 - accuracy: 0.8774 - val_loss: 0.2740 - val_accuracy: 0.8750\n",
      "Epoch 267/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2710 - accuracy: 0.8774 - val_loss: 0.2730 - val_accuracy: 0.8750\n",
      "Epoch 268/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2700 - accuracy: 0.8774 - val_loss: 0.2720 - val_accuracy: 0.8750\n",
      "Epoch 269/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2691 - accuracy: 0.8774 - val_loss: 0.2710 - val_accuracy: 0.8750\n",
      "Epoch 270/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.8774 - val_loss: 0.2700 - val_accuracy: 0.8750\n",
      "Epoch 271/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2672 - accuracy: 0.8774 - val_loss: 0.2690 - val_accuracy: 0.8750\n",
      "Epoch 272/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2662 - accuracy: 0.8774 - val_loss: 0.2680 - val_accuracy: 0.8750\n",
      "Epoch 273/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2652 - accuracy: 0.8774 - val_loss: 0.2670 - val_accuracy: 0.8750\n",
      "Epoch 274/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2643 - accuracy: 0.8774 - val_loss: 0.2660 - val_accuracy: 0.8750\n",
      "Epoch 275/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2633 - accuracy: 0.8774 - val_loss: 0.2650 - val_accuracy: 0.8750\n",
      "Epoch 276/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2623 - accuracy: 0.8774 - val_loss: 0.2640 - val_accuracy: 0.8750\n",
      "Epoch 277/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2614 - accuracy: 0.8774 - val_loss: 0.2630 - val_accuracy: 0.8750\n",
      "Epoch 278/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2604 - accuracy: 0.8774 - val_loss: 0.2620 - val_accuracy: 0.8750\n",
      "Epoch 279/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2594 - accuracy: 0.8774 - val_loss: 0.2610 - val_accuracy: 0.8750\n",
      "Epoch 280/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2585 - accuracy: 0.8774 - val_loss: 0.2600 - val_accuracy: 0.8750\n",
      "Epoch 281/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2575 - accuracy: 0.8774 - val_loss: 0.2590 - val_accuracy: 0.8750\n",
      "Epoch 282/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2565 - accuracy: 0.8774 - val_loss: 0.2580 - val_accuracy: 0.8750\n",
      "Epoch 283/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2556 - accuracy: 0.8774 - val_loss: 0.2571 - val_accuracy: 0.8750\n",
      "Epoch 284/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2546 - accuracy: 0.8774 - val_loss: 0.2560 - val_accuracy: 0.8750\n",
      "Epoch 285/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.2536 - accuracy: 0.8774 - val_loss: 0.2550 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2527 - accuracy: 0.8774 - val_loss: 0.2540 - val_accuracy: 0.8750\n",
      "Epoch 287/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2517 - accuracy: 0.8774 - val_loss: 0.2530 - val_accuracy: 0.8750\n",
      "Epoch 288/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2507 - accuracy: 0.8774 - val_loss: 0.2520 - val_accuracy: 0.8750\n",
      "Epoch 289/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2497 - accuracy: 0.8774 - val_loss: 0.2510 - val_accuracy: 0.8750\n",
      "Epoch 290/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2488 - accuracy: 0.8774 - val_loss: 0.2500 - val_accuracy: 0.8750\n",
      "Epoch 291/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2478 - accuracy: 0.8774 - val_loss: 0.2489 - val_accuracy: 0.8750\n",
      "Epoch 292/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2468 - accuracy: 0.8774 - val_loss: 0.2479 - val_accuracy: 0.8750\n",
      "Epoch 293/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2458 - accuracy: 0.8774 - val_loss: 0.2469 - val_accuracy: 0.8750\n",
      "Epoch 294/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2448 - accuracy: 0.8774 - val_loss: 0.2459 - val_accuracy: 0.8750\n",
      "Epoch 295/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2439 - accuracy: 0.8774 - val_loss: 0.2449 - val_accuracy: 0.8750\n",
      "Epoch 296/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2429 - accuracy: 0.8774 - val_loss: 0.2439 - val_accuracy: 0.8750\n",
      "Epoch 297/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2419 - accuracy: 0.8774 - val_loss: 0.2429 - val_accuracy: 0.8751\n",
      "Epoch 298/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2409 - accuracy: 0.8775 - val_loss: 0.2419 - val_accuracy: 0.8754\n",
      "Epoch 299/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 0.2408 - val_accuracy: 0.8757\n",
      "Epoch 300/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2390 - accuracy: 0.8781 - val_loss: 0.2398 - val_accuracy: 0.8762\n",
      "Epoch 301/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2380 - accuracy: 0.8789 - val_loss: 0.2388 - val_accuracy: 0.8781\n",
      "Epoch 302/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2370 - accuracy: 0.8797 - val_loss: 0.2377 - val_accuracy: 0.8796\n",
      "Epoch 303/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2360 - accuracy: 0.8809 - val_loss: 0.2367 - val_accuracy: 0.8802\n",
      "Epoch 304/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2350 - accuracy: 0.8820 - val_loss: 0.2357 - val_accuracy: 0.8806\n",
      "Epoch 305/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2340 - accuracy: 0.8835 - val_loss: 0.2346 - val_accuracy: 0.8820\n",
      "Epoch 306/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2330 - accuracy: 0.8853 - val_loss: 0.2336 - val_accuracy: 0.8848\n",
      "Epoch 307/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2319 - accuracy: 0.8860 - val_loss: 0.2326 - val_accuracy: 0.8867\n",
      "Epoch 308/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2309 - accuracy: 0.8872 - val_loss: 0.2315 - val_accuracy: 0.8879\n",
      "Epoch 309/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2299 - accuracy: 0.8882 - val_loss: 0.2304 - val_accuracy: 0.8883\n",
      "Epoch 310/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2289 - accuracy: 0.8896 - val_loss: 0.2294 - val_accuracy: 0.8888\n",
      "Epoch 311/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2278 - accuracy: 0.8905 - val_loss: 0.2283 - val_accuracy: 0.8892\n",
      "Epoch 312/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2268 - accuracy: 0.8916 - val_loss: 0.2272 - val_accuracy: 0.8910\n",
      "Epoch 313/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2258 - accuracy: 0.8930 - val_loss: 0.2262 - val_accuracy: 0.8911\n",
      "Epoch 314/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2248 - accuracy: 0.8937 - val_loss: 0.2252 - val_accuracy: 0.8923\n",
      "Epoch 315/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2238 - accuracy: 0.8949 - val_loss: 0.2241 - val_accuracy: 0.8932\n",
      "Epoch 316/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2228 - accuracy: 0.8950 - val_loss: 0.2231 - val_accuracy: 0.8928\n",
      "Epoch 317/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2219 - accuracy: 0.8948 - val_loss: 0.2221 - val_accuracy: 0.8936\n",
      "Epoch 318/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2209 - accuracy: 0.8950 - val_loss: 0.2211 - val_accuracy: 0.8944\n",
      "Epoch 319/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2199 - accuracy: 0.8948 - val_loss: 0.2200 - val_accuracy: 0.8947\n",
      "Epoch 320/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2188 - accuracy: 0.8948 - val_loss: 0.2190 - val_accuracy: 0.8943\n",
      "Epoch 321/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2178 - accuracy: 0.8953 - val_loss: 0.2180 - val_accuracy: 0.8944\n",
      "Epoch 322/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2169 - accuracy: 0.8958 - val_loss: 0.2169 - val_accuracy: 0.8948\n",
      "Epoch 323/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2159 - accuracy: 0.8964 - val_loss: 0.2159 - val_accuracy: 0.8946\n",
      "Epoch 324/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2149 - accuracy: 0.8973 - val_loss: 0.2149 - val_accuracy: 0.8954\n",
      "Epoch 325/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2139 - accuracy: 0.8974 - val_loss: 0.2139 - val_accuracy: 0.8963\n",
      "Epoch 326/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2129 - accuracy: 0.8975 - val_loss: 0.2129 - val_accuracy: 0.8972\n",
      "Epoch 327/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2119 - accuracy: 0.8979 - val_loss: 0.2119 - val_accuracy: 0.8978\n",
      "Epoch 328/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2110 - accuracy: 0.8983 - val_loss: 0.2109 - val_accuracy: 0.8979\n",
      "Epoch 329/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2100 - accuracy: 0.8988 - val_loss: 0.2099 - val_accuracy: 0.8980\n",
      "Epoch 330/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.2091 - accuracy: 0.8995 - val_loss: 0.2089 - val_accuracy: 0.8985\n",
      "Epoch 331/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2082 - accuracy: 0.8997 - val_loss: 0.2080 - val_accuracy: 0.8988\n",
      "Epoch 332/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2072 - accuracy: 0.8998 - val_loss: 0.2070 - val_accuracy: 0.8989\n",
      "Epoch 333/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2063 - accuracy: 0.9002 - val_loss: 0.2060 - val_accuracy: 0.8996\n",
      "Epoch 334/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2054 - accuracy: 0.9006 - val_loss: 0.2051 - val_accuracy: 0.9001\n",
      "Epoch 335/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2045 - accuracy: 0.9010 - val_loss: 0.2041 - val_accuracy: 0.9005\n",
      "Epoch 336/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2036 - accuracy: 0.9014 - val_loss: 0.2032 - val_accuracy: 0.9013\n",
      "Epoch 337/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2027 - accuracy: 0.9017 - val_loss: 0.2023 - val_accuracy: 0.9015\n",
      "Epoch 338/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.2018 - accuracy: 0.9021 - val_loss: 0.2013 - val_accuracy: 0.9023\n",
      "Epoch 339/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2008 - accuracy: 0.9024 - val_loss: 0.2004 - val_accuracy: 0.9033\n",
      "Epoch 340/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.2000 - accuracy: 0.9027 - val_loss: 0.1995 - val_accuracy: 0.9035\n",
      "Epoch 341/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1991 - accuracy: 0.9032 - val_loss: 0.1986 - val_accuracy: 0.9033\n",
      "Epoch 342/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1982 - accuracy: 0.9036 - val_loss: 0.1977 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1973 - accuracy: 0.9041 - val_loss: 0.1968 - val_accuracy: 0.9035\n",
      "Epoch 344/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1965 - accuracy: 0.9046 - val_loss: 0.1959 - val_accuracy: 0.9044\n",
      "Epoch 345/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1956 - accuracy: 0.9053 - val_loss: 0.1950 - val_accuracy: 0.9049\n",
      "Epoch 346/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1947 - accuracy: 0.9058 - val_loss: 0.1941 - val_accuracy: 0.9057\n",
      "Epoch 347/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1939 - accuracy: 0.9065 - val_loss: 0.1933 - val_accuracy: 0.9060\n",
      "Epoch 348/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1930 - accuracy: 0.9073 - val_loss: 0.1924 - val_accuracy: 0.9066\n",
      "Epoch 349/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1922 - accuracy: 0.9077 - val_loss: 0.1916 - val_accuracy: 0.9075\n",
      "Epoch 350/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.1914 - accuracy: 0.9081 - val_loss: 0.1907 - val_accuracy: 0.9081\n",
      "Epoch 351/2048\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.1906 - accuracy: 0.9085 - val_loss: 0.1899 - val_accuracy: 0.9084\n",
      "Epoch 352/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1898 - accuracy: 0.9092 - val_loss: 0.1891 - val_accuracy: 0.9090\n",
      "Epoch 353/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1890 - accuracy: 0.9098 - val_loss: 0.1882 - val_accuracy: 0.9092\n",
      "Epoch 354/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1882 - accuracy: 0.9102 - val_loss: 0.1874 - val_accuracy: 0.9100\n",
      "Epoch 355/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1874 - accuracy: 0.9110 - val_loss: 0.1866 - val_accuracy: 0.9102\n",
      "Epoch 356/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1866 - accuracy: 0.9116 - val_loss: 0.1858 - val_accuracy: 0.9106\n",
      "Epoch 357/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1858 - accuracy: 0.9120 - val_loss: 0.1850 - val_accuracy: 0.9110\n",
      "Epoch 358/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1850 - accuracy: 0.9122 - val_loss: 0.1842 - val_accuracy: 0.9114\n",
      "Epoch 359/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1842 - accuracy: 0.9128 - val_loss: 0.1834 - val_accuracy: 0.9122\n",
      "Epoch 360/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1835 - accuracy: 0.9133 - val_loss: 0.1826 - val_accuracy: 0.9126\n",
      "Epoch 361/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1827 - accuracy: 0.9137 - val_loss: 0.1819 - val_accuracy: 0.9128\n",
      "Epoch 362/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1820 - accuracy: 0.9144 - val_loss: 0.1812 - val_accuracy: 0.9139\n",
      "Epoch 363/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.1813 - accuracy: 0.9149 - val_loss: 0.1804 - val_accuracy: 0.9146\n",
      "Epoch 364/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.1806 - accuracy: 0.9151 - val_loss: 0.1797 - val_accuracy: 0.9145\n",
      "Epoch 365/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.1798 - accuracy: 0.9154 - val_loss: 0.1789 - val_accuracy: 0.9150\n",
      "Epoch 366/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1791 - accuracy: 0.9159 - val_loss: 0.1782 - val_accuracy: 0.9157\n",
      "Epoch 367/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1784 - accuracy: 0.9162 - val_loss: 0.1775 - val_accuracy: 0.9164\n",
      "Epoch 368/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1777 - accuracy: 0.9165 - val_loss: 0.1768 - val_accuracy: 0.9165\n",
      "Epoch 369/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1771 - accuracy: 0.9167 - val_loss: 0.1761 - val_accuracy: 0.9172\n",
      "Epoch 370/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1764 - accuracy: 0.9167 - val_loss: 0.1755 - val_accuracy: 0.9173\n",
      "Epoch 371/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1757 - accuracy: 0.9171 - val_loss: 0.1748 - val_accuracy: 0.9177\n",
      "Epoch 372/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1750 - accuracy: 0.9175 - val_loss: 0.1741 - val_accuracy: 0.9180\n",
      "Epoch 373/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1744 - accuracy: 0.9180 - val_loss: 0.1735 - val_accuracy: 0.9179\n",
      "Epoch 374/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1737 - accuracy: 0.9182 - val_loss: 0.1728 - val_accuracy: 0.9180\n",
      "Epoch 375/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1731 - accuracy: 0.9182 - val_loss: 0.1722 - val_accuracy: 0.9184\n",
      "Epoch 376/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1724 - accuracy: 0.9184 - val_loss: 0.1715 - val_accuracy: 0.9183\n",
      "Epoch 377/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1718 - accuracy: 0.9186 - val_loss: 0.1709 - val_accuracy: 0.9185\n",
      "Epoch 378/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1712 - accuracy: 0.9190 - val_loss: 0.1703 - val_accuracy: 0.9193\n",
      "Epoch 379/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1706 - accuracy: 0.9194 - val_loss: 0.1697 - val_accuracy: 0.9195\n",
      "Epoch 380/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1700 - accuracy: 0.9197 - val_loss: 0.1691 - val_accuracy: 0.9195\n",
      "Epoch 381/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1693 - accuracy: 0.9199 - val_loss: 0.1685 - val_accuracy: 0.9193\n",
      "Epoch 382/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1687 - accuracy: 0.9204 - val_loss: 0.1678 - val_accuracy: 0.9195\n",
      "Epoch 383/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1681 - accuracy: 0.9206 - val_loss: 0.1673 - val_accuracy: 0.9203\n",
      "Epoch 384/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1676 - accuracy: 0.9209 - val_loss: 0.1667 - val_accuracy: 0.9207\n",
      "Epoch 385/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1670 - accuracy: 0.9213 - val_loss: 0.1661 - val_accuracy: 0.9208\n",
      "Epoch 386/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1664 - accuracy: 0.9215 - val_loss: 0.1655 - val_accuracy: 0.9210\n",
      "Epoch 387/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1658 - accuracy: 0.9216 - val_loss: 0.1649 - val_accuracy: 0.9213\n",
      "Epoch 388/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.9221 - val_loss: 0.1644 - val_accuracy: 0.9217\n",
      "Epoch 389/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1647 - accuracy: 0.9223 - val_loss: 0.1638 - val_accuracy: 0.9216\n",
      "Epoch 390/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1641 - accuracy: 0.9226 - val_loss: 0.1633 - val_accuracy: 0.9220\n",
      "Epoch 391/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1635 - accuracy: 0.9230 - val_loss: 0.1628 - val_accuracy: 0.9221\n",
      "Epoch 392/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1630 - accuracy: 0.9232 - val_loss: 0.1622 - val_accuracy: 0.9224\n",
      "Epoch 393/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1625 - accuracy: 0.9234 - val_loss: 0.1617 - val_accuracy: 0.9231\n",
      "Epoch 394/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1619 - accuracy: 0.9237 - val_loss: 0.1612 - val_accuracy: 0.9239\n",
      "Epoch 395/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1614 - accuracy: 0.9241 - val_loss: 0.1606 - val_accuracy: 0.9244\n",
      "Epoch 396/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1608 - accuracy: 0.9244 - val_loss: 0.1601 - val_accuracy: 0.9245\n",
      "Epoch 397/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.1603 - accuracy: 0.9246 - val_loss: 0.1596 - val_accuracy: 0.9247\n",
      "Epoch 398/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1598 - accuracy: 0.9248 - val_loss: 0.1591 - val_accuracy: 0.9249\n",
      "Epoch 399/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1593 - accuracy: 0.9249 - val_loss: 0.1586 - val_accuracy: 0.9252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1587 - accuracy: 0.9252 - val_loss: 0.1581 - val_accuracy: 0.9249\n",
      "Epoch 401/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1582 - accuracy: 0.9255 - val_loss: 0.1576 - val_accuracy: 0.9255\n",
      "Epoch 402/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1577 - accuracy: 0.9257 - val_loss: 0.1571 - val_accuracy: 0.9253\n",
      "Epoch 403/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1572 - accuracy: 0.9261 - val_loss: 0.1566 - val_accuracy: 0.9257\n",
      "Epoch 404/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1567 - accuracy: 0.9263 - val_loss: 0.1561 - val_accuracy: 0.9262\n",
      "Epoch 405/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1562 - accuracy: 0.9265 - val_loss: 0.1556 - val_accuracy: 0.9263\n",
      "Epoch 406/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1557 - accuracy: 0.9268 - val_loss: 0.1551 - val_accuracy: 0.9264\n",
      "Epoch 407/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1551 - accuracy: 0.9272 - val_loss: 0.1546 - val_accuracy: 0.9266\n",
      "Epoch 408/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1546 - accuracy: 0.9272 - val_loss: 0.1541 - val_accuracy: 0.9272\n",
      "Epoch 409/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1541 - accuracy: 0.9275 - val_loss: 0.1536 - val_accuracy: 0.9275\n",
      "Epoch 410/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1536 - accuracy: 0.9277 - val_loss: 0.1532 - val_accuracy: 0.9280\n",
      "Epoch 411/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1531 - accuracy: 0.9280 - val_loss: 0.1527 - val_accuracy: 0.9283\n",
      "Epoch 412/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1526 - accuracy: 0.9283 - val_loss: 0.1522 - val_accuracy: 0.9286\n",
      "Epoch 413/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1521 - accuracy: 0.9286 - val_loss: 0.1517 - val_accuracy: 0.9286\n",
      "Epoch 414/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1516 - accuracy: 0.9287 - val_loss: 0.1513 - val_accuracy: 0.9287\n",
      "Epoch 415/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1511 - accuracy: 0.9289 - val_loss: 0.1508 - val_accuracy: 0.9292\n",
      "Epoch 416/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1507 - accuracy: 0.9291 - val_loss: 0.1503 - val_accuracy: 0.9294\n",
      "Epoch 417/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1502 - accuracy: 0.9293 - val_loss: 0.1499 - val_accuracy: 0.9297\n",
      "Epoch 418/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1497 - accuracy: 0.9296 - val_loss: 0.1494 - val_accuracy: 0.9301\n",
      "Epoch 419/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1492 - accuracy: 0.9300 - val_loss: 0.1490 - val_accuracy: 0.9302\n",
      "Epoch 420/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1487 - accuracy: 0.9301 - val_loss: 0.1485 - val_accuracy: 0.9304\n",
      "Epoch 421/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1482 - accuracy: 0.9304 - val_loss: 0.1480 - val_accuracy: 0.9307\n",
      "Epoch 422/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1477 - accuracy: 0.9305 - val_loss: 0.1475 - val_accuracy: 0.9311\n",
      "Epoch 423/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1472 - accuracy: 0.9310 - val_loss: 0.1471 - val_accuracy: 0.9315\n",
      "Epoch 424/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1467 - accuracy: 0.9309 - val_loss: 0.1466 - val_accuracy: 0.9317\n",
      "Epoch 425/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1463 - accuracy: 0.9312 - val_loss: 0.1462 - val_accuracy: 0.9323\n",
      "Epoch 426/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1458 - accuracy: 0.9316 - val_loss: 0.1457 - val_accuracy: 0.9324\n",
      "Epoch 427/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1453 - accuracy: 0.9317 - val_loss: 0.1452 - val_accuracy: 0.9325\n",
      "Epoch 428/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1448 - accuracy: 0.9321 - val_loss: 0.1448 - val_accuracy: 0.9326\n",
      "Epoch 429/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1444 - accuracy: 0.9321 - val_loss: 0.1444 - val_accuracy: 0.9329\n",
      "Epoch 430/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1439 - accuracy: 0.9323 - val_loss: 0.1439 - val_accuracy: 0.9328\n",
      "Epoch 431/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1434 - accuracy: 0.9328 - val_loss: 0.1435 - val_accuracy: 0.9331\n",
      "Epoch 432/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1430 - accuracy: 0.9328 - val_loss: 0.1431 - val_accuracy: 0.9334\n",
      "Epoch 433/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9331 - val_loss: 0.1427 - val_accuracy: 0.9333\n",
      "Epoch 434/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1421 - accuracy: 0.9328 - val_loss: 0.1422 - val_accuracy: 0.9335\n",
      "Epoch 435/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1416 - accuracy: 0.9334 - val_loss: 0.1418 - val_accuracy: 0.9337\n",
      "Epoch 436/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.9334 - val_loss: 0.1413 - val_accuracy: 0.9340\n",
      "Epoch 437/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1407 - accuracy: 0.9337 - val_loss: 0.1409 - val_accuracy: 0.9344\n",
      "Epoch 438/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9340 - val_loss: 0.1405 - val_accuracy: 0.9345\n",
      "Epoch 439/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1398 - accuracy: 0.9342 - val_loss: 0.1401 - val_accuracy: 0.9349\n",
      "Epoch 440/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1393 - accuracy: 0.9346 - val_loss: 0.1396 - val_accuracy: 0.9350\n",
      "Epoch 441/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1389 - accuracy: 0.9346 - val_loss: 0.1392 - val_accuracy: 0.9350\n",
      "Epoch 442/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1384 - accuracy: 0.9350 - val_loss: 0.1388 - val_accuracy: 0.9352\n",
      "Epoch 443/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1380 - accuracy: 0.9352 - val_loss: 0.1384 - val_accuracy: 0.9353\n",
      "Epoch 444/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1375 - accuracy: 0.9356 - val_loss: 0.1379 - val_accuracy: 0.9354\n",
      "Epoch 445/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1371 - accuracy: 0.9358 - val_loss: 0.1375 - val_accuracy: 0.9356\n",
      "Epoch 446/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1366 - accuracy: 0.9361 - val_loss: 0.1371 - val_accuracy: 0.9353\n",
      "Epoch 447/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1362 - accuracy: 0.9364 - val_loss: 0.1367 - val_accuracy: 0.9356\n",
      "Epoch 448/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1357 - accuracy: 0.9365 - val_loss: 0.1363 - val_accuracy: 0.9358\n",
      "Epoch 449/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1353 - accuracy: 0.9369 - val_loss: 0.1359 - val_accuracy: 0.9361\n",
      "Epoch 450/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1349 - accuracy: 0.9369 - val_loss: 0.1355 - val_accuracy: 0.9367\n",
      "Epoch 451/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1344 - accuracy: 0.9372 - val_loss: 0.1350 - val_accuracy: 0.9374\n",
      "Epoch 452/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1340 - accuracy: 0.9374 - val_loss: 0.1346 - val_accuracy: 0.9374\n",
      "Epoch 453/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1336 - accuracy: 0.9378 - val_loss: 0.1342 - val_accuracy: 0.9373\n",
      "Epoch 454/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1331 - accuracy: 0.9376 - val_loss: 0.1338 - val_accuracy: 0.9376\n",
      "Epoch 455/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1327 - accuracy: 0.9379 - val_loss: 0.1334 - val_accuracy: 0.9378\n",
      "Epoch 456/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1323 - accuracy: 0.9383 - val_loss: 0.1330 - val_accuracy: 0.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1318 - accuracy: 0.9383 - val_loss: 0.1326 - val_accuracy: 0.9382\n",
      "Epoch 458/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1314 - accuracy: 0.9387 - val_loss: 0.1322 - val_accuracy: 0.9380\n",
      "Epoch 459/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1310 - accuracy: 0.9388 - val_loss: 0.1318 - val_accuracy: 0.9382\n",
      "Epoch 460/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1306 - accuracy: 0.9390 - val_loss: 0.1314 - val_accuracy: 0.9387\n",
      "Epoch 461/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1301 - accuracy: 0.9393 - val_loss: 0.1310 - val_accuracy: 0.9385\n",
      "Epoch 462/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1297 - accuracy: 0.9396 - val_loss: 0.1307 - val_accuracy: 0.9386\n",
      "Epoch 463/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1293 - accuracy: 0.9399 - val_loss: 0.1303 - val_accuracy: 0.9385\n",
      "Epoch 464/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1289 - accuracy: 0.9400 - val_loss: 0.1299 - val_accuracy: 0.9389\n",
      "Epoch 465/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1285 - accuracy: 0.9402 - val_loss: 0.1295 - val_accuracy: 0.9389\n",
      "Epoch 466/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1281 - accuracy: 0.9405 - val_loss: 0.1291 - val_accuracy: 0.9392\n",
      "Epoch 467/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1277 - accuracy: 0.9408 - val_loss: 0.1287 - val_accuracy: 0.9394\n",
      "Epoch 468/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1273 - accuracy: 0.9408 - val_loss: 0.1284 - val_accuracy: 0.9393\n",
      "Epoch 469/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1269 - accuracy: 0.9410 - val_loss: 0.1280 - val_accuracy: 0.9393\n",
      "Epoch 470/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1264 - accuracy: 0.9411 - val_loss: 0.1276 - val_accuracy: 0.9398\n",
      "Epoch 471/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1261 - accuracy: 0.9414 - val_loss: 0.1272 - val_accuracy: 0.9399\n",
      "Epoch 472/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1257 - accuracy: 0.9415 - val_loss: 0.1268 - val_accuracy: 0.9400\n",
      "Epoch 473/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1253 - accuracy: 0.9418 - val_loss: 0.1265 - val_accuracy: 0.9404\n",
      "Epoch 474/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1249 - accuracy: 0.9422 - val_loss: 0.1261 - val_accuracy: 0.9401\n",
      "Epoch 475/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.9422 - val_loss: 0.1257 - val_accuracy: 0.9405\n",
      "Epoch 476/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1241 - accuracy: 0.9426 - val_loss: 0.1254 - val_accuracy: 0.9407\n",
      "Epoch 477/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1237 - accuracy: 0.9428 - val_loss: 0.1250 - val_accuracy: 0.9406\n",
      "Epoch 478/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1233 - accuracy: 0.9430 - val_loss: 0.1246 - val_accuracy: 0.9409\n",
      "Epoch 479/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1229 - accuracy: 0.9433 - val_loss: 0.1243 - val_accuracy: 0.9406\n",
      "Epoch 480/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1225 - accuracy: 0.9436 - val_loss: 0.1239 - val_accuracy: 0.9408\n",
      "Epoch 481/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1221 - accuracy: 0.9436 - val_loss: 0.1235 - val_accuracy: 0.9412\n",
      "Epoch 482/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1217 - accuracy: 0.9437 - val_loss: 0.1232 - val_accuracy: 0.9412\n",
      "Epoch 483/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1213 - accuracy: 0.9440 - val_loss: 0.1228 - val_accuracy: 0.9417\n",
      "Epoch 484/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1210 - accuracy: 0.9442 - val_loss: 0.1224 - val_accuracy: 0.9421\n",
      "Epoch 485/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1206 - accuracy: 0.9445 - val_loss: 0.1221 - val_accuracy: 0.9418\n",
      "Epoch 486/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1202 - accuracy: 0.9447 - val_loss: 0.1217 - val_accuracy: 0.9426\n",
      "Epoch 487/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1198 - accuracy: 0.9450 - val_loss: 0.1214 - val_accuracy: 0.9430\n",
      "Epoch 488/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1195 - accuracy: 0.9452 - val_loss: 0.1210 - val_accuracy: 0.9430\n",
      "Epoch 489/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1191 - accuracy: 0.9454 - val_loss: 0.1207 - val_accuracy: 0.9431\n",
      "Epoch 490/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1187 - accuracy: 0.9455 - val_loss: 0.1203 - val_accuracy: 0.9432\n",
      "Epoch 491/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1184 - accuracy: 0.9459 - val_loss: 0.1200 - val_accuracy: 0.9435\n",
      "Epoch 492/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1180 - accuracy: 0.9459 - val_loss: 0.1197 - val_accuracy: 0.9441\n",
      "Epoch 493/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1176 - accuracy: 0.9463 - val_loss: 0.1193 - val_accuracy: 0.9440\n",
      "Epoch 494/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.9465 - val_loss: 0.1190 - val_accuracy: 0.9441\n",
      "Epoch 495/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1169 - accuracy: 0.9466 - val_loss: 0.1186 - val_accuracy: 0.9444\n",
      "Epoch 496/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1166 - accuracy: 0.9469 - val_loss: 0.1183 - val_accuracy: 0.9446\n",
      "Epoch 497/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1162 - accuracy: 0.9472 - val_loss: 0.1180 - val_accuracy: 0.9448\n",
      "Epoch 498/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1158 - accuracy: 0.9475 - val_loss: 0.1176 - val_accuracy: 0.9451\n",
      "Epoch 499/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1155 - accuracy: 0.9477 - val_loss: 0.1173 - val_accuracy: 0.9452\n",
      "Epoch 500/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1152 - accuracy: 0.9478 - val_loss: 0.1170 - val_accuracy: 0.9453\n",
      "Epoch 501/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1148 - accuracy: 0.9479 - val_loss: 0.1167 - val_accuracy: 0.9455\n",
      "Epoch 502/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1144 - accuracy: 0.9482 - val_loss: 0.1163 - val_accuracy: 0.9455\n",
      "Epoch 503/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1141 - accuracy: 0.9485 - val_loss: 0.1160 - val_accuracy: 0.9457\n",
      "Epoch 504/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1137 - accuracy: 0.9485 - val_loss: 0.1157 - val_accuracy: 0.9461\n",
      "Epoch 505/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1134 - accuracy: 0.9489 - val_loss: 0.1154 - val_accuracy: 0.9462\n",
      "Epoch 506/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1131 - accuracy: 0.9489 - val_loss: 0.1150 - val_accuracy: 0.9464\n",
      "Epoch 507/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1127 - accuracy: 0.9493 - val_loss: 0.1147 - val_accuracy: 0.9465\n",
      "Epoch 508/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1124 - accuracy: 0.9493 - val_loss: 0.1144 - val_accuracy: 0.9465\n",
      "Epoch 509/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1121 - accuracy: 0.9496 - val_loss: 0.1141 - val_accuracy: 0.9469\n",
      "Epoch 510/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1117 - accuracy: 0.9499 - val_loss: 0.1138 - val_accuracy: 0.9465\n",
      "Epoch 511/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1114 - accuracy: 0.9500 - val_loss: 0.1134 - val_accuracy: 0.9468\n",
      "Epoch 512/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1110 - accuracy: 0.9502 - val_loss: 0.1131 - val_accuracy: 0.9471\n",
      "Epoch 513/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1107 - accuracy: 0.9504 - val_loss: 0.1128 - val_accuracy: 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1104 - accuracy: 0.9506 - val_loss: 0.1125 - val_accuracy: 0.9472\n",
      "Epoch 515/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1101 - accuracy: 0.9508 - val_loss: 0.1122 - val_accuracy: 0.9471\n",
      "Epoch 516/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1097 - accuracy: 0.9511 - val_loss: 0.1119 - val_accuracy: 0.9475\n",
      "Epoch 517/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1094 - accuracy: 0.9512 - val_loss: 0.1116 - val_accuracy: 0.9482\n",
      "Epoch 518/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1091 - accuracy: 0.9514 - val_loss: 0.1113 - val_accuracy: 0.9479\n",
      "Epoch 519/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1088 - accuracy: 0.9516 - val_loss: 0.1109 - val_accuracy: 0.9494\n",
      "Epoch 520/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1084 - accuracy: 0.9517 - val_loss: 0.1106 - val_accuracy: 0.9491\n",
      "Epoch 521/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1081 - accuracy: 0.9519 - val_loss: 0.1103 - val_accuracy: 0.9495\n",
      "Epoch 522/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9519 - val_loss: 0.1100 - val_accuracy: 0.9496\n",
      "Epoch 523/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1075 - accuracy: 0.9522 - val_loss: 0.1097 - val_accuracy: 0.9501\n",
      "Epoch 524/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1071 - accuracy: 0.9523 - val_loss: 0.1094 - val_accuracy: 0.9505\n",
      "Epoch 525/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1068 - accuracy: 0.9524 - val_loss: 0.1091 - val_accuracy: 0.9500\n",
      "Epoch 526/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1065 - accuracy: 0.9525 - val_loss: 0.1088 - val_accuracy: 0.9505\n",
      "Epoch 527/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1062 - accuracy: 0.9528 - val_loss: 0.1085 - val_accuracy: 0.9504\n",
      "Epoch 528/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1059 - accuracy: 0.9529 - val_loss: 0.1082 - val_accuracy: 0.9505\n",
      "Epoch 529/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1056 - accuracy: 0.9531 - val_loss: 0.1079 - val_accuracy: 0.9506\n",
      "Epoch 530/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.1053 - accuracy: 0.9534 - val_loss: 0.1076 - val_accuracy: 0.9508\n",
      "Epoch 531/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1050 - accuracy: 0.9536 - val_loss: 0.1073 - val_accuracy: 0.9509\n",
      "Epoch 532/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.1047 - accuracy: 0.9537 - val_loss: 0.1071 - val_accuracy: 0.9509\n",
      "Epoch 533/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.1044 - accuracy: 0.9538 - val_loss: 0.1068 - val_accuracy: 0.9511\n",
      "Epoch 534/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1041 - accuracy: 0.9539 - val_loss: 0.1065 - val_accuracy: 0.9514\n",
      "Epoch 535/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1038 - accuracy: 0.9539 - val_loss: 0.1062 - val_accuracy: 0.9514\n",
      "Epoch 536/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1034 - accuracy: 0.9540 - val_loss: 0.1059 - val_accuracy: 0.9517\n",
      "Epoch 537/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1031 - accuracy: 0.9541 - val_loss: 0.1056 - val_accuracy: 0.9523\n",
      "Epoch 538/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1028 - accuracy: 0.9543 - val_loss: 0.1053 - val_accuracy: 0.9521\n",
      "Epoch 539/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1026 - accuracy: 0.9545 - val_loss: 0.1050 - val_accuracy: 0.9520\n",
      "Epoch 540/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1023 - accuracy: 0.9547 - val_loss: 0.1048 - val_accuracy: 0.9520\n",
      "Epoch 541/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1020 - accuracy: 0.9546 - val_loss: 0.1045 - val_accuracy: 0.9529\n",
      "Epoch 542/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1017 - accuracy: 0.9550 - val_loss: 0.1042 - val_accuracy: 0.9529\n",
      "Epoch 543/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.1014 - accuracy: 0.9552 - val_loss: 0.1039 - val_accuracy: 0.9531\n",
      "Epoch 544/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1011 - accuracy: 0.9554 - val_loss: 0.1036 - val_accuracy: 0.9533\n",
      "Epoch 545/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.1008 - accuracy: 0.9554 - val_loss: 0.1034 - val_accuracy: 0.9531\n",
      "Epoch 546/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1005 - accuracy: 0.9555 - val_loss: 0.1031 - val_accuracy: 0.9538\n",
      "Epoch 547/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.1002 - accuracy: 0.9558 - val_loss: 0.1028 - val_accuracy: 0.9543\n",
      "Epoch 548/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0999 - accuracy: 0.9557 - val_loss: 0.1025 - val_accuracy: 0.9542\n",
      "Epoch 549/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0996 - accuracy: 0.9559 - val_loss: 0.1022 - val_accuracy: 0.9544\n",
      "Epoch 550/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0994 - accuracy: 0.9562 - val_loss: 0.1020 - val_accuracy: 0.9539\n",
      "Epoch 551/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0991 - accuracy: 0.9560 - val_loss: 0.1017 - val_accuracy: 0.9545\n",
      "Epoch 552/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0988 - accuracy: 0.9563 - val_loss: 0.1014 - val_accuracy: 0.9546\n",
      "Epoch 553/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0985 - accuracy: 0.9563 - val_loss: 0.1011 - val_accuracy: 0.9547\n",
      "Epoch 554/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.9564 - val_loss: 0.1008 - val_accuracy: 0.9549\n",
      "Epoch 555/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0980 - accuracy: 0.9564 - val_loss: 0.1006 - val_accuracy: 0.9550\n",
      "Epoch 556/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0977 - accuracy: 0.9566 - val_loss: 0.1003 - val_accuracy: 0.9551\n",
      "Epoch 557/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0974 - accuracy: 0.9569 - val_loss: 0.1000 - val_accuracy: 0.9553\n",
      "Epoch 558/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0971 - accuracy: 0.9569 - val_loss: 0.0998 - val_accuracy: 0.9554\n",
      "Epoch 559/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0968 - accuracy: 0.9571 - val_loss: 0.0995 - val_accuracy: 0.9557\n",
      "Epoch 560/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0966 - accuracy: 0.9572 - val_loss: 0.0993 - val_accuracy: 0.9556\n",
      "Epoch 561/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0963 - accuracy: 0.9573 - val_loss: 0.0990 - val_accuracy: 0.9561\n",
      "Epoch 562/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0960 - accuracy: 0.9575 - val_loss: 0.0987 - val_accuracy: 0.9564\n",
      "Epoch 563/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0958 - accuracy: 0.9577 - val_loss: 0.0984 - val_accuracy: 0.9565\n",
      "Epoch 564/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0955 - accuracy: 0.9579 - val_loss: 0.0983 - val_accuracy: 0.9565\n",
      "Epoch 565/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0953 - accuracy: 0.9579 - val_loss: 0.0980 - val_accuracy: 0.9566\n",
      "Epoch 566/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0950 - accuracy: 0.9580 - val_loss: 0.0977 - val_accuracy: 0.9571\n",
      "Epoch 567/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0947 - accuracy: 0.9581 - val_loss: 0.0974 - val_accuracy: 0.9571\n",
      "Epoch 568/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0945 - accuracy: 0.9585 - val_loss: 0.0973 - val_accuracy: 0.9569\n",
      "Epoch 569/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0942 - accuracy: 0.9584 - val_loss: 0.0970 - val_accuracy: 0.9572\n",
      "Epoch 570/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0940 - accuracy: 0.9586 - val_loss: 0.0967 - val_accuracy: 0.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0937 - accuracy: 0.9587 - val_loss: 0.0964 - val_accuracy: 0.9573\n",
      "Epoch 572/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0934 - accuracy: 0.9587 - val_loss: 0.0962 - val_accuracy: 0.9572\n",
      "Epoch 573/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0932 - accuracy: 0.9590 - val_loss: 0.0959 - val_accuracy: 0.9575\n",
      "Epoch 574/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0929 - accuracy: 0.9591 - val_loss: 0.0957 - val_accuracy: 0.9581\n",
      "Epoch 575/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0927 - accuracy: 0.9594 - val_loss: 0.0954 - val_accuracy: 0.9585\n",
      "Epoch 576/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0924 - accuracy: 0.9595 - val_loss: 0.0952 - val_accuracy: 0.9586\n",
      "Epoch 577/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0922 - accuracy: 0.9597 - val_loss: 0.0949 - val_accuracy: 0.9587\n",
      "Epoch 578/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0919 - accuracy: 0.9599 - val_loss: 0.0947 - val_accuracy: 0.9588\n",
      "Epoch 579/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0917 - accuracy: 0.9600 - val_loss: 0.0944 - val_accuracy: 0.9587\n",
      "Epoch 580/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0914 - accuracy: 0.9601 - val_loss: 0.0942 - val_accuracy: 0.9590\n",
      "Epoch 581/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0912 - accuracy: 0.9602 - val_loss: 0.0939 - val_accuracy: 0.9589\n",
      "Epoch 582/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0909 - accuracy: 0.9602 - val_loss: 0.0938 - val_accuracy: 0.9592\n",
      "Epoch 583/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0907 - accuracy: 0.9603 - val_loss: 0.0934 - val_accuracy: 0.9591\n",
      "Epoch 584/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0904 - accuracy: 0.9606 - val_loss: 0.0932 - val_accuracy: 0.9594\n",
      "Epoch 585/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0902 - accuracy: 0.9607 - val_loss: 0.0930 - val_accuracy: 0.9594\n",
      "Epoch 586/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0899 - accuracy: 0.9607 - val_loss: 0.0927 - val_accuracy: 0.9595\n",
      "Epoch 587/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0897 - accuracy: 0.9609 - val_loss: 0.0925 - val_accuracy: 0.9596\n",
      "Epoch 588/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0895 - accuracy: 0.9610 - val_loss: 0.0923 - val_accuracy: 0.9600\n",
      "Epoch 589/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0892 - accuracy: 0.9612 - val_loss: 0.0920 - val_accuracy: 0.9604\n",
      "Epoch 590/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0890 - accuracy: 0.9614 - val_loss: 0.0918 - val_accuracy: 0.9605\n",
      "Epoch 591/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0887 - accuracy: 0.9616 - val_loss: 0.0915 - val_accuracy: 0.9604\n",
      "Epoch 592/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0885 - accuracy: 0.9617 - val_loss: 0.0913 - val_accuracy: 0.9608\n",
      "Epoch 593/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0883 - accuracy: 0.9618 - val_loss: 0.0910 - val_accuracy: 0.9607\n",
      "Epoch 594/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0880 - accuracy: 0.9620 - val_loss: 0.0908 - val_accuracy: 0.9610\n",
      "Epoch 595/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0878 - accuracy: 0.9621 - val_loss: 0.0906 - val_accuracy: 0.9609\n",
      "Epoch 596/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0876 - accuracy: 0.9624 - val_loss: 0.0904 - val_accuracy: 0.9613\n",
      "Epoch 597/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0873 - accuracy: 0.9627 - val_loss: 0.0902 - val_accuracy: 0.9618\n",
      "Epoch 598/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0871 - accuracy: 0.9631 - val_loss: 0.0899 - val_accuracy: 0.9618\n",
      "Epoch 599/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9633 - val_loss: 0.0896 - val_accuracy: 0.9622\n",
      "Epoch 600/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0866 - accuracy: 0.9634 - val_loss: 0.0895 - val_accuracy: 0.9621\n",
      "Epoch 601/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0864 - accuracy: 0.9638 - val_loss: 0.0893 - val_accuracy: 0.9624\n",
      "Epoch 602/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0862 - accuracy: 0.9639 - val_loss: 0.0890 - val_accuracy: 0.9626\n",
      "Epoch 603/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0860 - accuracy: 0.9640 - val_loss: 0.0888 - val_accuracy: 0.9627\n",
      "Epoch 604/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0857 - accuracy: 0.9642 - val_loss: 0.0885 - val_accuracy: 0.9632\n",
      "Epoch 605/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0855 - accuracy: 0.9645 - val_loss: 0.0883 - val_accuracy: 0.9634\n",
      "Epoch 606/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0853 - accuracy: 0.9648 - val_loss: 0.0881 - val_accuracy: 0.9631\n",
      "Epoch 607/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0851 - accuracy: 0.9648 - val_loss: 0.0879 - val_accuracy: 0.9632\n",
      "Epoch 608/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0848 - accuracy: 0.9651 - val_loss: 0.0877 - val_accuracy: 0.9635\n",
      "Epoch 609/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0846 - accuracy: 0.9651 - val_loss: 0.0875 - val_accuracy: 0.9636\n",
      "Epoch 610/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0844 - accuracy: 0.9651 - val_loss: 0.0872 - val_accuracy: 0.9641\n",
      "Epoch 611/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0842 - accuracy: 0.9654 - val_loss: 0.0871 - val_accuracy: 0.9641\n",
      "Epoch 612/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0840 - accuracy: 0.9658 - val_loss: 0.0868 - val_accuracy: 0.9642\n",
      "Epoch 613/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0837 - accuracy: 0.9659 - val_loss: 0.0866 - val_accuracy: 0.9646\n",
      "Epoch 614/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0835 - accuracy: 0.9661 - val_loss: 0.0864 - val_accuracy: 0.9647\n",
      "Epoch 615/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0833 - accuracy: 0.9661 - val_loss: 0.0861 - val_accuracy: 0.9650\n",
      "Epoch 616/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0831 - accuracy: 0.9662 - val_loss: 0.0859 - val_accuracy: 0.9649\n",
      "Epoch 617/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0829 - accuracy: 0.9665 - val_loss: 0.0857 - val_accuracy: 0.9653\n",
      "Epoch 618/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0827 - accuracy: 0.9667 - val_loss: 0.0855 - val_accuracy: 0.9662\n",
      "Epoch 619/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0825 - accuracy: 0.9671 - val_loss: 0.0852 - val_accuracy: 0.9661\n",
      "Epoch 620/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0822 - accuracy: 0.9672 - val_loss: 0.0850 - val_accuracy: 0.9663\n",
      "Epoch 621/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0820 - accuracy: 0.9673 - val_loss: 0.0849 - val_accuracy: 0.9665\n",
      "Epoch 622/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0818 - accuracy: 0.9676 - val_loss: 0.0846 - val_accuracy: 0.9664\n",
      "Epoch 623/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0816 - accuracy: 0.9678 - val_loss: 0.0844 - val_accuracy: 0.9668\n",
      "Epoch 624/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0814 - accuracy: 0.9678 - val_loss: 0.0842 - val_accuracy: 0.9666\n",
      "Epoch 625/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0812 - accuracy: 0.9679 - val_loss: 0.0840 - val_accuracy: 0.9668\n",
      "Epoch 626/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0810 - accuracy: 0.9684 - val_loss: 0.0838 - val_accuracy: 0.9669\n",
      "Epoch 627/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0807 - accuracy: 0.9690 - val_loss: 0.0836 - val_accuracy: 0.9686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0806 - accuracy: 0.9699 - val_loss: 0.0834 - val_accuracy: 0.9691\n",
      "Epoch 629/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9700 - val_loss: 0.0832 - val_accuracy: 0.9694\n",
      "Epoch 630/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0801 - accuracy: 0.9703 - val_loss: 0.0830 - val_accuracy: 0.9694\n",
      "Epoch 631/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0799 - accuracy: 0.9704 - val_loss: 0.0828 - val_accuracy: 0.9695\n",
      "Epoch 632/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0797 - accuracy: 0.9708 - val_loss: 0.0826 - val_accuracy: 0.9700\n",
      "Epoch 633/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0795 - accuracy: 0.9712 - val_loss: 0.0824 - val_accuracy: 0.9703\n",
      "Epoch 634/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0793 - accuracy: 0.9713 - val_loss: 0.0822 - val_accuracy: 0.9703\n",
      "Epoch 635/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0791 - accuracy: 0.9715 - val_loss: 0.0820 - val_accuracy: 0.9705\n",
      "Epoch 636/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0789 - accuracy: 0.9717 - val_loss: 0.0817 - val_accuracy: 0.9706\n",
      "Epoch 637/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0787 - accuracy: 0.9719 - val_loss: 0.0816 - val_accuracy: 0.9715\n",
      "Epoch 638/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0785 - accuracy: 0.9719 - val_loss: 0.0813 - val_accuracy: 0.9715\n",
      "Epoch 639/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0783 - accuracy: 0.9722 - val_loss: 0.0811 - val_accuracy: 0.9716\n",
      "Epoch 640/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0781 - accuracy: 0.9723 - val_loss: 0.0809 - val_accuracy: 0.9722\n",
      "Epoch 641/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0779 - accuracy: 0.9724 - val_loss: 0.0807 - val_accuracy: 0.9718\n",
      "Epoch 642/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0777 - accuracy: 0.9727 - val_loss: 0.0806 - val_accuracy: 0.9721\n",
      "Epoch 643/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0775 - accuracy: 0.9728 - val_loss: 0.0803 - val_accuracy: 0.9722\n",
      "Epoch 644/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9730 - val_loss: 0.0801 - val_accuracy: 0.9721\n",
      "Epoch 645/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0772 - accuracy: 0.9730 - val_loss: 0.0799 - val_accuracy: 0.9724\n",
      "Epoch 646/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0770 - accuracy: 0.9731 - val_loss: 0.0797 - val_accuracy: 0.9729\n",
      "Epoch 647/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0768 - accuracy: 0.9732 - val_loss: 0.0795 - val_accuracy: 0.9734\n",
      "Epoch 648/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0766 - accuracy: 0.9733 - val_loss: 0.0793 - val_accuracy: 0.9736\n",
      "Epoch 649/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9735 - val_loss: 0.0791 - val_accuracy: 0.9737\n",
      "Epoch 650/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0762 - accuracy: 0.9736 - val_loss: 0.0789 - val_accuracy: 0.9745\n",
      "Epoch 651/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0760 - accuracy: 0.9740 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
      "Epoch 652/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9742 - val_loss: 0.0785 - val_accuracy: 0.9745\n",
      "Epoch 653/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9742 - val_loss: 0.0783 - val_accuracy: 0.9749\n",
      "Epoch 654/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0754 - accuracy: 0.9745 - val_loss: 0.0781 - val_accuracy: 0.9748\n",
      "Epoch 655/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0752 - accuracy: 0.9746 - val_loss: 0.0780 - val_accuracy: 0.9753\n",
      "Epoch 656/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0750 - accuracy: 0.9747 - val_loss: 0.0777 - val_accuracy: 0.9747\n",
      "Epoch 657/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9749 - val_loss: 0.0776 - val_accuracy: 0.9753\n",
      "Epoch 658/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0747 - accuracy: 0.9750 - val_loss: 0.0774 - val_accuracy: 0.9753\n",
      "Epoch 659/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.0772 - val_accuracy: 0.9755\n",
      "Epoch 660/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.0770 - val_accuracy: 0.9758\n",
      "Epoch 661/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0741 - accuracy: 0.9751 - val_loss: 0.0768 - val_accuracy: 0.9758\n",
      "Epoch 662/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0739 - accuracy: 0.9751 - val_loss: 0.0766 - val_accuracy: 0.9759\n",
      "Epoch 663/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0737 - accuracy: 0.9754 - val_loss: 0.0764 - val_accuracy: 0.9762\n",
      "Epoch 664/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0736 - accuracy: 0.9755 - val_loss: 0.0762 - val_accuracy: 0.9761\n",
      "Epoch 665/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9758 - val_loss: 0.0761 - val_accuracy: 0.9765\n",
      "Epoch 666/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0732 - accuracy: 0.9758 - val_loss: 0.0759 - val_accuracy: 0.9766\n",
      "Epoch 667/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0730 - accuracy: 0.9760 - val_loss: 0.0757 - val_accuracy: 0.9767\n",
      "Epoch 668/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0729 - accuracy: 0.9761 - val_loss: 0.0756 - val_accuracy: 0.9767\n",
      "Epoch 669/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0727 - accuracy: 0.9763 - val_loss: 0.0753 - val_accuracy: 0.9766\n",
      "Epoch 670/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0725 - accuracy: 0.9763 - val_loss: 0.0752 - val_accuracy: 0.9770\n",
      "Epoch 671/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 0.0750 - val_accuracy: 0.9769\n",
      "Epoch 672/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0721 - accuracy: 0.9764 - val_loss: 0.0748 - val_accuracy: 0.9771\n",
      "Epoch 673/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0720 - accuracy: 0.9765 - val_loss: 0.0746 - val_accuracy: 0.9773\n",
      "Epoch 674/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0718 - accuracy: 0.9767 - val_loss: 0.0745 - val_accuracy: 0.9775\n",
      "Epoch 675/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0716 - accuracy: 0.9767 - val_loss: 0.0742 - val_accuracy: 0.9774\n",
      "Epoch 676/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0714 - accuracy: 0.9768 - val_loss: 0.0740 - val_accuracy: 0.9774\n",
      "Epoch 677/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0713 - accuracy: 0.9769 - val_loss: 0.0739 - val_accuracy: 0.9776\n",
      "Epoch 678/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0711 - accuracy: 0.9769 - val_loss: 0.0737 - val_accuracy: 0.9776\n",
      "Epoch 679/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0709 - accuracy: 0.9770 - val_loss: 0.0735 - val_accuracy: 0.9778\n",
      "Epoch 680/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0707 - accuracy: 0.9772 - val_loss: 0.0733 - val_accuracy: 0.9778\n",
      "Epoch 681/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0706 - accuracy: 0.9772 - val_loss: 0.0731 - val_accuracy: 0.9779\n",
      "Epoch 682/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0704 - accuracy: 0.9774 - val_loss: 0.0730 - val_accuracy: 0.9780\n",
      "Epoch 683/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0702 - accuracy: 0.9775 - val_loss: 0.0728 - val_accuracy: 0.9780\n",
      "Epoch 684/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0700 - accuracy: 0.9776 - val_loss: 0.0726 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0699 - accuracy: 0.9777 - val_loss: 0.0725 - val_accuracy: 0.9782\n",
      "Epoch 686/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0697 - accuracy: 0.9778 - val_loss: 0.0723 - val_accuracy: 0.9781\n",
      "Epoch 687/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0695 - accuracy: 0.9779 - val_loss: 0.0720 - val_accuracy: 0.9779\n",
      "Epoch 688/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0694 - accuracy: 0.9779 - val_loss: 0.0719 - val_accuracy: 0.9782\n",
      "Epoch 689/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0692 - accuracy: 0.9779 - val_loss: 0.0717 - val_accuracy: 0.9781\n",
      "Epoch 690/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0690 - accuracy: 0.9779 - val_loss: 0.0715 - val_accuracy: 0.9783\n",
      "Epoch 691/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9780 - val_loss: 0.0714 - val_accuracy: 0.9783\n",
      "Epoch 692/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0687 - accuracy: 0.9782 - val_loss: 0.0712 - val_accuracy: 0.9784\n",
      "Epoch 693/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0685 - accuracy: 0.9782 - val_loss: 0.0711 - val_accuracy: 0.9786\n",
      "Epoch 694/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0684 - accuracy: 0.9782 - val_loss: 0.0709 - val_accuracy: 0.9786\n",
      "Epoch 695/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 0.0707 - val_accuracy: 0.9787\n",
      "Epoch 696/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9785 - val_loss: 0.0706 - val_accuracy: 0.9788\n",
      "Epoch 697/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0679 - accuracy: 0.9786 - val_loss: 0.0703 - val_accuracy: 0.9790\n",
      "Epoch 698/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0677 - accuracy: 0.9787 - val_loss: 0.0702 - val_accuracy: 0.9789\n",
      "Epoch 699/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0676 - accuracy: 0.9787 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
      "Epoch 700/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.0699 - val_accuracy: 0.9790\n",
      "Epoch 701/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0673 - accuracy: 0.9788 - val_loss: 0.0697 - val_accuracy: 0.9788\n",
      "Epoch 702/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0671 - accuracy: 0.9791 - val_loss: 0.0696 - val_accuracy: 0.9791\n",
      "Epoch 703/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0670 - accuracy: 0.9790 - val_loss: 0.0694 - val_accuracy: 0.9791\n",
      "Epoch 704/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.0692 - val_accuracy: 0.9792\n",
      "Epoch 705/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0666 - accuracy: 0.9792 - val_loss: 0.0690 - val_accuracy: 0.9791\n",
      "Epoch 706/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0665 - accuracy: 0.9791 - val_loss: 0.0690 - val_accuracy: 0.9794\n",
      "Epoch 707/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0663 - accuracy: 0.9793 - val_loss: 0.0687 - val_accuracy: 0.9792\n",
      "Epoch 708/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0662 - accuracy: 0.9793 - val_loss: 0.0686 - val_accuracy: 0.9793\n",
      "Epoch 709/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0660 - accuracy: 0.9794 - val_loss: 0.0685 - val_accuracy: 0.9796\n",
      "Epoch 710/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0659 - accuracy: 0.9795 - val_loss: 0.0682 - val_accuracy: 0.9795\n",
      "Epoch 711/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0657 - accuracy: 0.9795 - val_loss: 0.0681 - val_accuracy: 0.9795\n",
      "Epoch 712/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0656 - accuracy: 0.9796 - val_loss: 0.0679 - val_accuracy: 0.9795\n",
      "Epoch 713/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0654 - accuracy: 0.9795 - val_loss: 0.0678 - val_accuracy: 0.9796\n",
      "Epoch 714/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0653 - accuracy: 0.9796 - val_loss: 0.0676 - val_accuracy: 0.9796\n",
      "Epoch 715/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0651 - accuracy: 0.9798 - val_loss: 0.0674 - val_accuracy: 0.9796\n",
      "Epoch 716/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0650 - accuracy: 0.9797 - val_loss: 0.0673 - val_accuracy: 0.9797\n",
      "Epoch 717/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0648 - accuracy: 0.9797 - val_loss: 0.0671 - val_accuracy: 0.9797\n",
      "Epoch 718/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0647 - accuracy: 0.9798 - val_loss: 0.0669 - val_accuracy: 0.9796\n",
      "Epoch 719/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0645 - accuracy: 0.9799 - val_loss: 0.0668 - val_accuracy: 0.9797\n",
      "Epoch 720/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.0666 - val_accuracy: 0.9800\n",
      "Epoch 721/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0642 - accuracy: 0.9800 - val_loss: 0.0665 - val_accuracy: 0.9800\n",
      "Epoch 722/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0641 - accuracy: 0.9800 - val_loss: 0.0665 - val_accuracy: 0.9803\n",
      "Epoch 723/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0640 - accuracy: 0.9800 - val_loss: 0.0662 - val_accuracy: 0.9801\n",
      "Epoch 724/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 0.0660 - val_accuracy: 0.9801\n",
      "Epoch 725/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0637 - accuracy: 0.9800 - val_loss: 0.0659 - val_accuracy: 0.9801\n",
      "Epoch 726/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0635 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9804\n",
      "Epoch 727/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 0.0656 - val_accuracy: 0.9801\n",
      "Epoch 728/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0633 - accuracy: 0.9802 - val_loss: 0.0654 - val_accuracy: 0.9803\n",
      "Epoch 729/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0631 - accuracy: 0.9802 - val_loss: 0.0653 - val_accuracy: 0.9802\n",
      "Epoch 730/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0630 - accuracy: 0.9803 - val_loss: 0.0652 - val_accuracy: 0.9802\n",
      "Epoch 731/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0650 - val_accuracy: 0.9802\n",
      "Epoch 732/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0627 - accuracy: 0.9804 - val_loss: 0.0649 - val_accuracy: 0.9803\n",
      "Epoch 733/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0626 - accuracy: 0.9804 - val_loss: 0.0648 - val_accuracy: 0.9804\n",
      "Epoch 734/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0624 - accuracy: 0.9804 - val_loss: 0.0646 - val_accuracy: 0.9803\n",
      "Epoch 735/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0623 - accuracy: 0.9805 - val_loss: 0.0645 - val_accuracy: 0.9804\n",
      "Epoch 736/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0622 - accuracy: 0.9805 - val_loss: 0.0643 - val_accuracy: 0.9803\n",
      "Epoch 737/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0620 - accuracy: 0.9805 - val_loss: 0.0642 - val_accuracy: 0.9805\n",
      "Epoch 738/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.0640 - val_accuracy: 0.9805\n",
      "Epoch 739/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.0639 - val_accuracy: 0.9806\n",
      "Epoch 740/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0616 - accuracy: 0.9806 - val_loss: 0.0637 - val_accuracy: 0.9804\n",
      "Epoch 741/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.0637 - val_accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.0635 - val_accuracy: 0.9807\n",
      "Epoch 743/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0613 - accuracy: 0.9805 - val_loss: 0.0633 - val_accuracy: 0.9808\n",
      "Epoch 744/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0611 - accuracy: 0.9807 - val_loss: 0.0633 - val_accuracy: 0.9808\n",
      "Epoch 745/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0610 - accuracy: 0.9807 - val_loss: 0.0631 - val_accuracy: 0.9809\n",
      "Epoch 746/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 0.0629 - val_accuracy: 0.9809\n",
      "Epoch 747/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0608 - accuracy: 0.9806 - val_loss: 0.0628 - val_accuracy: 0.9809\n",
      "Epoch 748/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.0627 - val_accuracy: 0.9809\n",
      "Epoch 749/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.0625 - val_accuracy: 0.9812\n",
      "Epoch 750/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.0624 - val_accuracy: 0.9812\n",
      "Epoch 751/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.0623 - val_accuracy: 0.9810\n",
      "Epoch 752/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0601 - accuracy: 0.9809 - val_loss: 0.0622 - val_accuracy: 0.9810\n",
      "Epoch 753/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.0620 - val_accuracy: 0.9814\n",
      "Epoch 754/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0599 - accuracy: 0.9809 - val_loss: 0.0619 - val_accuracy: 0.9811\n",
      "Epoch 755/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0617 - val_accuracy: 0.9812\n",
      "Epoch 756/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0596 - accuracy: 0.9811 - val_loss: 0.0617 - val_accuracy: 0.9816\n",
      "Epoch 757/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.0615 - val_accuracy: 0.9814\n",
      "Epoch 758/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.0614 - val_accuracy: 0.9814\n",
      "Epoch 759/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0593 - accuracy: 0.9811 - val_loss: 0.0613 - val_accuracy: 0.9816\n",
      "Epoch 760/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0612 - val_accuracy: 0.9817\n",
      "Epoch 761/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.0610 - val_accuracy: 0.9816\n",
      "Epoch 762/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.0609 - val_accuracy: 0.9816\n",
      "Epoch 763/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.0608 - val_accuracy: 0.9817\n",
      "Epoch 764/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.0606 - val_accuracy: 0.9816\n",
      "Epoch 765/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 0.0606 - val_accuracy: 0.9818\n",
      "Epoch 766/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.0605 - val_accuracy: 0.9818\n",
      "Epoch 767/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0584 - accuracy: 0.9812 - val_loss: 0.0603 - val_accuracy: 0.9819\n",
      "Epoch 768/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0583 - accuracy: 0.9811 - val_loss: 0.0602 - val_accuracy: 0.9818\n",
      "Epoch 769/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0582 - accuracy: 0.9814 - val_loss: 0.0601 - val_accuracy: 0.9819\n",
      "Epoch 770/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 0.0600 - val_accuracy: 0.9819\n",
      "Epoch 771/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.0599 - val_accuracy: 0.9817\n",
      "Epoch 772/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0579 - accuracy: 0.9812 - val_loss: 0.0597 - val_accuracy: 0.9818\n",
      "Epoch 773/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0577 - accuracy: 0.9812 - val_loss: 0.0597 - val_accuracy: 0.9818\n",
      "Epoch 774/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.0595 - val_accuracy: 0.9817\n",
      "Epoch 775/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 0.0594 - val_accuracy: 0.9817\n",
      "Epoch 776/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0574 - accuracy: 0.9811 - val_loss: 0.0593 - val_accuracy: 0.9817\n",
      "Epoch 777/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0573 - accuracy: 0.9812 - val_loss: 0.0592 - val_accuracy: 0.9817\n",
      "Epoch 778/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0572 - accuracy: 0.9812 - val_loss: 0.0591 - val_accuracy: 0.9817\n",
      "Epoch 779/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0571 - accuracy: 0.9812 - val_loss: 0.0590 - val_accuracy: 0.9818\n",
      "Epoch 780/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 0.0589 - val_accuracy: 0.9817\n",
      "Epoch 781/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0569 - accuracy: 0.9811 - val_loss: 0.0588 - val_accuracy: 0.9819\n",
      "Epoch 782/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0568 - accuracy: 0.9811 - val_loss: 0.0587 - val_accuracy: 0.9817\n",
      "Epoch 783/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 0.0586 - val_accuracy: 0.9816\n",
      "Epoch 784/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0566 - accuracy: 0.9812 - val_loss: 0.0585 - val_accuracy: 0.9818\n",
      "Epoch 785/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0565 - accuracy: 0.9813 - val_loss: 0.0584 - val_accuracy: 0.9818\n",
      "Epoch 786/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0564 - accuracy: 0.9813 - val_loss: 0.0583 - val_accuracy: 0.9816\n",
      "Epoch 787/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0563 - accuracy: 0.9814 - val_loss: 0.0581 - val_accuracy: 0.9818\n",
      "Epoch 788/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0562 - accuracy: 0.9812 - val_loss: 0.0580 - val_accuracy: 0.9820\n",
      "Epoch 789/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0562 - accuracy: 0.9814 - val_loss: 0.0579 - val_accuracy: 0.9820\n",
      "Epoch 790/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0561 - accuracy: 0.9815 - val_loss: 0.0579 - val_accuracy: 0.9818\n",
      "Epoch 791/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0560 - accuracy: 0.9813 - val_loss: 0.0578 - val_accuracy: 0.9819\n",
      "Epoch 792/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0559 - accuracy: 0.9814 - val_loss: 0.0577 - val_accuracy: 0.9817\n",
      "Epoch 793/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0558 - accuracy: 0.9813 - val_loss: 0.0576 - val_accuracy: 0.9820\n",
      "Epoch 794/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0557 - accuracy: 0.9813 - val_loss: 0.0575 - val_accuracy: 0.9822\n",
      "Epoch 795/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9814 - val_loss: 0.0574 - val_accuracy: 0.9819\n",
      "Epoch 796/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9813 - val_loss: 0.0575 - val_accuracy: 0.9818\n",
      "Epoch 797/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0554 - accuracy: 0.9812 - val_loss: 0.0572 - val_accuracy: 0.9819\n",
      "Epoch 798/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0553 - accuracy: 0.9814 - val_loss: 0.0571 - val_accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0552 - accuracy: 0.9813 - val_loss: 0.0570 - val_accuracy: 0.9824\n",
      "Epoch 800/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0551 - accuracy: 0.9814 - val_loss: 0.0569 - val_accuracy: 0.9823\n",
      "Epoch 801/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0551 - accuracy: 0.9815 - val_loss: 0.0569 - val_accuracy: 0.9821\n",
      "Epoch 802/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.0567 - val_accuracy: 0.9822\n",
      "Epoch 803/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0549 - accuracy: 0.9815 - val_loss: 0.0566 - val_accuracy: 0.9824\n",
      "Epoch 804/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.0566 - val_accuracy: 0.9821\n",
      "Epoch 805/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 0.0565 - val_accuracy: 0.9822\n",
      "Epoch 806/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0546 - accuracy: 0.9815 - val_loss: 0.0564 - val_accuracy: 0.9822\n",
      "Epoch 807/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.0563 - val_accuracy: 0.9826\n",
      "Epoch 808/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.0562 - val_accuracy: 0.9824\n",
      "Epoch 809/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.0561 - val_accuracy: 0.9827\n",
      "Epoch 810/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 0.0561 - val_accuracy: 0.9821\n",
      "Epoch 811/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
      "Epoch 812/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0541 - accuracy: 0.9815 - val_loss: 0.0560 - val_accuracy: 0.9820\n",
      "Epoch 813/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0541 - accuracy: 0.9815 - val_loss: 0.0558 - val_accuracy: 0.9823\n",
      "Epoch 814/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.0557 - val_accuracy: 0.9825\n",
      "Epoch 815/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0556 - val_accuracy: 0.9825\n",
      "Epoch 816/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9816 - val_loss: 0.0556 - val_accuracy: 0.9825\n",
      "Epoch 817/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0537 - accuracy: 0.9816 - val_loss: 0.0554 - val_accuracy: 0.9827\n",
      "Epoch 818/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0537 - accuracy: 0.9816 - val_loss: 0.0554 - val_accuracy: 0.9825\n",
      "Epoch 819/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0536 - accuracy: 0.9817 - val_loss: 0.0553 - val_accuracy: 0.9826\n",
      "Epoch 820/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.0553 - val_accuracy: 0.9825\n",
      "Epoch 821/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0534 - accuracy: 0.9815 - val_loss: 0.0551 - val_accuracy: 0.9828\n",
      "Epoch 822/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 0.0550 - val_accuracy: 0.9828\n",
      "Epoch 823/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.0550 - val_accuracy: 0.9828\n",
      "Epoch 824/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0549 - val_accuracy: 0.9828\n",
      "Epoch 825/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0531 - accuracy: 0.9816 - val_loss: 0.0548 - val_accuracy: 0.9828\n",
      "Epoch 826/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0531 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9828\n",
      "Epoch 827/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0530 - accuracy: 0.9816 - val_loss: 0.0548 - val_accuracy: 0.9824\n",
      "Epoch 828/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9824\n",
      "Epoch 829/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9824\n",
      "Epoch 830/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 0.0546 - val_accuracy: 0.9824\n",
      "Epoch 831/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0527 - accuracy: 0.9817 - val_loss: 0.0544 - val_accuracy: 0.9828\n",
      "Epoch 832/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.0544 - val_accuracy: 0.9828\n",
      "Epoch 833/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9818 - val_loss: 0.0542 - val_accuracy: 0.9829\n",
      "Epoch 834/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 0.0543 - val_accuracy: 0.9826\n",
      "Epoch 835/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0524 - accuracy: 0.9817 - val_loss: 0.0541 - val_accuracy: 0.9828\n",
      "Epoch 836/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0523 - accuracy: 0.9818 - val_loss: 0.0541 - val_accuracy: 0.9827\n",
      "Epoch 837/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0523 - accuracy: 0.9818 - val_loss: 0.0540 - val_accuracy: 0.9829\n",
      "Epoch 838/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0522 - accuracy: 0.9819 - val_loss: 0.0539 - val_accuracy: 0.9829\n",
      "Epoch 839/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0521 - accuracy: 0.9819 - val_loss: 0.0539 - val_accuracy: 0.9828\n",
      "Epoch 840/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0521 - accuracy: 0.9820 - val_loss: 0.0538 - val_accuracy: 0.9829\n",
      "Epoch 841/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.0537 - val_accuracy: 0.9829\n",
      "Epoch 842/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0519 - accuracy: 0.9819 - val_loss: 0.0536 - val_accuracy: 0.9828\n",
      "Epoch 843/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 0.0537 - val_accuracy: 0.9828\n",
      "Epoch 844/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0518 - accuracy: 0.9820 - val_loss: 0.0535 - val_accuracy: 0.9829\n",
      "Epoch 845/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.0535 - val_accuracy: 0.9828\n",
      "Epoch 846/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.0534 - val_accuracy: 0.9828\n",
      "Epoch 847/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0516 - accuracy: 0.9820 - val_loss: 0.0533 - val_accuracy: 0.9828\n",
      "Epoch 848/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0533 - val_accuracy: 0.9829\n",
      "Epoch 849/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0531 - val_accuracy: 0.9828\n",
      "Epoch 850/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0514 - accuracy: 0.9819 - val_loss: 0.0531 - val_accuracy: 0.9829\n",
      "Epoch 851/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9820 - val_loss: 0.0530 - val_accuracy: 0.9828\n",
      "Epoch 852/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9820 - val_loss: 0.0530 - val_accuracy: 0.9828\n",
      "Epoch 853/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9820 - val_loss: 0.0529 - val_accuracy: 0.9828\n",
      "Epoch 854/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9819 - val_loss: 0.0529 - val_accuracy: 0.9829\n",
      "Epoch 855/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9821 - val_loss: 0.0528 - val_accuracy: 0.9829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.0527 - val_accuracy: 0.9828\n",
      "Epoch 857/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9820 - val_loss: 0.0527 - val_accuracy: 0.9829\n",
      "Epoch 858/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0509 - accuracy: 0.9819 - val_loss: 0.0527 - val_accuracy: 0.9828\n",
      "Epoch 859/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0508 - accuracy: 0.9820 - val_loss: 0.0526 - val_accuracy: 0.9828\n",
      "Epoch 860/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0508 - accuracy: 0.9820 - val_loss: 0.0525 - val_accuracy: 0.9829\n",
      "Epoch 861/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9820 - val_loss: 0.0524 - val_accuracy: 0.9828\n",
      "Epoch 862/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 0.0523 - val_accuracy: 0.9829\n",
      "Epoch 863/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 0.0524 - val_accuracy: 0.9828\n",
      "Epoch 864/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0505 - accuracy: 0.9820 - val_loss: 0.0522 - val_accuracy: 0.9830\n",
      "Epoch 865/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0505 - accuracy: 0.9820 - val_loss: 0.0523 - val_accuracy: 0.9828\n",
      "Epoch 866/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0504 - accuracy: 0.9821 - val_loss: 0.0521 - val_accuracy: 0.9828\n",
      "Epoch 867/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0504 - accuracy: 0.9821 - val_loss: 0.0521 - val_accuracy: 0.9827\n",
      "Epoch 868/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0503 - accuracy: 0.9821 - val_loss: 0.0520 - val_accuracy: 0.9827\n",
      "Epoch 869/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.0519 - val_accuracy: 0.9829\n",
      "Epoch 870/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 0.0520 - val_accuracy: 0.9826\n",
      "Epoch 871/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0501 - accuracy: 0.9821 - val_loss: 0.0518 - val_accuracy: 0.9829\n",
      "Epoch 872/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0501 - accuracy: 0.9822 - val_loss: 0.0519 - val_accuracy: 0.9827\n",
      "Epoch 873/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0500 - accuracy: 0.9822 - val_loss: 0.0517 - val_accuracy: 0.9829\n",
      "Epoch 874/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0499 - accuracy: 0.9822 - val_loss: 0.0517 - val_accuracy: 0.9826\n",
      "Epoch 875/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0499 - accuracy: 0.9821 - val_loss: 0.0516 - val_accuracy: 0.9827\n",
      "Epoch 876/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0498 - accuracy: 0.9821 - val_loss: 0.0516 - val_accuracy: 0.9827\n",
      "Epoch 877/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0498 - accuracy: 0.9822 - val_loss: 0.0516 - val_accuracy: 0.9826\n",
      "Epoch 878/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.0514 - val_accuracy: 0.9830\n",
      "Epoch 879/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0497 - accuracy: 0.9822 - val_loss: 0.0515 - val_accuracy: 0.9827\n",
      "Epoch 880/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0496 - accuracy: 0.9823 - val_loss: 0.0513 - val_accuracy: 0.9831\n",
      "Epoch 881/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 0.0513 - val_accuracy: 0.9827\n",
      "Epoch 882/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0495 - accuracy: 0.9822 - val_loss: 0.0513 - val_accuracy: 0.9827\n",
      "Epoch 883/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0495 - accuracy: 0.9822 - val_loss: 0.0512 - val_accuracy: 0.9827\n",
      "Epoch 884/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.0511 - val_accuracy: 0.9828\n",
      "Epoch 885/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9822 - val_loss: 0.0511 - val_accuracy: 0.9828\n",
      "Epoch 886/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0493 - accuracy: 0.9822 - val_loss: 0.0511 - val_accuracy: 0.9827\n",
      "Epoch 887/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9823 - val_loss: 0.0510 - val_accuracy: 0.9830\n",
      "Epoch 888/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9823 - val_loss: 0.0509 - val_accuracy: 0.9828\n",
      "Epoch 889/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0491 - accuracy: 0.9822 - val_loss: 0.0509 - val_accuracy: 0.9827\n",
      "Epoch 890/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.0509 - val_accuracy: 0.9830\n",
      "Epoch 891/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0490 - accuracy: 0.9822 - val_loss: 0.0508 - val_accuracy: 0.9830\n",
      "Epoch 892/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0490 - accuracy: 0.9823 - val_loss: 0.0508 - val_accuracy: 0.9827\n",
      "Epoch 893/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 0.0507 - val_accuracy: 0.9828\n",
      "Epoch 894/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 0.0507 - val_accuracy: 0.9827\n",
      "Epoch 895/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.0506 - val_accuracy: 0.9832\n",
      "Epoch 896/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 0.0506 - val_accuracy: 0.9826\n",
      "Epoch 897/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0487 - accuracy: 0.9823 - val_loss: 0.0505 - val_accuracy: 0.9832\n",
      "Epoch 898/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9823 - val_loss: 0.0504 - val_accuracy: 0.9832\n",
      "Epoch 899/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9824 - val_loss: 0.0504 - val_accuracy: 0.9832\n",
      "Epoch 900/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0486 - accuracy: 0.9824 - val_loss: 0.0504 - val_accuracy: 0.9833\n",
      "Epoch 901/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0485 - accuracy: 0.9824 - val_loss: 0.0504 - val_accuracy: 0.9829\n",
      "Epoch 902/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0485 - accuracy: 0.9826 - val_loss: 0.0504 - val_accuracy: 0.9829\n",
      "Epoch 903/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.0503 - val_accuracy: 0.9832\n",
      "Epoch 904/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0484 - accuracy: 0.9824 - val_loss: 0.0502 - val_accuracy: 0.9835\n",
      "Epoch 905/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 0.0501 - val_accuracy: 0.9835\n",
      "Epoch 906/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0501 - val_accuracy: 0.9835\n",
      "Epoch 907/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0501 - val_accuracy: 0.9831\n",
      "Epoch 908/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0500 - val_accuracy: 0.9835\n",
      "Epoch 909/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: 0.0499 - val_accuracy: 0.9836\n",
      "Epoch 910/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.0499 - val_accuracy: 0.9836\n",
      "Epoch 911/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.0499 - val_accuracy: 0.9836\n",
      "Epoch 912/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.0498 - val_accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0479 - accuracy: 0.9825 - val_loss: 0.0498 - val_accuracy: 0.9835\n",
      "Epoch 914/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0479 - accuracy: 0.9825 - val_loss: 0.0497 - val_accuracy: 0.9835\n",
      "Epoch 915/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.0497 - val_accuracy: 0.9835\n",
      "Epoch 916/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.0496 - val_accuracy: 0.9835\n",
      "Epoch 917/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.0497 - val_accuracy: 0.9835\n",
      "Epoch 918/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9826 - val_loss: 0.0496 - val_accuracy: 0.9835\n",
      "Epoch 919/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.0495 - val_accuracy: 0.9837\n",
      "Epoch 920/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.0494 - val_accuracy: 0.9837\n",
      "Epoch 921/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.0494 - val_accuracy: 0.9836\n",
      "Epoch 922/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9827 - val_loss: 0.0495 - val_accuracy: 0.9835\n",
      "Epoch 923/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0475 - accuracy: 0.9825 - val_loss: 0.0493 - val_accuracy: 0.9837\n",
      "Epoch 924/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 0.0494 - val_accuracy: 0.9835\n",
      "Epoch 925/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.0492 - val_accuracy: 0.9836\n",
      "Epoch 926/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.0493 - val_accuracy: 0.9836\n",
      "Epoch 927/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0473 - accuracy: 0.9826 - val_loss: 0.0492 - val_accuracy: 0.9837\n",
      "Epoch 928/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0472 - accuracy: 0.9826 - val_loss: 0.0492 - val_accuracy: 0.9837\n",
      "Epoch 929/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0472 - accuracy: 0.9826 - val_loss: 0.0491 - val_accuracy: 0.9837\n",
      "Epoch 930/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0471 - accuracy: 0.9826 - val_loss: 0.0490 - val_accuracy: 0.9837\n",
      "Epoch 931/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0471 - accuracy: 0.9826 - val_loss: 0.0490 - val_accuracy: 0.9838\n",
      "Epoch 932/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0471 - accuracy: 0.9826 - val_loss: 0.0490 - val_accuracy: 0.9838\n",
      "Epoch 933/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0470 - accuracy: 0.9826 - val_loss: 0.0489 - val_accuracy: 0.9839\n",
      "Epoch 934/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0469 - accuracy: 0.9827 - val_loss: 0.0489 - val_accuracy: 0.9838\n",
      "Epoch 935/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0469 - accuracy: 0.9826 - val_loss: 0.0489 - val_accuracy: 0.9838\n",
      "Epoch 936/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0469 - accuracy: 0.9827 - val_loss: 0.0489 - val_accuracy: 0.9838\n",
      "Epoch 937/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0468 - accuracy: 0.9828 - val_loss: 0.0489 - val_accuracy: 0.9839\n",
      "Epoch 938/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0468 - accuracy: 0.9827 - val_loss: 0.0488 - val_accuracy: 0.9838\n",
      "Epoch 939/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0467 - accuracy: 0.9828 - val_loss: 0.0488 - val_accuracy: 0.9840\n",
      "Epoch 940/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9827 - val_loss: 0.0486 - val_accuracy: 0.9839\n",
      "Epoch 941/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9829 - val_loss: 0.0487 - val_accuracy: 0.9840\n",
      "Epoch 942/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0466 - accuracy: 0.9828 - val_loss: 0.0486 - val_accuracy: 0.9840\n",
      "Epoch 943/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0466 - accuracy: 0.9828 - val_loss: 0.0485 - val_accuracy: 0.9839\n",
      "Epoch 944/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0465 - accuracy: 0.9828 - val_loss: 0.0485 - val_accuracy: 0.9840\n",
      "Epoch 945/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0465 - accuracy: 0.9829 - val_loss: 0.0485 - val_accuracy: 0.9840\n",
      "Epoch 946/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 0.0485 - val_accuracy: 0.9840\n",
      "Epoch 947/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 0.0484 - val_accuracy: 0.9841\n",
      "Epoch 948/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0464 - accuracy: 0.9830 - val_loss: 0.0484 - val_accuracy: 0.9840\n",
      "Epoch 949/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0463 - accuracy: 0.9829 - val_loss: 0.0484 - val_accuracy: 0.9840\n",
      "Epoch 950/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0463 - accuracy: 0.9829 - val_loss: 0.0484 - val_accuracy: 0.9840\n",
      "Epoch 951/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0463 - accuracy: 0.9828 - val_loss: 0.0483 - val_accuracy: 0.9840\n",
      "Epoch 952/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0462 - accuracy: 0.9829 - val_loss: 0.0482 - val_accuracy: 0.9841\n",
      "Epoch 953/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0462 - accuracy: 0.9830 - val_loss: 0.0482 - val_accuracy: 0.9840\n",
      "Epoch 954/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0461 - accuracy: 0.9830 - val_loss: 0.0481 - val_accuracy: 0.9841\n",
      "Epoch 955/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9830 - val_loss: 0.0481 - val_accuracy: 0.9841\n",
      "Epoch 956/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0460 - accuracy: 0.9830 - val_loss: 0.0481 - val_accuracy: 0.9841\n",
      "Epoch 957/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0460 - accuracy: 0.9830 - val_loss: 0.0481 - val_accuracy: 0.9840\n",
      "Epoch 958/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0460 - accuracy: 0.9830 - val_loss: 0.0480 - val_accuracy: 0.9841\n",
      "Epoch 959/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9830 - val_loss: 0.0480 - val_accuracy: 0.9840\n",
      "Epoch 960/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 0.0479 - val_accuracy: 0.9841\n",
      "Epoch 961/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0458 - accuracy: 0.9830 - val_loss: 0.0479 - val_accuracy: 0.9843\n",
      "Epoch 962/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.0482 - val_accuracy: 0.9840\n",
      "Epoch 963/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 0.0478 - val_accuracy: 0.9842\n",
      "Epoch 964/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.0478 - val_accuracy: 0.9841\n",
      "Epoch 965/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 0.0478 - val_accuracy: 0.9841\n",
      "Epoch 966/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 0.0478 - val_accuracy: 0.9842\n",
      "Epoch 967/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 0.0477 - val_accuracy: 0.9843\n",
      "Epoch 968/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 0.0477 - val_accuracy: 0.9842\n",
      "Epoch 969/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 0.0476 - val_accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0455 - accuracy: 0.9833 - val_loss: 0.0476 - val_accuracy: 0.9842\n",
      "Epoch 971/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0454 - accuracy: 0.9833 - val_loss: 0.0475 - val_accuracy: 0.9841\n",
      "Epoch 972/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0454 - accuracy: 0.9833 - val_loss: 0.0476 - val_accuracy: 0.9842\n",
      "Epoch 973/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0454 - accuracy: 0.9833 - val_loss: 0.0475 - val_accuracy: 0.9842\n",
      "Epoch 974/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 0.0475 - val_accuracy: 0.9842\n",
      "Epoch 975/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 0.0474 - val_accuracy: 0.9842\n",
      "Epoch 976/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9834 - val_loss: 0.0475 - val_accuracy: 0.9841\n",
      "Epoch 977/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0452 - accuracy: 0.9834 - val_loss: 0.0474 - val_accuracy: 0.9842\n",
      "Epoch 978/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0452 - accuracy: 0.9834 - val_loss: 0.0473 - val_accuracy: 0.9842\n",
      "Epoch 979/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.0475 - val_accuracy: 0.9841\n",
      "Epoch 980/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.0473 - val_accuracy: 0.9843\n",
      "Epoch 981/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.0472 - val_accuracy: 0.9843\n",
      "Epoch 982/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.0473 - val_accuracy: 0.9842\n",
      "Epoch 983/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.0472 - val_accuracy: 0.9843\n",
      "Epoch 984/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.0471 - val_accuracy: 0.9843\n",
      "Epoch 985/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0449 - accuracy: 0.9835 - val_loss: 0.0471 - val_accuracy: 0.9843\n",
      "Epoch 986/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0449 - accuracy: 0.9835 - val_loss: 0.0471 - val_accuracy: 0.9842\n",
      "Epoch 987/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0449 - accuracy: 0.9834 - val_loss: 0.0471 - val_accuracy: 0.9843\n",
      "Epoch 988/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0448 - accuracy: 0.9835 - val_loss: 0.0470 - val_accuracy: 0.9844\n",
      "Epoch 989/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0448 - accuracy: 0.9835 - val_loss: 0.0470 - val_accuracy: 0.9845\n",
      "Epoch 990/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0448 - accuracy: 0.9836 - val_loss: 0.0470 - val_accuracy: 0.9845\n",
      "Epoch 991/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0447 - accuracy: 0.9836 - val_loss: 0.0469 - val_accuracy: 0.9845\n",
      "Epoch 992/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0447 - accuracy: 0.9835 - val_loss: 0.0469 - val_accuracy: 0.9844\n",
      "Epoch 993/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9835 - val_loss: 0.0470 - val_accuracy: 0.9846\n",
      "Epoch 994/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9835 - val_loss: 0.0468 - val_accuracy: 0.9845\n",
      "Epoch 995/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0446 - accuracy: 0.9836 - val_loss: 0.0468 - val_accuracy: 0.9845\n",
      "Epoch 996/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0445 - accuracy: 0.9836 - val_loss: 0.0469 - val_accuracy: 0.9846\n",
      "Epoch 997/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0445 - accuracy: 0.9835 - val_loss: 0.0468 - val_accuracy: 0.9846\n",
      "Epoch 998/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0445 - accuracy: 0.9836 - val_loss: 0.0468 - val_accuracy: 0.9847\n",
      "Epoch 999/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.0467 - val_accuracy: 0.9848\n",
      "Epoch 1000/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0444 - accuracy: 0.9835 - val_loss: 0.0467 - val_accuracy: 0.9847\n",
      "Epoch 1001/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.0467 - val_accuracy: 0.9848\n",
      "Epoch 1002/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0443 - accuracy: 0.9837 - val_loss: 0.0467 - val_accuracy: 0.9848\n",
      "Epoch 1003/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0443 - accuracy: 0.9836 - val_loss: 0.0466 - val_accuracy: 0.9848\n",
      "Epoch 1004/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0443 - accuracy: 0.9837 - val_loss: 0.0467 - val_accuracy: 0.9848\n",
      "Epoch 1005/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9836 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 1006/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9836 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 1007/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0442 - accuracy: 0.9837 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 1008/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 1009/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.0464 - val_accuracy: 0.9848\n",
      "Epoch 1010/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0441 - accuracy: 0.9837 - val_loss: 0.0464 - val_accuracy: 0.9848\n",
      "Epoch 1011/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0440 - accuracy: 0.9836 - val_loss: 0.0464 - val_accuracy: 0.9846\n",
      "Epoch 1012/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9848\n",
      "Epoch 1013/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0440 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9848\n",
      "Epoch 1014/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9848\n",
      "Epoch 1015/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9848\n",
      "Epoch 1016/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9850\n",
      "Epoch 1017/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9848\n",
      "Epoch 1018/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0438 - accuracy: 0.9836 - val_loss: 0.0462 - val_accuracy: 0.9848\n",
      "Epoch 1019/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0438 - accuracy: 0.9837 - val_loss: 0.0461 - val_accuracy: 0.9847\n",
      "Epoch 1020/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0437 - accuracy: 0.9838 - val_loss: 0.0461 - val_accuracy: 0.9847\n",
      "Epoch 1021/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0437 - accuracy: 0.9838 - val_loss: 0.0461 - val_accuracy: 0.9848\n",
      "Epoch 1022/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9839 - val_loss: 0.0461 - val_accuracy: 0.9848\n",
      "Epoch 1023/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.0461 - val_accuracy: 0.9848\n",
      "Epoch 1024/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.0462 - val_accuracy: 0.9849\n",
      "Epoch 1025/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9838 - val_loss: 0.0460 - val_accuracy: 0.9849\n",
      "Epoch 1026/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.0460 - val_accuracy: 0.9847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9838 - val_loss: 0.0460 - val_accuracy: 0.9848\n",
      "Epoch 1028/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9838 - val_loss: 0.0460 - val_accuracy: 0.9849\n",
      "Epoch 1029/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9839 - val_loss: 0.0459 - val_accuracy: 0.9848\n",
      "Epoch 1030/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0434 - accuracy: 0.9839 - val_loss: 0.0459 - val_accuracy: 0.9850\n",
      "Epoch 1031/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0434 - accuracy: 0.9840 - val_loss: 0.0458 - val_accuracy: 0.9848\n",
      "Epoch 1032/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0434 - accuracy: 0.9838 - val_loss: 0.0458 - val_accuracy: 0.9848\n",
      "Epoch 1033/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 0.0459 - val_accuracy: 0.9849\n",
      "Epoch 1034/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0433 - accuracy: 0.9840 - val_loss: 0.0458 - val_accuracy: 0.9848\n",
      "Epoch 1035/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0433 - accuracy: 0.9839 - val_loss: 0.0458 - val_accuracy: 0.9848\n",
      "Epoch 1036/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9839 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
      "Epoch 1037/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9840 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
      "Epoch 1038/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9839 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
      "Epoch 1039/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0432 - accuracy: 0.9840 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
      "Epoch 1040/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 0.0456 - val_accuracy: 0.9848\n",
      "Epoch 1041/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 0.0457 - val_accuracy: 0.9847\n",
      "Epoch 1042/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 0.0456 - val_accuracy: 0.9848\n",
      "Epoch 1043/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 0.0456 - val_accuracy: 0.9848\n",
      "Epoch 1044/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 0.0455 - val_accuracy: 0.9848\n",
      "Epoch 1045/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9840 - val_loss: 0.0455 - val_accuracy: 0.9848\n",
      "Epoch 1046/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 0.0455 - val_accuracy: 0.9847\n",
      "Epoch 1047/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0429 - accuracy: 0.9840 - val_loss: 0.0455 - val_accuracy: 0.9848\n",
      "Epoch 1048/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0429 - accuracy: 0.9840 - val_loss: 0.0454 - val_accuracy: 0.9847\n",
      "Epoch 1049/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 0.0454 - val_accuracy: 0.9847\n",
      "Epoch 1050/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.0454 - val_accuracy: 0.9848\n",
      "Epoch 1051/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0428 - accuracy: 0.9841 - val_loss: 0.0454 - val_accuracy: 0.9847\n",
      "Epoch 1052/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.0454 - val_accuracy: 0.9848\n",
      "Epoch 1053/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0427 - accuracy: 0.9841 - val_loss: 0.0454 - val_accuracy: 0.9848\n",
      "Epoch 1054/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0427 - accuracy: 0.9841 - val_loss: 0.0454 - val_accuracy: 0.9848\n",
      "Epoch 1055/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0427 - accuracy: 0.9843 - val_loss: 0.0453 - val_accuracy: 0.9848\n",
      "Epoch 1056/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.0452 - val_accuracy: 0.9848\n",
      "Epoch 1057/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.0454 - val_accuracy: 0.9849\n",
      "Epoch 1058/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.0452 - val_accuracy: 0.9848\n",
      "Epoch 1059/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.0452 - val_accuracy: 0.9847\n",
      "Epoch 1060/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0425 - accuracy: 0.9842 - val_loss: 0.0452 - val_accuracy: 0.9848\n",
      "Epoch 1061/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0425 - accuracy: 0.9843 - val_loss: 0.0451 - val_accuracy: 0.9848\n",
      "Epoch 1062/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0425 - accuracy: 0.9841 - val_loss: 0.0451 - val_accuracy: 0.9849\n",
      "Epoch 1063/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0425 - accuracy: 0.9843 - val_loss: 0.0451 - val_accuracy: 0.9848\n",
      "Epoch 1064/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9843 - val_loss: 0.0451 - val_accuracy: 0.9847\n",
      "Epoch 1065/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9842 - val_loss: 0.0451 - val_accuracy: 0.9849\n",
      "Epoch 1066/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9843 - val_loss: 0.0451 - val_accuracy: 0.9848\n",
      "Epoch 1067/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9843 - val_loss: 0.0450 - val_accuracy: 0.9848\n",
      "Epoch 1068/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9843 - val_loss: 0.0450 - val_accuracy: 0.9847\n",
      "Epoch 1069/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0423 - accuracy: 0.9843 - val_loss: 0.0450 - val_accuracy: 0.9848\n",
      "Epoch 1070/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0422 - accuracy: 0.9843 - val_loss: 0.0449 - val_accuracy: 0.9848\n",
      "Epoch 1071/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0422 - accuracy: 0.9843 - val_loss: 0.0449 - val_accuracy: 0.9848\n",
      "Epoch 1072/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0422 - accuracy: 0.9843 - val_loss: 0.0449 - val_accuracy: 0.9848\n",
      "Epoch 1073/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0422 - accuracy: 0.9843 - val_loss: 0.0449 - val_accuracy: 0.9847\n",
      "Epoch 1074/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.0448 - val_accuracy: 0.9847\n",
      "Epoch 1075/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0421 - accuracy: 0.9843 - val_loss: 0.0449 - val_accuracy: 0.9851\n",
      "Epoch 1076/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0421 - accuracy: 0.9842 - val_loss: 0.0448 - val_accuracy: 0.9849\n",
      "Epoch 1077/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0421 - accuracy: 0.9843 - val_loss: 0.0448 - val_accuracy: 0.9849\n",
      "Epoch 1078/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.0448 - val_accuracy: 0.9849\n",
      "Epoch 1079/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.0448 - val_accuracy: 0.9849\n",
      "Epoch 1080/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.0447 - val_accuracy: 0.9851\n",
      "Epoch 1081/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.0447 - val_accuracy: 0.9851\n",
      "Epoch 1082/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.0447 - val_accuracy: 0.9851\n",
      "Epoch 1083/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 0.0447 - val_accuracy: 0.9849\n",
      "Epoch 1084/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 0.0447 - val_accuracy: 0.9849\n",
      "Epoch 1085/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0418 - accuracy: 0.9846 - val_loss: 0.0446 - val_accuracy: 0.9851\n",
      "Epoch 1086/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0418 - accuracy: 0.9845 - val_loss: 0.0446 - val_accuracy: 0.9852\n",
      "Epoch 1087/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0418 - accuracy: 0.9846 - val_loss: 0.0446 - val_accuracy: 0.9852\n",
      "Epoch 1088/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0418 - accuracy: 0.9845 - val_loss: 0.0446 - val_accuracy: 0.9849\n",
      "Epoch 1089/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 0.0445 - val_accuracy: 0.9849\n",
      "Epoch 1090/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0417 - accuracy: 0.9844 - val_loss: 0.0446 - val_accuracy: 0.9849\n",
      "Epoch 1091/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 0.0445 - val_accuracy: 0.9852\n",
      "Epoch 1092/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0416 - accuracy: 0.9845 - val_loss: 0.0445 - val_accuracy: 0.9851\n",
      "Epoch 1093/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9845 - val_loss: 0.0444 - val_accuracy: 0.9853\n",
      "Epoch 1094/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.0444 - val_accuracy: 0.9852\n",
      "Epoch 1095/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.0445 - val_accuracy: 0.9852\n",
      "Epoch 1096/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 0.0444 - val_accuracy: 0.9852\n",
      "Epoch 1097/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0415 - accuracy: 0.9846 - val_loss: 0.0445 - val_accuracy: 0.9849\n",
      "Epoch 1098/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0415 - accuracy: 0.9846 - val_loss: 0.0444 - val_accuracy: 0.9852\n",
      "Epoch 1099/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0415 - accuracy: 0.9847 - val_loss: 0.0444 - val_accuracy: 0.9852\n",
      "Epoch 1100/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0443 - val_accuracy: 0.9853\n",
      "Epoch 1101/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "Epoch 1102/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "Epoch 1103/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "Epoch 1104/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "Epoch 1105/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "Epoch 1106/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "Epoch 1107/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9848 - val_loss: 0.0442 - val_accuracy: 0.9852\n",
      "Epoch 1108/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0413 - accuracy: 0.9849 - val_loss: 0.0442 - val_accuracy: 0.9852\n",
      "Epoch 1109/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0412 - accuracy: 0.9849 - val_loss: 0.0441 - val_accuracy: 0.9854\n",
      "Epoch 1110/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0412 - accuracy: 0.9849 - val_loss: 0.0441 - val_accuracy: 0.9853\n",
      "Epoch 1111/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0412 - accuracy: 0.9848 - val_loss: 0.0441 - val_accuracy: 0.9853\n",
      "Epoch 1112/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0412 - accuracy: 0.9848 - val_loss: 0.0441 - val_accuracy: 0.9853\n",
      "Epoch 1113/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.0441 - val_accuracy: 0.9852\n",
      "Epoch 1114/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0411 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9854\n",
      "Epoch 1115/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.0440 - val_accuracy: 0.9854\n",
      "Epoch 1116/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0411 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9853\n",
      "Epoch 1117/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9854\n",
      "Epoch 1118/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9854\n",
      "Epoch 1119/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9852\n",
      "Epoch 1120/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0409 - accuracy: 0.9849 - val_loss: 0.0439 - val_accuracy: 0.9854\n",
      "Epoch 1121/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9849 - val_loss: 0.0439 - val_accuracy: 0.9854\n",
      "Epoch 1122/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 0.0439 - val_accuracy: 0.9853\n",
      "Epoch 1123/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9849 - val_loss: 0.0439 - val_accuracy: 0.9853\n",
      "Epoch 1124/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0409 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9852\n",
      "Epoch 1125/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0408 - accuracy: 0.9849 - val_loss: 0.0439 - val_accuracy: 0.9853\n",
      "Epoch 1126/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0408 - accuracy: 0.9849 - val_loss: 0.0438 - val_accuracy: 0.9854\n",
      "Epoch 1127/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0408 - accuracy: 0.9850 - val_loss: 0.0439 - val_accuracy: 0.9853\n",
      "Epoch 1128/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 0.0438 - val_accuracy: 0.9853\n",
      "Epoch 1129/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9850 - val_loss: 0.0438 - val_accuracy: 0.9853\n",
      "Epoch 1130/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9849 - val_loss: 0.0438 - val_accuracy: 0.9853\n",
      "Epoch 1131/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9849 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
      "Epoch 1132/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 0.0438 - val_accuracy: 0.9853\n",
      "Epoch 1133/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
      "Epoch 1134/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0406 - accuracy: 0.9850 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
      "Epoch 1135/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0406 - accuracy: 0.9850 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
      "Epoch 1136/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
      "Epoch 1137/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.0436 - val_accuracy: 0.9855\n",
      "Epoch 1138/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.0436 - val_accuracy: 0.9855\n",
      "Epoch 1139/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.0436 - val_accuracy: 0.9855\n",
      "Epoch 1140/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.0436 - val_accuracy: 0.9855\n",
      "Epoch 1141/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.0436 - val_accuracy: 0.9855\n",
      "Epoch 1142/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9850 - val_loss: 0.0436 - val_accuracy: 0.9855\n",
      "Epoch 1143/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0404 - accuracy: 0.9849 - val_loss: 0.0436 - val_accuracy: 0.9853\n",
      "Epoch 1144/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0404 - accuracy: 0.9850 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 1145/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0404 - accuracy: 0.9850 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 1146/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0403 - accuracy: 0.9851 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 1147/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9850 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 1148/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9850 - val_loss: 0.0435 - val_accuracy: 0.9854\n",
      "Epoch 1149/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9851 - val_loss: 0.0435 - val_accuracy: 0.9855\n",
      "Epoch 1150/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.0435 - val_accuracy: 0.9854\n",
      "Epoch 1151/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 0.0435 - val_accuracy: 0.9854\n",
      "Epoch 1152/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 0.0434 - val_accuracy: 0.9854\n",
      "Epoch 1153/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.0434 - val_accuracy: 0.9854\n",
      "Epoch 1154/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.0434 - val_accuracy: 0.9855\n",
      "Epoch 1155/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9850 - val_loss: 0.0435 - val_accuracy: 0.9854\n",
      "Epoch 1156/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9851 - val_loss: 0.0434 - val_accuracy: 0.9855\n",
      "Epoch 1157/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9852 - val_loss: 0.0433 - val_accuracy: 0.9855\n",
      "Epoch 1158/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9855\n",
      "Epoch 1159/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9854\n",
      "Epoch 1160/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9855\n",
      "Epoch 1161/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9855\n",
      "Epoch 1162/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9854\n",
      "Epoch 1163/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.0432 - val_accuracy: 0.9855\n",
      "Epoch 1164/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0399 - accuracy: 0.9852 - val_loss: 0.0433 - val_accuracy: 0.9854\n",
      "Epoch 1165/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0399 - accuracy: 0.9851 - val_loss: 0.0434 - val_accuracy: 0.9854\n",
      "Epoch 1166/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0399 - accuracy: 0.9851 - val_loss: 0.0433 - val_accuracy: 0.9854\n",
      "Epoch 1167/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0399 - accuracy: 0.9852 - val_loss: 0.0432 - val_accuracy: 0.9854\n",
      "Epoch 1168/2048\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.0399 - accuracy: 0.9852 - val_loss: 0.0433 - val_accuracy: 0.9854\n",
      "Epoch 1169/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.0431 - val_accuracy: 0.9855\n",
      "Epoch 1170/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0398 - accuracy: 0.9851 - val_loss: 0.0431 - val_accuracy: 0.9855\n",
      "Epoch 1171/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.0431 - val_accuracy: 0.9855\n",
      "Epoch 1172/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0398 - accuracy: 0.9851 - val_loss: 0.0431 - val_accuracy: 0.9855\n",
      "Epoch 1173/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.0431 - val_accuracy: 0.9855\n",
      "Epoch 1174/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.0431 - val_accuracy: 0.9855\n",
      "Epoch 1175/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.0431 - val_accuracy: 0.9855\n",
      "Epoch 1176/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.0431 - val_accuracy: 0.9854\n",
      "Epoch 1177/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9853 - val_loss: 0.0431 - val_accuracy: 0.9854\n",
      "Epoch 1178/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 0.0430 - val_accuracy: 0.9855\n",
      "Epoch 1179/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 0.0430 - val_accuracy: 0.9855\n",
      "Epoch 1180/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 0.0430 - val_accuracy: 0.9854\n",
      "Epoch 1181/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.0430 - val_accuracy: 0.9854\n",
      "Epoch 1182/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.0430 - val_accuracy: 0.9855\n",
      "Epoch 1183/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0395 - accuracy: 0.9852 - val_loss: 0.0430 - val_accuracy: 0.9854\n",
      "Epoch 1184/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9855\n",
      "Epoch 1185/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9855\n",
      "Epoch 1186/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9855\n",
      "Epoch 1187/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0395 - accuracy: 0.9852 - val_loss: 0.0429 - val_accuracy: 0.9855\n",
      "Epoch 1188/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9855\n",
      "Epoch 1189/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9854\n",
      "Epoch 1190/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9854\n",
      "Epoch 1191/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 1192/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 1193/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.0429 - val_accuracy: 0.9854\n",
      "Epoch 1194/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0393 - accuracy: 0.9854 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 1195/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0393 - accuracy: 0.9854 - val_loss: 0.0428 - val_accuracy: 0.9854\n",
      "Epoch 1196/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0393 - accuracy: 0.9854 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 1197/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 1198/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0392 - accuracy: 0.9853 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 1199/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 0.0428 - val_accuracy: 0.9855\n",
      "Epoch 1200/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 0.0427 - val_accuracy: 0.9856\n",
      "Epoch 1201/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 0.0427 - val_accuracy: 0.9855\n",
      "Epoch 1202/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0427 - val_accuracy: 0.9855\n",
      "Epoch 1203/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0427 - val_accuracy: 0.9855\n",
      "Epoch 1204/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0426 - val_accuracy: 0.9855\n",
      "Epoch 1205/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0426 - val_accuracy: 0.9856\n",
      "Epoch 1206/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0426 - val_accuracy: 0.9855\n",
      "Epoch 1207/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9853 - val_loss: 0.0426 - val_accuracy: 0.9856\n",
      "Epoch 1208/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0427 - val_accuracy: 0.9854\n",
      "Epoch 1209/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0390 - accuracy: 0.9854 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 1210/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 1211/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 0.0426 - val_accuracy: 0.9855\n",
      "Epoch 1212/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 1213/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 1214/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.0426 - val_accuracy: 0.9855\n",
      "Epoch 1215/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.0425 - val_accuracy: 0.9855\n",
      "Epoch 1216/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 1217/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 1218/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 1219/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 1220/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 1221/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0426 - val_accuracy: 0.9857\n",
      "Epoch 1222/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0425 - val_accuracy: 0.9856\n",
      "Epoch 1223/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 1224/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9856 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 1225/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9855 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 1226/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9856 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 1227/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9856 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 1228/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0387 - accuracy: 0.9856 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
      "Epoch 1229/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.0424 - val_accuracy: 0.9856\n",
      "Epoch 1230/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
      "Epoch 1231/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
      "Epoch 1232/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
      "Epoch 1233/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
      "Epoch 1234/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
      "Epoch 1235/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
      "Epoch 1236/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9856 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1237/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1238/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9858 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1239/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1240/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1241/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1242/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9856 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1243/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9859\n",
      "Epoch 1244/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0384 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1245/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0384 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9857\n",
      "Epoch 1246/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 0.0422 - val_accuracy: 0.9856\n",
      "Epoch 1247/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9857\n",
      "Epoch 1248/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 1249/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0383 - accuracy: 0.9858 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 1250/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 1251/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0383 - accuracy: 0.9859 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 1252/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 1253/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9859\n",
      "Epoch 1254/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9857 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 1255/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9857 - val_loss: 0.0420 - val_accuracy: 0.9857\n",
      "Epoch 1256/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9858 - val_loss: 0.0421 - val_accuracy: 0.9859\n",
      "Epoch 1257/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9857 - val_loss: 0.0420 - val_accuracy: 0.9857\n",
      "Epoch 1258/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.0420 - val_accuracy: 0.9857\n",
      "Epoch 1259/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0381 - accuracy: 0.9857 - val_loss: 0.0420 - val_accuracy: 0.9856\n",
      "Epoch 1260/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.0420 - val_accuracy: 0.9857\n",
      "Epoch 1261/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0381 - accuracy: 0.9857 - val_loss: 0.0420 - val_accuracy: 0.9859\n",
      "Epoch 1262/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.0420 - val_accuracy: 0.9859\n",
      "Epoch 1263/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9858 - val_loss: 0.0419 - val_accuracy: 0.9857\n",
      "Epoch 1264/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0380 - accuracy: 0.9858 - val_loss: 0.0419 - val_accuracy: 0.9857\n",
      "Epoch 1265/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9858 - val_loss: 0.0420 - val_accuracy: 0.9859\n",
      "Epoch 1266/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 0.0419 - val_accuracy: 0.9856\n",
      "Epoch 1267/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9858 - val_loss: 0.0419 - val_accuracy: 0.9859\n",
      "Epoch 1268/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 0.0419 - val_accuracy: 0.9856\n",
      "Epoch 1269/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.0419 - val_accuracy: 0.9856\n",
      "Epoch 1270/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.0419 - val_accuracy: 0.9859\n",
      "Epoch 1271/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.0419 - val_accuracy: 0.9859\n",
      "Epoch 1272/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.0418 - val_accuracy: 0.9857\n",
      "Epoch 1273/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.0418 - val_accuracy: 0.9856\n",
      "Epoch 1274/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 0.0418 - val_accuracy: 0.9857\n",
      "Epoch 1275/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 0.0418 - val_accuracy: 0.9857\n",
      "Epoch 1276/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.0418 - val_accuracy: 0.9856\n",
      "Epoch 1277/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.0418 - val_accuracy: 0.9856\n",
      "Epoch 1278/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.0418 - val_accuracy: 0.9859\n",
      "Epoch 1279/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.0418 - val_accuracy: 0.9857\n",
      "Epoch 1280/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.0418 - val_accuracy: 0.9857\n",
      "Epoch 1281/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9858 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1282/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1283/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.9857\n",
      "Epoch 1284/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.9858\n",
      "Epoch 1285/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1286/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1287/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1288/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0376 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1289/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0376 - accuracy: 0.9858 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1290/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9859 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
      "Epoch 1291/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0376 - accuracy: 0.9858 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 1292/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.0416 - val_accuracy: 0.9858\n",
      "Epoch 1293/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.0416 - val_accuracy: 0.9860\n",
      "Epoch 1294/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
      "Epoch 1295/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
      "Epoch 1296/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
      "Epoch 1297/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.0416 - val_accuracy: 0.9858\n",
      "Epoch 1298/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
      "Epoch 1299/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.0416 - val_accuracy: 0.9860\n",
      "Epoch 1300/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0374 - accuracy: 0.9860 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
      "Epoch 1301/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9861\n",
      "Epoch 1302/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9859 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
      "Epoch 1303/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9861 - val_loss: 0.0415 - val_accuracy: 0.9861\n",
      "Epoch 1304/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9859 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 1305/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9858\n",
      "Epoch 1306/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9859 - val_loss: 0.0416 - val_accuracy: 0.9859\n",
      "Epoch 1307/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 1308/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 1309/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 1310/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 1311/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9858\n",
      "Epoch 1312/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 1313/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.0414 - val_accuracy: 0.9862\n",
      "Epoch 1314/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 1315/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9862\n",
      "Epoch 1316/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 1317/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 1318/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.0414 - val_accuracy: 0.9862\n",
      "Epoch 1319/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 0.0414 - val_accuracy: 0.9862\n",
      "Epoch 1320/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 1321/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 0.0414 - val_accuracy: 0.9863\n",
      "Epoch 1322/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 0.0414 - val_accuracy: 0.9863\n",
      "Epoch 1323/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 1324/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9862 - val_loss: 0.0414 - val_accuracy: 0.9861\n",
      "Epoch 1325/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9860 - val_loss: 0.0413 - val_accuracy: 0.9863\n",
      "Epoch 1326/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9862 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 1327/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9864\n",
      "Epoch 1328/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9864\n",
      "Epoch 1329/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.0413 - val_accuracy: 0.9864\n",
      "Epoch 1330/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 1331/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 1332/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0370 - accuracy: 0.9862 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 1333/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9860 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 1334/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 1335/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9862\n",
      "Epoch 1336/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9864\n",
      "Epoch 1337/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0414 - val_accuracy: 0.9860\n",
      "Epoch 1338/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9863\n",
      "Epoch 1339/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9862\n",
      "Epoch 1340/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9859\n",
      "Epoch 1341/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9861\n",
      "Epoch 1342/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9864\n",
      "Epoch 1343/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9864\n",
      "Epoch 1344/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9862\n",
      "Epoch 1345/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9864\n",
      "Epoch 1346/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0368 - accuracy: 0.9860 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1347/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1348/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1349/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1350/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9862\n",
      "Epoch 1351/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1352/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.0412 - val_accuracy: 0.9861\n",
      "Epoch 1353/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1354/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1355/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1356/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1357/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1358/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0366 - accuracy: 0.9862 - val_loss: 0.0410 - val_accuracy: 0.9864\n",
      "Epoch 1359/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9864\n",
      "Epoch 1360/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0366 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9864\n",
      "Epoch 1361/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 1362/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9863\n",
      "Epoch 1363/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9862 - val_loss: 0.0410 - val_accuracy: 0.9864\n",
      "Epoch 1364/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.0411 - val_accuracy: 0.9859\n",
      "Epoch 1365/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 1366/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 1367/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9864\n",
      "Epoch 1368/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9864\n",
      "Epoch 1369/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9861\n",
      "Epoch 1370/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 1371/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 1372/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 1373/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 0.0410 - val_accuracy: 0.9860\n",
      "Epoch 1374/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9861 - val_loss: 0.0409 - val_accuracy: 0.9863\n",
      "Epoch 1375/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9862 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 1376/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.0409 - val_accuracy: 0.9864\n",
      "Epoch 1377/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9864\n",
      "Epoch 1378/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.0409 - val_accuracy: 0.9863\n",
      "Epoch 1379/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9864\n",
      "Epoch 1380/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0363 - accuracy: 0.9863 - val_loss: 0.0410 - val_accuracy: 0.9862\n",
      "Epoch 1381/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.0409 - val_accuracy: 0.9864\n",
      "Epoch 1382/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9864\n",
      "Epoch 1383/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.0409 - val_accuracy: 0.9863\n",
      "Epoch 1384/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9864\n",
      "Epoch 1385/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0362 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9864\n",
      "Epoch 1386/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0362 - accuracy: 0.9861 - val_loss: 0.0408 - val_accuracy: 0.9864\n",
      "Epoch 1387/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0362 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9862\n",
      "Epoch 1388/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0362 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9863\n",
      "Epoch 1389/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0362 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9864\n",
      "Epoch 1390/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9863\n",
      "Epoch 1391/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9857\n",
      "Epoch 1392/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9864\n",
      "Epoch 1393/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9864\n",
      "Epoch 1394/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9863\n",
      "Epoch 1395/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0361 - accuracy: 0.9861 - val_loss: 0.0409 - val_accuracy: 0.9858\n",
      "Epoch 1396/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9864\n",
      "Epoch 1397/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9864\n",
      "Epoch 1398/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9863 - val_loss: 0.0408 - val_accuracy: 0.9863\n",
      "Epoch 1399/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9862 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
      "Epoch 1400/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9862 - val_loss: 0.0409 - val_accuracy: 0.9858\n",
      "Epoch 1401/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9863\n",
      "Epoch 1402/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
      "Epoch 1403/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1404/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1405/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1406/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1407/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1408/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9863\n",
      "Epoch 1409/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9863 - val_loss: 0.0408 - val_accuracy: 0.9860\n",
      "Epoch 1410/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1411/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9863 - val_loss: 0.0409 - val_accuracy: 0.9856\n",
      "Epoch 1412/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9862 - val_loss: 0.0407 - val_accuracy: 0.9861\n",
      "Epoch 1413/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9862 - val_loss: 0.0407 - val_accuracy: 0.9863\n",
      "Epoch 1414/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0359 - accuracy: 0.9862 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1415/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0358 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1416/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0358 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9863\n",
      "Epoch 1417/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9864 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1418/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9862 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1419/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1420/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0357 - accuracy: 0.9862 - val_loss: 0.0407 - val_accuracy: 0.9862\n",
      "Epoch 1421/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0358 - accuracy: 0.9862 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1422/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0358 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1423/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9864 - val_loss: 0.0406 - val_accuracy: 0.9863\n",
      "Epoch 1424/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1425/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1426/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9863\n",
      "Epoch 1427/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1428/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0407 - val_accuracy: 0.9860\n",
      "Epoch 1429/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9863\n",
      "Epoch 1430/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1431/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1432/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1433/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0406 - val_accuracy: 0.9862\n",
      "Epoch 1434/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1435/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1436/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1437/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1438/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1439/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9861\n",
      "Epoch 1440/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1441/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 0.0406 - val_accuracy: 0.9863\n",
      "Epoch 1442/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0355 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9861\n",
      "Epoch 1443/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1444/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1445/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9863\n",
      "Epoch 1446/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0406 - val_accuracy: 0.9860\n",
      "Epoch 1447/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0355 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 1448/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9863\n",
      "Epoch 1449/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0405 - val_accuracy: 0.9860\n",
      "Epoch 1450/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1451/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9861\n",
      "Epoch 1452/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9864 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1453/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1454/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1455/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
      "Epoch 1456/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
      "Epoch 1457/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0354 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1458/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1459/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1460/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1461/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
      "Epoch 1462/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 0.0405 - val_accuracy: 0.9861\n",
      "Epoch 1463/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9862\n",
      "Epoch 1464/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
      "Epoch 1465/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
      "Epoch 1466/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9864 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
      "Epoch 1467/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1468/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9860\n",
      "Epoch 1469/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1470/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1471/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9861\n",
      "Epoch 1472/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0404 - val_accuracy: 0.9859\n",
      "Epoch 1473/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1474/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0403 - val_accuracy: 0.9863\n",
      "Epoch 1475/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0403 - val_accuracy: 0.9863\n",
      "Epoch 1476/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.0404 - val_accuracy: 0.9861\n",
      "Epoch 1477/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1478/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1479/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9863\n",
      "Epoch 1480/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9865 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1481/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1482/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1483/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1484/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9865 - val_loss: 0.0402 - val_accuracy: 0.9864\n",
      "Epoch 1485/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9863\n",
      "Epoch 1486/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9862\n",
      "Epoch 1487/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0402 - val_accuracy: 0.9863\n",
      "Epoch 1488/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9865 - val_loss: 0.0402 - val_accuracy: 0.9864\n",
      "Epoch 1489/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1490/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9864\n",
      "Epoch 1491/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0403 - val_accuracy: 0.9861\n",
      "Epoch 1492/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1493/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0349 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9864\n",
      "Epoch 1494/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9864\n",
      "Epoch 1495/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9865 - val_loss: 0.0403 - val_accuracy: 0.9862\n",
      "Epoch 1496/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9863\n",
      "Epoch 1497/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9863\n",
      "Epoch 1498/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9865 - val_loss: 0.0402 - val_accuracy: 0.9864\n",
      "Epoch 1499/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9866 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
      "Epoch 1500/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.0402 - val_accuracy: 0.9863\n",
      "Epoch 1501/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9863\n",
      "Epoch 1502/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9863 - val_loss: 0.0402 - val_accuracy: 0.9864\n",
      "Epoch 1503/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9865 - val_loss: 0.0402 - val_accuracy: 0.9861\n",
      "Epoch 1504/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 0.9865\n",
      "Epoch 1505/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1506/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9861\n",
      "Epoch 1507/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0348 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1508/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0401 - val_accuracy: 0.9863\n",
      "Epoch 1509/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0401 - val_accuracy: 0.9863\n",
      "Epoch 1510/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1511/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
      "Epoch 1512/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1513/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
      "Epoch 1514/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9863\n",
      "Epoch 1515/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1516/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
      "Epoch 1517/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 0.0401 - val_accuracy: 0.9862\n",
      "Epoch 1518/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1519/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9866 - val_loss: 0.0401 - val_accuracy: 0.9865\n",
      "Epoch 1520/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0402 - val_accuracy: 0.9861\n",
      "Epoch 1521/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9866 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1522/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9863\n",
      "Epoch 1523/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9866 - val_loss: 0.0401 - val_accuracy: 0.9864\n",
      "Epoch 1524/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9862\n",
      "Epoch 1525/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1526/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1527/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1528/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1529/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9864\n",
      "Epoch 1530/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 0.0401 - val_accuracy: 0.9862\n",
      "Epoch 1531/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9864\n",
      "Epoch 1532/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9866\n",
      "Epoch 1533/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9867 - val_loss: 0.0400 - val_accuracy: 0.9863\n",
      "Epoch 1534/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9866\n",
      "Epoch 1535/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9864\n",
      "Epoch 1536/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9867 - val_loss: 0.0400 - val_accuracy: 0.9864\n",
      "Epoch 1537/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9866\n",
      "Epoch 1538/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9864\n",
      "Epoch 1539/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0345 - accuracy: 0.9867 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1540/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0400 - val_accuracy: 0.9864\n",
      "Epoch 1541/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1542/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.0400 - val_accuracy: 0.9866\n",
      "Epoch 1543/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1544/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9863\n",
      "Epoch 1545/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1546/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0344 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1547/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0344 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1548/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1549/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0343 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1550/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0343 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9862\n",
      "Epoch 1551/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0400 - val_accuracy: 0.9862\n",
      "Epoch 1552/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1553/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9863\n",
      "Epoch 1554/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1555/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1556/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1557/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1558/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9864\n",
      "Epoch 1559/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1560/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1561/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1562/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9863\n",
      "Epoch 1563/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1564/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1565/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9868 - val_loss: 0.0400 - val_accuracy: 0.9866\n",
      "Epoch 1566/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9868 - val_loss: 0.0400 - val_accuracy: 0.9865\n",
      "Epoch 1567/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9868 - val_loss: 0.0399 - val_accuracy: 0.9865\n",
      "Epoch 1568/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9864\n",
      "Epoch 1569/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1570/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
      "Epoch 1571/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1572/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
      "Epoch 1573/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9864\n",
      "Epoch 1574/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1575/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.0400 - val_accuracy: 0.9867\n",
      "Epoch 1576/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 1577/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
      "Epoch 1578/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1579/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1580/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0341 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1581/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9870 - val_loss: 0.0398 - val_accuracy: 0.9864\n",
      "Epoch 1582/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1583/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9867\n",
      "Epoch 1584/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1585/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0398 - val_accuracy: 0.9864\n",
      "Epoch 1586/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.0399 - val_accuracy: 0.9869\n",
      "Epoch 1587/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1588/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1589/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
      "Epoch 1590/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0339 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1591/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1592/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1593/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1594/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1595/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1596/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0398 - val_accuracy: 0.9865\n",
      "Epoch 1597/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.0398 - val_accuracy: 0.9867\n",
      "Epoch 1598/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.0398 - val_accuracy: 0.9866\n",
      "Epoch 1599/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.0398 - val_accuracy: 0.9867\n",
      "Epoch 1600/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0339 - accuracy: 0.9870 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1601/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9864\n",
      "Epoch 1602/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1603/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1604/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1605/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1606/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.0398 - val_accuracy: 0.9867\n",
      "Epoch 1607/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1608/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9868\n",
      "Epoch 1609/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9864\n",
      "Epoch 1610/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1611/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9864\n",
      "Epoch 1612/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1613/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9870 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1614/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9864\n",
      "Epoch 1615/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9869\n",
      "Epoch 1616/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9869\n",
      "Epoch 1617/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9871 - val_loss: 0.0397 - val_accuracy: 0.9870\n",
      "Epoch 1618/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1619/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9871 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1620/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0337 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1621/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9870\n",
      "Epoch 1622/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9870\n",
      "Epoch 1623/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9869\n",
      "Epoch 1624/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9869 - val_loss: 0.0397 - val_accuracy: 0.9865\n",
      "Epoch 1625/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0396 - val_accuracy: 0.9865\n",
      "Epoch 1626/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9868 - val_loss: 0.0397 - val_accuracy: 0.9870\n",
      "Epoch 1627/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9865\n",
      "Epoch 1628/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9866\n",
      "Epoch 1629/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1630/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9868 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 1631/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9868\n",
      "Epoch 1632/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 0.0397 - val_accuracy: 0.9868\n",
      "Epoch 1633/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0397 - val_accuracy: 0.9870\n",
      "Epoch 1634/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1635/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9868\n",
      "Epoch 1636/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9869 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1637/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9869 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1638/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1639/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1640/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1641/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9869 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1642/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1643/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9871\n",
      "Epoch 1644/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1645/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 1646/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1647/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9872 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 1648/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9866\n",
      "Epoch 1649/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 1650/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1651/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 1652/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9870 - val_loss: 0.0397 - val_accuracy: 0.9870\n",
      "Epoch 1653/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1654/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9872\n",
      "Epoch 1655/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9867\n",
      "Epoch 1656/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9869\n",
      "Epoch 1657/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1658/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1659/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9866\n",
      "Epoch 1660/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0333 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9867\n",
      "Epoch 1661/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0333 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1662/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1663/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0333 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 1664/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0333 - accuracy: 0.9870 - val_loss: 0.0397 - val_accuracy: 0.9870\n",
      "Epoch 1665/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0333 - accuracy: 0.9872 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1666/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1667/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0332 - accuracy: 0.9869 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1668/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1669/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0333 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9868\n",
      "Epoch 1670/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0332 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1671/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0332 - accuracy: 0.9870 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1672/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1673/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9869\n",
      "Epoch 1674/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1675/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9869\n",
      "Epoch 1676/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1677/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1678/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1679/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1680/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1681/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1682/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1683/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9872 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 1684/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1685/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9869\n",
      "Epoch 1686/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9873 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1687/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1688/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1689/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1690/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9873 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1691/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1692/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9869\n",
      "Epoch 1693/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9870 - val_loss: 0.0395 - val_accuracy: 0.9867\n",
      "Epoch 1694/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1695/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9867\n",
      "Epoch 1696/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1697/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9869\n",
      "Epoch 1698/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9870 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1699/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1700/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1701/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1702/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9869\n",
      "Epoch 1703/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1704/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1705/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1706/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9869\n",
      "Epoch 1707/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1708/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1709/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1710/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9869\n",
      "Epoch 1711/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1712/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1713/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 1714/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1715/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1716/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1717/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1718/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0328 - accuracy: 0.9871 - val_loss: 0.0396 - val_accuracy: 0.9871\n",
      "Epoch 1719/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1720/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1721/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1722/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1723/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1724/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1725/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1726/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1727/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1728/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0328 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1729/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1730/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1731/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1732/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1733/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 1734/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1735/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1736/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9874 - val_loss: 0.0394 - val_accuracy: 0.9872\n",
      "Epoch 1737/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1738/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1739/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9872 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1740/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1741/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9874 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1742/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1743/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1744/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1745/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9873\n",
      "Epoch 1746/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9873\n",
      "Epoch 1747/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1748/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1749/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0393 - val_accuracy: 0.9873\n",
      "Epoch 1750/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0393 - val_accuracy: 0.9873\n",
      "Epoch 1751/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.0393 - val_accuracy: 0.9873\n",
      "Epoch 1752/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1753/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1754/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1755/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1756/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9873\n",
      "Epoch 1757/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1758/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1759/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1760/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1761/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0395 - val_accuracy: 0.9872\n",
      "Epoch 1762/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1763/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1764/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1765/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9873\n",
      "Epoch 1766/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1767/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1768/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 1769/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0325 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1770/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1771/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1772/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9872 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1773/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1774/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1775/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0324 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1776/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1777/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1778/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1779/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1780/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1781/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1782/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1783/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1784/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1785/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1786/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1787/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1788/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
      "Epoch 1789/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1790/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1791/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1792/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0394 - val_accuracy: 0.9868\n",
      "Epoch 1793/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0323 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1794/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1795/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1796/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1797/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1798/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0323 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1799/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1800/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1801/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9872\n",
      "Epoch 1802/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0322 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1803/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1804/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1805/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1806/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1807/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1808/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1809/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1810/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0322 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1811/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0322 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1812/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1813/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0322 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1814/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 0.0393 - val_accuracy: 0.9871\n",
      "Epoch 1815/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0321 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1816/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9869\n",
      "Epoch 1817/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0321 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1818/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1819/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0321 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1820/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1821/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9869\n",
      "Epoch 1822/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0321 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1823/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1824/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1825/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1826/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1827/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9869\n",
      "Epoch 1828/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1829/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9875 - val_loss: 0.0393 - val_accuracy: 0.9869\n",
      "Epoch 1830/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1831/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1832/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1833/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1834/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1835/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1836/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9875 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1837/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0320 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1838/2048\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1839/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0320 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1840/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1841/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1842/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1843/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1844/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1845/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1846/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1847/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9869\n",
      "Epoch 1848/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1849/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1850/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1851/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9874 - val_loss: 0.0394 - val_accuracy: 0.9869\n",
      "Epoch 1852/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1853/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1854/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1855/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1856/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1857/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1858/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9872\n",
      "Epoch 1859/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1860/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1861/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1862/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1863/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1864/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1865/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1866/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1867/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 0.0393 - val_accuracy: 0.9870\n",
      "Epoch 1868/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1869/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1870/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1871/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1872/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1873/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1874/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9874 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1875/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9872\n",
      "Epoch 1876/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1877/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1878/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1879/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1880/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0394 - val_accuracy: 0.9867\n",
      "Epoch 1881/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1882/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0317 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1883/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1884/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1885/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1886/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1887/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1888/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1889/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1890/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1891/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1892/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1893/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1894/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1895/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1896/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1897/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1898/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1899/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1900/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1901/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1902/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1903/2048\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.0315 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1904/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1905/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1906/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1907/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1908/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1909/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1910/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1911/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1912/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1913/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1914/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1915/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1916/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1917/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1918/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0314 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1919/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0314 - accuracy: 0.9876 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1920/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9876 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1921/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1922/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1923/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1924/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9875 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1925/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9876 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1926/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1927/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1928/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1929/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0314 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1930/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0393 - val_accuracy: 0.9868\n",
      "Epoch 1931/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9872\n",
      "Epoch 1932/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1933/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9868\n",
      "Epoch 1934/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1935/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1936/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1937/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1938/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1939/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1940/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1941/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0393 - val_accuracy: 0.9867\n",
      "Epoch 1942/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1943/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1944/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1945/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1946/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9876 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1947/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1948/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0393 - val_accuracy: 0.9867\n",
      "Epoch 1949/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9876 - val_loss: 0.0393 - val_accuracy: 0.9866\n",
      "Epoch 1950/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1951/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1952/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1953/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9867\n",
      "Epoch 1954/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9868\n",
      "Epoch 1955/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1956/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1957/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1958/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1959/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9868\n",
      "Epoch 1960/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9867\n",
      "Epoch 1961/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9868\n",
      "Epoch 1962/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1963/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1964/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1965/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9866\n",
      "Epoch 1966/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1967/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1968/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1969/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9868\n",
      "Epoch 1970/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1971/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1972/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1973/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0393 - val_accuracy: 0.9865\n",
      "Epoch 1974/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0311 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1975/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1976/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1977/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9867\n",
      "Epoch 1978/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0311 - accuracy: 0.9876 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1979/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1980/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1981/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9871\n",
      "Epoch 1982/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1983/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1984/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1985/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1986/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1987/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9871\n",
      "Epoch 1988/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1989/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9866\n",
      "Epoch 1990/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0310 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 1991/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1992/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 1993/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 1994/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 1995/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0391 - val_accuracy: 0.9871\n",
      "Epoch 1996/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1997/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 1998/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 1999/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 2000/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2001/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 2002/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 2003/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 2004/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 2005/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2006/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 2007/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9877 - val_loss: 0.0393 - val_accuracy: 0.9866\n",
      "Epoch 2008/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9865\n",
      "Epoch 2009/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0393 - val_accuracy: 0.9865\n",
      "Epoch 2010/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2011/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2012/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2013/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0309 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2014/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
      "Epoch 2015/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2016/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 2017/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 2018/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9871\n",
      "Epoch 2019/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9871\n",
      "Epoch 2020/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2021/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 2022/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 2023/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2024/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 2025/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9872\n",
      "Epoch 2026/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9867\n",
      "Epoch 2027/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9867\n",
      "Epoch 2028/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2029/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9871\n",
      "Epoch 2030/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 2031/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2032/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
      "Epoch 2033/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9872\n",
      "Epoch 2034/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 2035/2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 2036/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9868\n",
      "Epoch 2037/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9872\n",
      "Epoch 2038/2048\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 2039/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 2040/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0391 - val_accuracy: 0.9871\n",
      "Epoch 2041/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9870\n",
      "Epoch 2042/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9877 - val_loss: 0.0392 - val_accuracy: 0.9871\n",
      "Epoch 2043/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
      "Epoch 2044/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.0392 - val_accuracy: 0.9867\n",
      "Epoch 2045/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9870\n",
      "Epoch 2046/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.0391 - val_accuracy: 0.9872\n",
      "Epoch 2047/2048\n",
      "78/78 [==============================] - 1s 7ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9869\n",
      "Epoch 2048/2048\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9879 - val_loss: 0.0392 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b783f1400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=512, epochs=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJIEsewSeOlc"
   },
   "source": [
    "#### test\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> Test your model by test.tsv and output the accuracy. Beat the accuracy baseline: **0.98** for extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nDzmeBV4eOlc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9755\n",
      "0.9754999876022339\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxVkZUuFeOlc"
   },
   "source": [
    "## Show wrong prediction results\n",
    "Observing wrong prediction result may help you improve your prediction.\n",
    "\n",
    "<font color=\"red\">**[ TODO ]**</font> show the wrong prediction results like this: \n",
    "\n",
    "<img src=\"https://imgur.com/BOTMyZH.jpg\" width=30%><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lVqH4lvleOld"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = model.predict(X_test)\n",
    "test[\"predict\"] = np.argmax(predicted_probabilities, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>class</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>earn pay</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>currency you earn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>earn my degree</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>earn the money ?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>earn your Masters Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>earn money fast earn money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>earn money without money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>earn their power</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>earn a &gt; living</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>earn money from earn money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>earn your commission !</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>earn victory</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>earn a living</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>earn commission</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>earn \" their money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>more we earn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>earn a fair income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>earn ( income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>what they can earn ,</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>more could you earn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>earn 1.5 times the amount</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>, earn on average</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Family Meeting can earn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>, earn or get money</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>earn affiliate income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>earn money | earn money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>what I earn ,</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>earn money online earn money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>earn affiliate commission</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>earn extra money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>earn an income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>earn , earned income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>earn enough money to retire</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>earn Free Gear with Bonus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>earn + money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>earn some extra income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>earn money , earn money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>earn my income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>earn ... more</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>earn points and redeem them</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>earn profit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>earn + a + degree</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>earn a profit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>earn the Most</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>- money earn -</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>earn a rental income</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>earn college scholarship</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>earn a special award</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>earn virtual money</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            phrase  class  predict\n",
       "6                         earn pay      1        0\n",
       "11               currency you earn      1        0\n",
       "20                  earn my degree      1        0\n",
       "196               earn the money ?      0        1\n",
       "197       earn your Masters Degree      0        1\n",
       "298     earn money fast earn money      1        0\n",
       "314       earn money without money      1        0\n",
       "328               earn their power      1        0\n",
       "519                earn a > living      1        0\n",
       "541     earn money from earn money      1        0\n",
       "641         earn your commission !      0        1\n",
       "705                   earn victory      1        0\n",
       "724                  earn a living      1        0\n",
       "783                earn commission      1        0\n",
       "831             earn \" their money      1        0\n",
       "986                   more we earn      1        0\n",
       "995             earn a fair income      1        0\n",
       "1021                 earn ( income      1        0\n",
       "1054          what they can earn ,      0        1\n",
       "1072           more could you earn      1        0\n",
       "1074     earn 1.5 times the amount      1        0\n",
       "1081             , earn on average      0        1\n",
       "1100       Family Meeting can earn      1        0\n",
       "1106           , earn or get money      0        1\n",
       "1197         earn affiliate income      1        0\n",
       "1201       earn money | earn money      1        0\n",
       "1245                 what I earn ,      0        1\n",
       "1287  earn money online earn money      1        0\n",
       "1352     earn affiliate commission      1        0\n",
       "1392              earn extra money      1        0\n",
       "1427                earn an income      1        0\n",
       "1470          earn , earned income      1        0\n",
       "1482   earn enough money to retire      0        1\n",
       "1512     earn Free Gear with Bonus      0        1\n",
       "1536                  earn + money      1        0\n",
       "1581        earn some extra income      1        0\n",
       "1585       earn money , earn money      1        0\n",
       "1627                earn my income      1        0\n",
       "1719                 earn ... more      1        0\n",
       "1720   earn points and redeem them      1        0\n",
       "1721                   earn profit      1        0\n",
       "1723             earn + a + degree      1        0\n",
       "1741                 earn a profit      1        0\n",
       "1795                 earn the Most      1        0\n",
       "1808                - money earn -      0        1\n",
       "1818          earn a rental income      1        0\n",
       "1840      earn college scholarship      1        0\n",
       "1841          earn a special award      1        0\n",
       "1852            earn virtual money      1        0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test[\"class\"] != test[\"predict\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model/assets\n"
     ]
    }
   ],
   "source": [
    "save_model = False\n",
    "if save_model:\n",
    "  model.save(\"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9755\n",
      "0.9754999876022339\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "trained_model = load_model(\"trained_model\")\n",
    "accuracy = trained_model.evaluate(X_test, y_test)\n",
    "print(accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KprbNm7KeOle"
   },
   "source": [
    "## TA's Notes\n",
    "\n",
    "If you complete the Assignment, please use [this link](https://docs.google.com/spreadsheets/d/1OKbXhcv6E3FEQDPnbHEHEeHvpxv01jxugMP7WwnKqKw/edit#gid=258852025) to reserve demo time.  \n",
    "The score is only given after TAs review your implementation, so <u>**make sure you make a appointment with a TA before you miss the deadline**</u> .  <br>After demo, please upload your assignment to elearn. You just need to hand in this ipynb file and rename it as XXXXXXXXX(Your student ID).ipynb.\n",
    "<br>Note that **late submission will not be allowed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQl6lTDzeOlf"
   },
   "source": [
    "## Learning Resource\n",
    "[Deep Learning with Python](https://tanthiamhuat.files.wordpress.com/2018/03/deeplearningwithpython.pdf)\n",
    "\n",
    "[Classification on IMDB](https://keras.io/examples/nlp/bidirectional_lstm_imdb/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
